{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "681983cb-0f3b-48a5-8276-c42dd3d0d47a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "---1---\n",
      "Requirement already satisfied: pandas in d:\\optimizing-catboost-model-with-bayesian\\env\\lib\\site-packages (2.2.3)\n",
      "Requirement already satisfied: numpy>=1.23.2 in d:\\optimizing-catboost-model-with-bayesian\\env\\lib\\site-packages (from pandas) (1.26.4)\n",
      "Requirement already satisfied: python-dateutil>=2.8.2 in d:\\optimizing-catboost-model-with-bayesian\\env\\lib\\site-packages (from pandas) (2.9.0.post0)\n",
      "Requirement already satisfied: pytz>=2020.1 in d:\\optimizing-catboost-model-with-bayesian\\env\\lib\\site-packages (from pandas) (2024.2)\n",
      "Requirement already satisfied: tzdata>=2022.7 in d:\\optimizing-catboost-model-with-bayesian\\env\\lib\\site-packages (from pandas) (2024.2)\n",
      "Requirement already satisfied: six>=1.5 in d:\\optimizing-catboost-model-with-bayesian\\env\\lib\\site-packages (from python-dateutil>=2.8.2->pandas) (1.17.0)\n",
      "Note: you may need to restart the kernel to use updated packages.\n",
      "---2---\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "[notice] A new release of pip is available: 24.3.1 -> 25.0.1\n",
      "[notice] To update, run: python.exe -m pip install --upgrade pip\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: seaborn in d:\\optimizing-catboost-model-with-bayesian\\env\\lib\\site-packages (0.13.2)Note: you may need to restart the kernel to use updated packages.\n",
      "---3---\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "[notice] A new release of pip is available: 24.3.1 -> 25.0.1\n",
      "[notice] To update, run: python.exe -m pip install --upgrade pip\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Requirement already satisfied: numpy!=1.24.0,>=1.20 in d:\\optimizing-catboost-model-with-bayesian\\env\\lib\\site-packages (from seaborn) (1.26.4)\n",
      "Requirement already satisfied: pandas>=1.2 in d:\\optimizing-catboost-model-with-bayesian\\env\\lib\\site-packages (from seaborn) (2.2.3)\n",
      "Requirement already satisfied: matplotlib!=3.6.1,>=3.4 in d:\\optimizing-catboost-model-with-bayesian\\env\\lib\\site-packages (from seaborn) (3.10.0)\n",
      "Requirement already satisfied: contourpy>=1.0.1 in d:\\optimizing-catboost-model-with-bayesian\\env\\lib\\site-packages (from matplotlib!=3.6.1,>=3.4->seaborn) (1.3.1)\n",
      "Requirement already satisfied: cycler>=0.10 in d:\\optimizing-catboost-model-with-bayesian\\env\\lib\\site-packages (from matplotlib!=3.6.1,>=3.4->seaborn) (0.12.1)\n",
      "Requirement already satisfied: fonttools>=4.22.0 in d:\\optimizing-catboost-model-with-bayesian\\env\\lib\\site-packages (from matplotlib!=3.6.1,>=3.4->seaborn) (4.55.3)\n",
      "Requirement already satisfied: kiwisolver>=1.3.1 in d:\\optimizing-catboost-model-with-bayesian\\env\\lib\\site-packages (from matplotlib!=3.6.1,>=3.4->seaborn) (1.4.7)\n",
      "Requirement already satisfied: packaging>=20.0 in d:\\optimizing-catboost-model-with-bayesian\\env\\lib\\site-packages (from matplotlib!=3.6.1,>=3.4->seaborn) (24.2)\n",
      "Requirement already satisfied: pillow>=8 in d:\\optimizing-catboost-model-with-bayesian\\env\\lib\\site-packages (from matplotlib!=3.6.1,>=3.4->seaborn) (11.0.0)\n",
      "Requirement already satisfied: pyparsing>=2.3.1 in d:\\optimizing-catboost-model-with-bayesian\\env\\lib\\site-packages (from matplotlib!=3.6.1,>=3.4->seaborn) (3.2.0)\n",
      "Requirement already satisfied: python-dateutil>=2.7 in d:\\optimizing-catboost-model-with-bayesian\\env\\lib\\site-packages (from matplotlib!=3.6.1,>=3.4->seaborn) (2.9.0.post0)\n",
      "Requirement already satisfied: pytz>=2020.1 in d:\\optimizing-catboost-model-with-bayesian\\env\\lib\\site-packages (from pandas>=1.2->seaborn) (2024.2)\n",
      "Requirement already satisfied: tzdata>=2022.7 in d:\\optimizing-catboost-model-with-bayesian\\env\\lib\\site-packages (from pandas>=1.2->seaborn) (2024.2)\n",
      "Requirement already satisfied: six>=1.5 in d:\\optimizing-catboost-model-with-bayesian\\env\\lib\\site-packages (from python-dateutil>=2.7->matplotlib!=3.6.1,>=3.4->seaborn) (1.17.0)\n",
      "Requirement already satisfied: scikit-learn in d:\\optimizing-catboost-model-with-bayesian\\env\\lib\\site-packages (1.6.1)\n",
      "Requirement already satisfied: numpy>=1.19.5 in d:\\optimizing-catboost-model-with-bayesian\\env\\lib\\site-packages (from scikit-learn) (1.26.4)\n",
      "Requirement already satisfied: scipy>=1.6.0 in d:\\optimizing-catboost-model-with-bayesian\\env\\lib\\site-packages (from scikit-learn) (1.14.1)\n",
      "Requirement already satisfied: joblib>=1.2.0 in d:\\optimizing-catboost-model-with-bayesian\\env\\lib\\site-packages (from scikit-learn) (1.4.2)\n",
      "Requirement already satisfied: threadpoolctl>=3.1.0 in d:\\optimizing-catboost-model-with-bayesian\\env\\lib\\site-packages (from scikit-learn) (3.5.0)\n",
      "Note: you may need to restart the kernel to use updated packages.\n",
      "---4---\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "[notice] A new release of pip is available: 24.3.1 -> 25.0.1\n",
      "[notice] To update, run: python.exe -m pip install --upgrade pip\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: catboost in d:\\optimizing-catboost-model-with-bayesian\\env\\lib\\site-packages (1.2.7)\n",
      "Requirement already satisfied: graphviz in d:\\optimizing-catboost-model-with-bayesian\\env\\lib\\site-packages (from catboost) (0.20.3)\n",
      "Requirement already satisfied: matplotlib in d:\\optimizing-catboost-model-with-bayesian\\env\\lib\\site-packages (from catboost) (3.10.0)\n",
      "Requirement already satisfied: numpy<2.0,>=1.16.0 in d:\\optimizing-catboost-model-with-bayesian\\env\\lib\\site-packages (from catboost) (1.26.4)\n",
      "Requirement already satisfied: pandas>=0.24 in d:\\optimizing-catboost-model-with-bayesian\\env\\lib\\site-packages (from catboost) (2.2.3)\n",
      "Requirement already satisfied: scipy in d:\\optimizing-catboost-model-with-bayesian\\env\\lib\\site-packages (from catboost) (1.14.1)\n",
      "Requirement already satisfied: plotly in d:\\optimizing-catboost-model-with-bayesian\\env\\lib\\site-packages (from catboost) (5.24.1)\n",
      "Requirement already satisfied: six in d:\\optimizing-catboost-model-with-bayesian\\env\\lib\\site-packages (from catboost) (1.17.0)\n",
      "Requirement already satisfied: python-dateutil>=2.8.2 in d:\\optimizing-catboost-model-with-bayesian\\env\\lib\\site-packages (from pandas>=0.24->catboost) (2.9.0.post0)\n",
      "Requirement already satisfied: pytz>=2020.1 in d:\\optimizing-catboost-model-with-bayesian\\env\\lib\\site-packages (from pandas>=0.24->catboost) (2024.2)\n",
      "Requirement already satisfied: tzdata>=2022.7 in d:\\optimizing-catboost-model-with-bayesian\\env\\lib\\site-packages (from pandas>=0.24->catboost) (2024.2)\n",
      "Requirement already satisfied: contourpy>=1.0.1 in d:\\optimizing-catboost-model-with-bayesian\\env\\lib\\site-packages (from matplotlib->catboost) (1.3.1)\n",
      "Requirement already satisfied: cycler>=0.10 in d:\\optimizing-catboost-model-with-bayesian\\env\\lib\\site-packages (from matplotlib->catboost) (0.12.1)\n",
      "Requirement already satisfied: fonttools>=4.22.0 in d:\\optimizing-catboost-model-with-bayesian\\env\\lib\\site-packages (from matplotlib->catboost) (4.55.3)\n",
      "Requirement already satisfied: kiwisolver>=1.3.1 in d:\\optimizing-catboost-model-with-bayesian\\env\\lib\\site-packages (from matplotlib->catboost) (1.4.7)\n",
      "Requirement already satisfied: packaging>=20.0 in d:\\optimizing-catboost-model-with-bayesian\\env\\lib\\site-packages (from matplotlib->catboost) (24.2)\n",
      "Requirement already satisfied: pillow>=8 in d:\\optimizing-catboost-model-with-bayesian\\env\\lib\\site-packages (from matplotlib->catboost) (11.0.0)\n",
      "Requirement already satisfied: pyparsing>=2.3.1 in d:\\optimizing-catboost-model-with-bayesian\\env\\lib\\site-packages (from matplotlib->catboost) (3.2.0)\n",
      "Requirement already satisfied: tenacity>=6.2.0 in d:\\optimizing-catboost-model-with-bayesian\\env\\lib\\site-packages (from plotly->catboost) (9.0.0)\n",
      "Note: you may need to restart the kernel to use updated packages.\n",
      "---5---\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "[notice] A new release of pip is available: 24.3.1 -> 25.0.1\n",
      "[notice] To update, run: python.exe -m pip install --upgrade pip\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: ipywidgets in d:\\optimizing-catboost-model-with-bayesian\\env\\lib\\site-packages (8.1.5)\n",
      "Requirement already satisfied: comm>=0.1.3 in d:\\optimizing-catboost-model-with-bayesian\\env\\lib\\site-packages (from ipywidgets) (0.2.2)\n",
      "Requirement already satisfied: ipython>=6.1.0 in d:\\optimizing-catboost-model-with-bayesian\\env\\lib\\site-packages (from ipywidgets) (8.31.0)\n",
      "Requirement already satisfied: traitlets>=4.3.1 in d:\\optimizing-catboost-model-with-bayesian\\env\\lib\\site-packages (from ipywidgets) (5.14.3)\n",
      "Requirement already satisfied: widgetsnbextension~=4.0.12 in d:\\optimizing-catboost-model-with-bayesian\\env\\lib\\site-packages (from ipywidgets) (4.0.13)\n",
      "Requirement already satisfied: jupyterlab-widgets~=3.0.12 in d:\\optimizing-catboost-model-with-bayesian\\env\\lib\\site-packages (from ipywidgets) (3.0.13)\n",
      "Requirement already satisfied: colorama in d:\\optimizing-catboost-model-with-bayesian\\env\\lib\\site-packages (from ipython>=6.1.0->ipywidgets) (0.4.6)\n",
      "Requirement already satisfied: decorator in d:\\optimizing-catboost-model-with-bayesian\\env\\lib\\site-packages (from ipython>=6.1.0->ipywidgets) (5.1.1)\n",
      "Requirement already satisfied: jedi>=0.16 in d:\\optimizing-catboost-model-with-bayesian\\env\\lib\\site-packages (from ipython>=6.1.0->ipywidgets) (0.19.2)\n",
      "Requirement already satisfied: matplotlib-inline in d:\\optimizing-catboost-model-with-bayesian\\env\\lib\\site-packages (from ipython>=6.1.0->ipywidgets) (0.1.7)\n",
      "Requirement already satisfied: prompt_toolkit<3.1.0,>=3.0.41 in d:\\optimizing-catboost-model-with-bayesian\\env\\lib\\site-packages (from ipython>=6.1.0->ipywidgets) (3.0.50)\n",
      "Requirement already satisfied: pygments>=2.4.0 in d:\\optimizing-catboost-model-with-bayesian\\env\\lib\\site-packages (from ipython>=6.1.0->ipywidgets) (2.19.1)\n",
      "Requirement already satisfied: stack_data in d:\\optimizing-catboost-model-with-bayesian\\env\\lib\\site-packages (from ipython>=6.1.0->ipywidgets) (0.6.3)\n",
      "Requirement already satisfied: typing_extensions>=4.6 in d:\\optimizing-catboost-model-with-bayesian\\env\\lib\\site-packages (from ipython>=6.1.0->ipywidgets) (4.12.2)\n",
      "Requirement already satisfied: parso<0.9.0,>=0.8.4 in d:\\optimizing-catboost-model-with-bayesian\\env\\lib\\site-packages (from jedi>=0.16->ipython>=6.1.0->ipywidgets) (0.8.4)\n",
      "Requirement already satisfied: wcwidth in d:\\optimizing-catboost-model-with-bayesian\\env\\lib\\site-packages (from prompt_toolkit<3.1.0,>=3.0.41->ipython>=6.1.0->ipywidgets) (0.2.13)\n",
      "Requirement already satisfied: executing>=1.2.0 in d:\\optimizing-catboost-model-with-bayesian\\env\\lib\\site-packages (from stack_data->ipython>=6.1.0->ipywidgets) (2.1.0)\n",
      "Requirement already satisfied: asttokens>=2.1.0 in d:\\optimizing-catboost-model-with-bayesian\\env\\lib\\site-packages (from stack_data->ipython>=6.1.0->ipywidgets) (3.0.0)\n",
      "Requirement already satisfied: pure-eval in d:\\optimizing-catboost-model-with-bayesian\\env\\lib\\site-packages (from stack_data->ipython>=6.1.0->ipywidgets) (0.2.3)\n",
      "Note: you may need to restart the kernel to use updated packages.\n",
      "---6---\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "[notice] A new release of pip is available: 24.3.1 -> 25.0.1\n",
      "[notice] To update, run: python.exe -m pip install --upgrade pip\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: pandas in d:\\optimizing-catboost-model-with-bayesian\\env\\lib\\site-packages (2.2.3)\n",
      "Requirement already satisfied: openpyxl in d:\\optimizing-catboost-model-with-bayesian\\env\\lib\\site-packages (3.1.5)\n",
      "Requirement already satisfied: numpy>=1.23.2 in d:\\optimizing-catboost-model-with-bayesian\\env\\lib\\site-packages (from pandas) (1.26.4)\n",
      "Requirement already satisfied: python-dateutil>=2.8.2 in d:\\optimizing-catboost-model-with-bayesian\\env\\lib\\site-packages (from pandas) (2.9.0.post0)\n",
      "Requirement already satisfied: pytz>=2020.1 in d:\\optimizing-catboost-model-with-bayesian\\env\\lib\\site-packages (from pandas) (2024.2)\n",
      "Requirement already satisfied: tzdata>=2022.7 in d:\\optimizing-catboost-model-with-bayesian\\env\\lib\\site-packages (from pandas) (2024.2)\n",
      "Requirement already satisfied: et-xmlfile in d:\\optimizing-catboost-model-with-bayesian\\env\\lib\\site-packages (from openpyxl) (2.0.0)\n",
      "Requirement already satisfied: six>=1.5 in d:\\optimizing-catboost-model-with-bayesian\\env\\lib\\site-packages (from python-dateutil>=2.8.2->pandas) (1.17.0)\n",
      "Note: you may need to restart the kernel to use updated packages.\n",
      "---7---\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "[notice] A new release of pip is available: 24.3.1 -> 25.0.1\n",
      "[notice] To update, run: python.exe -m pip install --upgrade pip\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: bayesian-optimization in d:\\optimizing-catboost-model-with-bayesian\\env\\lib\\site-packages (2.0.3)\n",
      "Requirement already satisfied: colorama<0.5.0,>=0.4.6 in d:\\optimizing-catboost-model-with-bayesian\\env\\lib\\site-packages (from bayesian-optimization) (0.4.6)\n",
      "Requirement already satisfied: numpy>=1.25 in d:\\optimizing-catboost-model-with-bayesian\\env\\lib\\site-packages (from bayesian-optimization) (1.26.4)\n",
      "Requirement already satisfied: scikit-learn<2.0.0,>=1.0.0 in d:\\optimizing-catboost-model-with-bayesian\\env\\lib\\site-packages (from bayesian-optimization) (1.6.1)\n",
      "Requirement already satisfied: scipy<2.0.0,>=1.0.0 in d:\\optimizing-catboost-model-with-bayesian\\env\\lib\\site-packages (from bayesian-optimization) (1.14.1)\n",
      "Requirement already satisfied: joblib>=1.2.0 in d:\\optimizing-catboost-model-with-bayesian\\env\\lib\\site-packages (from scikit-learn<2.0.0,>=1.0.0->bayesian-optimization) (1.4.2)\n",
      "Requirement already satisfied: threadpoolctl>=3.1.0 in d:\\optimizing-catboost-model-with-bayesian\\env\\lib\\site-packages (from scikit-learn<2.0.0,>=1.0.0->bayesian-optimization) (3.5.0)\n",
      "Note: you may need to restart the kernel to use updated packages.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "[notice] A new release of pip is available: 24.3.1 -> 25.0.1\n",
      "[notice] To update, run: python.exe -m pip install --upgrade pip\n"
     ]
    }
   ],
   "source": [
    "#PIP INSTALLATION\n",
    "print('---1---')\n",
    "%pip install pandas\n",
    "print('---2---')\n",
    "%pip install seaborn\n",
    "print('---3---')\n",
    "%pip install scikit-learn\n",
    "print('---4---')\n",
    "%pip install catboost\n",
    "print('---5---')\n",
    "%pip install ipywidgets\n",
    "print('---6---')\n",
    "%pip install pandas openpyxl\n",
    "print('---7---')\n",
    "%pip install bayesian-optimization\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "6e7ab83d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Package               Version\n",
      "--------------------- -----------\n",
      "aiohappyeyeballs      2.4.6\n",
      "aiohttp               3.11.12\n",
      "aiosignal             1.3.2\n",
      "asttokens             3.0.0\n",
      "attrs                 25.1.0\n",
      "bayesian-optimization 2.0.3\n",
      "blinker               1.9.0\n",
      "catboost              1.2.7\n",
      "category_encoders     2.8.0\n",
      "certifi               2025.1.31\n",
      "charset-normalizer    3.4.1\n",
      "click                 8.1.7\n",
      "colorama              0.4.6\n",
      "comm                  0.2.2\n",
      "contourpy             1.3.1\n",
      "cycler                0.12.1\n",
      "datasets              3.2.0\n",
      "debugpy               1.8.12\n",
      "decorator             5.1.1\n",
      "dill                  0.3.8\n",
      "et_xmlfile            2.0.0\n",
      "executing             2.1.0\n",
      "filelock              3.17.0\n",
      "Flask                 3.1.0\n",
      "Flask-SQLAlchemy      3.1.1\n",
      "fonttools             4.55.3\n",
      "frozenlist            1.5.0\n",
      "fsspec                2024.9.0\n",
      "graphviz              0.20.3\n",
      "greenlet              3.1.1\n",
      "huggingface-hub       0.28.1\n",
      "idna                  3.10\n",
      "ipykernel             6.29.5\n",
      "ipython               8.31.0\n",
      "ipywidgets            8.1.5\n",
      "itsdangerous          2.2.0\n",
      "jedi                  0.19.2\n",
      "Jinja2                3.1.4\n",
      "joblib                1.4.2\n",
      "jupyter_client        8.6.3\n",
      "jupyter_core          5.7.2\n",
      "jupyterlab_widgets    3.0.13\n",
      "kiwisolver            1.4.7\n",
      "MarkupSafe            3.0.2\n",
      "matplotlib            3.10.0\n",
      "matplotlib-inline     0.1.7\n",
      "multidict             6.1.0\n",
      "multiprocess          0.70.16\n",
      "nest-asyncio          1.6.0\n",
      "numpy                 1.26.4\n",
      "openpyxl              3.1.5\n",
      "packaging             24.2\n",
      "pandas                2.2.3\n",
      "parso                 0.8.4\n",
      "patsy                 1.0.1\n",
      "pillow                11.0.0\n",
      "pip                   24.3.1\n",
      "platformdirs          4.3.6\n",
      "plotly                5.24.1\n",
      "prompt_toolkit        3.0.50\n",
      "propcache             0.2.1\n",
      "psutil                6.1.1\n",
      "pure_eval             0.2.3\n",
      "pyarrow               19.0.0\n",
      "Pygments              2.19.1\n",
      "pyparsing             3.2.0\n",
      "python-dateutil       2.9.0.post0\n",
      "pytz                  2024.2\n",
      "pywin32               308\n",
      "PyYAML                6.0.2\n",
      "pyzmq                 26.2.0\n",
      "requests              2.32.3\n",
      "scikit-learn          1.6.1\n",
      "scipy                 1.14.1\n",
      "seaborn               0.13.2\n",
      "setuptools            75.6.0\n",
      "six                   1.17.0\n",
      "SQLAlchemy            2.0.36\n",
      "stack-data            0.6.3\n",
      "statsmodels           0.14.4\n",
      "tenacity              9.0.0\n",
      "threadpoolctl         3.5.0\n",
      "tornado               6.4.2\n",
      "tqdm                  4.67.1\n",
      "traitlets             5.14.3\n",
      "typing_extensions     4.12.2\n",
      "tzdata                2024.2\n",
      "urllib3               2.3.0\n",
      "wcwidth               0.2.13\n",
      "Werkzeug              3.1.3\n",
      "wheel                 0.45.1\n",
      "widgetsnbextension    4.0.13\n",
      "xxhash                3.5.0\n",
      "yarl                  1.18.3\n",
      "Note: you may need to restart the kernel to use updated packages.\n"
     ]
    }
   ],
   "source": [
    "%pip list"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "007b7ecb-c7f7-40c7-a50a-b7d8bd468704",
   "metadata": {},
   "outputs": [],
   "source": [
    "#FROM LIBRARIES\n",
    "from bayes_opt import BayesianOptimization\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.model_selection import StratifiedKFold\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from catboost import CatBoostClassifier, Pool\n",
    "from IPython.display import FileLink\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "from sklearn import metrics\n",
    "from sklearn.metrics import (\n",
    "    accuracy_score, precision_score, recall_score, f1_score,\n",
    "    roc_curve, roc_auc_score, precision_recall_curve, average_precision_score,\n",
    "    confusion_matrix\n",
    ")\n",
    "from typing import Optional\n",
    "\n",
    "\n",
    "#IMPORT AS\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import seaborn as sns\n",
    "import os\n",
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline\n",
    "plt.style.use('ggplot')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "d92e7141-3441-4a97-835a-ef1897779b0f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>encounter_id</th>\n",
       "      <th>patient_nbr</th>\n",
       "      <th>race</th>\n",
       "      <th>gender</th>\n",
       "      <th>age</th>\n",
       "      <th>weight</th>\n",
       "      <th>admission_type_id</th>\n",
       "      <th>discharge_disposition_id</th>\n",
       "      <th>admission_source_id</th>\n",
       "      <th>time_in_hospital</th>\n",
       "      <th>...</th>\n",
       "      <th>citoglipton</th>\n",
       "      <th>insulin</th>\n",
       "      <th>glyburide-metformin</th>\n",
       "      <th>glipizide-metformin</th>\n",
       "      <th>glimepiride-pioglitazone</th>\n",
       "      <th>metformin-rosiglitazone</th>\n",
       "      <th>metformin-pioglitazone</th>\n",
       "      <th>change</th>\n",
       "      <th>diabetesMed</th>\n",
       "      <th>readmitted</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>2278392</td>\n",
       "      <td>8222157</td>\n",
       "      <td>Caucasian</td>\n",
       "      <td>Female</td>\n",
       "      <td>[0-10)</td>\n",
       "      <td>?</td>\n",
       "      <td>6</td>\n",
       "      <td>25</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>...</td>\n",
       "      <td>No</td>\n",
       "      <td>No</td>\n",
       "      <td>No</td>\n",
       "      <td>No</td>\n",
       "      <td>No</td>\n",
       "      <td>No</td>\n",
       "      <td>No</td>\n",
       "      <td>No</td>\n",
       "      <td>No</td>\n",
       "      <td>NO</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>149190</td>\n",
       "      <td>55629189</td>\n",
       "      <td>Caucasian</td>\n",
       "      <td>Female</td>\n",
       "      <td>[10-20)</td>\n",
       "      <td>?</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>7</td>\n",
       "      <td>3</td>\n",
       "      <td>...</td>\n",
       "      <td>No</td>\n",
       "      <td>Up</td>\n",
       "      <td>No</td>\n",
       "      <td>No</td>\n",
       "      <td>No</td>\n",
       "      <td>No</td>\n",
       "      <td>No</td>\n",
       "      <td>Ch</td>\n",
       "      <td>Yes</td>\n",
       "      <td>&gt;30</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>64410</td>\n",
       "      <td>86047875</td>\n",
       "      <td>AfricanAmerican</td>\n",
       "      <td>Female</td>\n",
       "      <td>[20-30)</td>\n",
       "      <td>?</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>7</td>\n",
       "      <td>2</td>\n",
       "      <td>...</td>\n",
       "      <td>No</td>\n",
       "      <td>No</td>\n",
       "      <td>No</td>\n",
       "      <td>No</td>\n",
       "      <td>No</td>\n",
       "      <td>No</td>\n",
       "      <td>No</td>\n",
       "      <td>No</td>\n",
       "      <td>Yes</td>\n",
       "      <td>NO</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>500364</td>\n",
       "      <td>82442376</td>\n",
       "      <td>Caucasian</td>\n",
       "      <td>Male</td>\n",
       "      <td>[30-40)</td>\n",
       "      <td>?</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>7</td>\n",
       "      <td>2</td>\n",
       "      <td>...</td>\n",
       "      <td>No</td>\n",
       "      <td>Up</td>\n",
       "      <td>No</td>\n",
       "      <td>No</td>\n",
       "      <td>No</td>\n",
       "      <td>No</td>\n",
       "      <td>No</td>\n",
       "      <td>Ch</td>\n",
       "      <td>Yes</td>\n",
       "      <td>NO</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>16680</td>\n",
       "      <td>42519267</td>\n",
       "      <td>Caucasian</td>\n",
       "      <td>Male</td>\n",
       "      <td>[40-50)</td>\n",
       "      <td>?</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>7</td>\n",
       "      <td>1</td>\n",
       "      <td>...</td>\n",
       "      <td>No</td>\n",
       "      <td>Steady</td>\n",
       "      <td>No</td>\n",
       "      <td>No</td>\n",
       "      <td>No</td>\n",
       "      <td>No</td>\n",
       "      <td>No</td>\n",
       "      <td>Ch</td>\n",
       "      <td>Yes</td>\n",
       "      <td>NO</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows Ã— 50 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "   encounter_id  patient_nbr             race  gender      age weight  \\\n",
       "0       2278392      8222157        Caucasian  Female   [0-10)      ?   \n",
       "1        149190     55629189        Caucasian  Female  [10-20)      ?   \n",
       "2         64410     86047875  AfricanAmerican  Female  [20-30)      ?   \n",
       "3        500364     82442376        Caucasian    Male  [30-40)      ?   \n",
       "4         16680     42519267        Caucasian    Male  [40-50)      ?   \n",
       "\n",
       "   admission_type_id  discharge_disposition_id  admission_source_id  \\\n",
       "0                  6                        25                    1   \n",
       "1                  1                         1                    7   \n",
       "2                  1                         1                    7   \n",
       "3                  1                         1                    7   \n",
       "4                  1                         1                    7   \n",
       "\n",
       "   time_in_hospital  ... citoglipton insulin  glyburide-metformin  \\\n",
       "0                 1  ...          No      No                   No   \n",
       "1                 3  ...          No      Up                   No   \n",
       "2                 2  ...          No      No                   No   \n",
       "3                 2  ...          No      Up                   No   \n",
       "4                 1  ...          No  Steady                   No   \n",
       "\n",
       "   glipizide-metformin  glimepiride-pioglitazone  metformin-rosiglitazone  \\\n",
       "0                   No                        No                       No   \n",
       "1                   No                        No                       No   \n",
       "2                   No                        No                       No   \n",
       "3                   No                        No                       No   \n",
       "4                   No                        No                       No   \n",
       "\n",
       "   metformin-pioglitazone  change diabetesMed readmitted  \n",
       "0                      No      No          No         NO  \n",
       "1                      No      Ch         Yes        >30  \n",
       "2                      No      No         Yes         NO  \n",
       "3                      No      Ch         Yes         NO  \n",
       "4                      No      Ch         Yes         NO  \n",
       "\n",
       "[5 rows x 50 columns]"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "file_path = 'Dataset/diabetic_data.csv'\n",
    "df = pd.read_csv(file_path,keep_default_na=False)\n",
    "df_clean = df.copy()\n",
    "df_clean.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "66f03d94-b072-4b51-b344-bdc5c5e6c1e2",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>encounter_id</th>\n",
       "      <th>patient_nbr</th>\n",
       "      <th>admission_type_id</th>\n",
       "      <th>discharge_disposition_id</th>\n",
       "      <th>admission_source_id</th>\n",
       "      <th>time_in_hospital</th>\n",
       "      <th>num_lab_procedures</th>\n",
       "      <th>num_procedures</th>\n",
       "      <th>num_medications</th>\n",
       "      <th>number_outpatient</th>\n",
       "      <th>number_emergency</th>\n",
       "      <th>number_inpatient</th>\n",
       "      <th>number_diagnoses</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>count</th>\n",
       "      <td>1.017660e+05</td>\n",
       "      <td>1.017660e+05</td>\n",
       "      <td>101766.000000</td>\n",
       "      <td>101766.000000</td>\n",
       "      <td>101766.000000</td>\n",
       "      <td>101766.000000</td>\n",
       "      <td>101766.000000</td>\n",
       "      <td>101766.000000</td>\n",
       "      <td>101766.000000</td>\n",
       "      <td>101766.000000</td>\n",
       "      <td>101766.000000</td>\n",
       "      <td>101766.000000</td>\n",
       "      <td>101766.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>mean</th>\n",
       "      <td>1.652016e+08</td>\n",
       "      <td>5.433040e+07</td>\n",
       "      <td>2.024006</td>\n",
       "      <td>3.715642</td>\n",
       "      <td>5.754437</td>\n",
       "      <td>4.395987</td>\n",
       "      <td>43.095641</td>\n",
       "      <td>1.339730</td>\n",
       "      <td>16.021844</td>\n",
       "      <td>0.369357</td>\n",
       "      <td>0.197836</td>\n",
       "      <td>0.635566</td>\n",
       "      <td>7.422607</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>std</th>\n",
       "      <td>1.026403e+08</td>\n",
       "      <td>3.869636e+07</td>\n",
       "      <td>1.445403</td>\n",
       "      <td>5.280166</td>\n",
       "      <td>4.064081</td>\n",
       "      <td>2.985108</td>\n",
       "      <td>19.674362</td>\n",
       "      <td>1.705807</td>\n",
       "      <td>8.127566</td>\n",
       "      <td>1.267265</td>\n",
       "      <td>0.930472</td>\n",
       "      <td>1.262863</td>\n",
       "      <td>1.933600</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>min</th>\n",
       "      <td>1.252200e+04</td>\n",
       "      <td>1.350000e+02</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>1.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25%</th>\n",
       "      <td>8.496119e+07</td>\n",
       "      <td>2.341322e+07</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>2.000000</td>\n",
       "      <td>31.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>10.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>6.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>50%</th>\n",
       "      <td>1.523890e+08</td>\n",
       "      <td>4.550514e+07</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>7.000000</td>\n",
       "      <td>4.000000</td>\n",
       "      <td>44.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>15.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>8.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>75%</th>\n",
       "      <td>2.302709e+08</td>\n",
       "      <td>8.754595e+07</td>\n",
       "      <td>3.000000</td>\n",
       "      <td>4.000000</td>\n",
       "      <td>7.000000</td>\n",
       "      <td>6.000000</td>\n",
       "      <td>57.000000</td>\n",
       "      <td>2.000000</td>\n",
       "      <td>20.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>9.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>max</th>\n",
       "      <td>4.438672e+08</td>\n",
       "      <td>1.895026e+08</td>\n",
       "      <td>8.000000</td>\n",
       "      <td>28.000000</td>\n",
       "      <td>25.000000</td>\n",
       "      <td>14.000000</td>\n",
       "      <td>132.000000</td>\n",
       "      <td>6.000000</td>\n",
       "      <td>81.000000</td>\n",
       "      <td>42.000000</td>\n",
       "      <td>76.000000</td>\n",
       "      <td>21.000000</td>\n",
       "      <td>16.000000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "       encounter_id   patient_nbr  admission_type_id  \\\n",
       "count  1.017660e+05  1.017660e+05      101766.000000   \n",
       "mean   1.652016e+08  5.433040e+07           2.024006   \n",
       "std    1.026403e+08  3.869636e+07           1.445403   \n",
       "min    1.252200e+04  1.350000e+02           1.000000   \n",
       "25%    8.496119e+07  2.341322e+07           1.000000   \n",
       "50%    1.523890e+08  4.550514e+07           1.000000   \n",
       "75%    2.302709e+08  8.754595e+07           3.000000   \n",
       "max    4.438672e+08  1.895026e+08           8.000000   \n",
       "\n",
       "       discharge_disposition_id  admission_source_id  time_in_hospital  \\\n",
       "count             101766.000000        101766.000000     101766.000000   \n",
       "mean                   3.715642             5.754437          4.395987   \n",
       "std                    5.280166             4.064081          2.985108   \n",
       "min                    1.000000             1.000000          1.000000   \n",
       "25%                    1.000000             1.000000          2.000000   \n",
       "50%                    1.000000             7.000000          4.000000   \n",
       "75%                    4.000000             7.000000          6.000000   \n",
       "max                   28.000000            25.000000         14.000000   \n",
       "\n",
       "       num_lab_procedures  num_procedures  num_medications  number_outpatient  \\\n",
       "count       101766.000000   101766.000000    101766.000000      101766.000000   \n",
       "mean            43.095641        1.339730        16.021844           0.369357   \n",
       "std             19.674362        1.705807         8.127566           1.267265   \n",
       "min              1.000000        0.000000         1.000000           0.000000   \n",
       "25%             31.000000        0.000000        10.000000           0.000000   \n",
       "50%             44.000000        1.000000        15.000000           0.000000   \n",
       "75%             57.000000        2.000000        20.000000           0.000000   \n",
       "max            132.000000        6.000000        81.000000          42.000000   \n",
       "\n",
       "       number_emergency  number_inpatient  number_diagnoses  \n",
       "count     101766.000000     101766.000000     101766.000000  \n",
       "mean           0.197836          0.635566          7.422607  \n",
       "std            0.930472          1.262863          1.933600  \n",
       "min            0.000000          0.000000          1.000000  \n",
       "25%            0.000000          0.000000          6.000000  \n",
       "50%            0.000000          0.000000          8.000000  \n",
       "75%            0.000000          1.000000          9.000000  \n",
       "max           76.000000         21.000000         16.000000  "
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_clean.describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "6d140a4d-da7c-41d0-8890-54c4f35d3405",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['encounter_id', 'patient_nbr', 'race', 'gender', 'age', 'weight', 'admission_type_id', 'discharge_disposition_id', 'admission_source_id', 'time_in_hospital', 'payer_code', 'medical_specialty', 'num_lab_procedures', 'num_procedures', 'num_medications', 'number_outpatient', 'number_emergency', 'number_inpatient', 'diag_1', 'diag_2', 'diag_3', 'number_diagnoses', 'max_glu_serum', 'A1Cresult', 'metformin', 'repaglinide', 'nateglinide', 'chlorpropamide', 'glimepiride', 'acetohexamide', 'glipizide', 'glyburide', 'tolbutamide', 'pioglitazone', 'rosiglitazone', 'acarbose', 'miglitol', 'troglitazone', 'tolazamide', 'examide', 'citoglipton', 'insulin', 'glyburide-metformin', 'glipizide-metformin', 'glimepiride-pioglitazone', 'metformin-rosiglitazone', 'metformin-pioglitazone', 'change', 'diabetesMed', 'readmitted']\n"
     ]
    }
   ],
   "source": [
    "print(list(df_clean))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "afc4d879",
   "metadata": {},
   "source": [
    "Data Cleaning "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "63b3c087-2e7b-4086-bc7a-4d2f5420f08e",
   "metadata": {},
   "outputs": [],
   "source": [
    "#REMOVING DUPLICATE DATA'S\n",
    "df_clean['patient_nbr'].value_counts()\n",
    "df_clean = df_clean.drop_duplicates(subset=['patient_nbr'])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "215ec990",
   "metadata": {},
   "source": [
    "There are 30,248 total of Duplicate Data's which the unique data consist only 71,518"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "1bca7cd8-29bc-472c-89ae-75e1512ab0c8",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "Index: 71518 entries, 0 to 101765\n",
      "Data columns (total 50 columns):\n",
      " #   Column                    Non-Null Count  Dtype \n",
      "---  ------                    --------------  ----- \n",
      " 0   encounter_id              71518 non-null  int64 \n",
      " 1   patient_nbr               71518 non-null  int64 \n",
      " 2   race                      71518 non-null  object\n",
      " 3   gender                    71518 non-null  object\n",
      " 4   age                       71518 non-null  object\n",
      " 5   weight                    71518 non-null  object\n",
      " 6   admission_type_id         71518 non-null  int64 \n",
      " 7   discharge_disposition_id  71518 non-null  int64 \n",
      " 8   admission_source_id       71518 non-null  int64 \n",
      " 9   time_in_hospital          71518 non-null  int64 \n",
      " 10  payer_code                71518 non-null  object\n",
      " 11  medical_specialty         71518 non-null  object\n",
      " 12  num_lab_procedures        71518 non-null  int64 \n",
      " 13  num_procedures            71518 non-null  int64 \n",
      " 14  num_medications           71518 non-null  int64 \n",
      " 15  number_outpatient         71518 non-null  int64 \n",
      " 16  number_emergency          71518 non-null  int64 \n",
      " 17  number_inpatient          71518 non-null  int64 \n",
      " 18  diag_1                    71518 non-null  object\n",
      " 19  diag_2                    71518 non-null  object\n",
      " 20  diag_3                    71518 non-null  object\n",
      " 21  number_diagnoses          71518 non-null  int64 \n",
      " 22  max_glu_serum             71518 non-null  object\n",
      " 23  A1Cresult                 71518 non-null  object\n",
      " 24  metformin                 71518 non-null  object\n",
      " 25  repaglinide               71518 non-null  object\n",
      " 26  nateglinide               71518 non-null  object\n",
      " 27  chlorpropamide            71518 non-null  object\n",
      " 28  glimepiride               71518 non-null  object\n",
      " 29  acetohexamide             71518 non-null  object\n",
      " 30  glipizide                 71518 non-null  object\n",
      " 31  glyburide                 71518 non-null  object\n",
      " 32  tolbutamide               71518 non-null  object\n",
      " 33  pioglitazone              71518 non-null  object\n",
      " 34  rosiglitazone             71518 non-null  object\n",
      " 35  acarbose                  71518 non-null  object\n",
      " 36  miglitol                  71518 non-null  object\n",
      " 37  troglitazone              71518 non-null  object\n",
      " 38  tolazamide                71518 non-null  object\n",
      " 39  examide                   71518 non-null  object\n",
      " 40  citoglipton               71518 non-null  object\n",
      " 41  insulin                   71518 non-null  object\n",
      " 42  glyburide-metformin       71518 non-null  object\n",
      " 43  glipizide-metformin       71518 non-null  object\n",
      " 44  glimepiride-pioglitazone  71518 non-null  object\n",
      " 45  metformin-rosiglitazone   71518 non-null  object\n",
      " 46  metformin-pioglitazone    71518 non-null  object\n",
      " 47  change                    71518 non-null  object\n",
      " 48  diabetesMed               71518 non-null  object\n",
      " 49  readmitted                71518 non-null  object\n",
      "dtypes: int64(13), object(37)\n",
      "memory usage: 27.8+ MB\n"
     ]
    }
   ],
   "source": [
    "df_clean.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "fa05a2a5",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "metformin\n",
      "No        56527\n",
      "Steady    13718\n",
      "Up          838\n",
      "Down        435\n",
      "Name: count, dtype: int64\n",
      "-----------------------------\n",
      "repaglinide\n",
      "No        70592\n",
      "Steady      824\n",
      "Up           73\n",
      "Down         29\n",
      "Name: count, dtype: int64\n",
      "-----------------------------\n",
      "nateglinide\n",
      "No        71020\n",
      "Steady      474\n",
      "Up           16\n",
      "Down          8\n",
      "Name: count, dtype: int64\n",
      "-----------------------------\n",
      "chlorpropamide\n",
      "No        71446\n",
      "Steady       67\n",
      "Up            4\n",
      "Down          1\n",
      "Name: count, dtype: int64\n"
     ]
    }
   ],
   "source": [
    "print(df_clean['metformin'].value_counts())\n",
    "print(\"-----------------------------\")\n",
    "print(df_clean['repaglinide'].value_counts())\n",
    "print(\"-----------------------------\")\n",
    "print(df_clean['nateglinide'].value_counts())\n",
    "print(\"-----------------------------\")\n",
    "print(df_clean['chlorpropamide'].value_counts())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "a937c13b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "glimepiride\n",
      "No        67773\n",
      "Steady     3372\n",
      "Up          235\n",
      "Down        138\n",
      "Name: count, dtype: int64\n",
      "-----------------------------\n",
      "acetohexamide\n",
      "No        71517\n",
      "Steady        1\n",
      "Name: count, dtype: int64\n",
      "-----------------------------\n",
      "glipizide\n",
      "No        62412\n",
      "Steady     8150\n",
      "Up          578\n",
      "Down        378\n",
      "Name: count, dtype: int64\n",
      "-----------------------------\n",
      "glyburide\n",
      "No        63664\n",
      "Steady     6812\n",
      "Up          621\n",
      "Down        421\n",
      "Name: count, dtype: int64\n"
     ]
    }
   ],
   "source": [
    "print(df_clean['glimepiride'].value_counts())\n",
    "print(\"-----------------------------\")\n",
    "print(df_clean['acetohexamide'].value_counts())\n",
    "print(\"-----------------------------\")\n",
    "print(df_clean['glipizide'].value_counts())\n",
    "print(\"-----------------------------\")\n",
    "print(df_clean['glyburide'].value_counts())\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "b77cbf2f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tolbutamide\n",
      "No        71499\n",
      "Steady       19\n",
      "Name: count, dtype: int64\n",
      "-----------------------------\n",
      "pioglitazone\n",
      "No        66210\n",
      "Steady     5047\n",
      "Up          180\n",
      "Down         81\n",
      "Name: count, dtype: int64\n",
      "-----------------------------\n",
      "rosiglitazone\n",
      "No        66817\n",
      "Steady     4490\n",
      "Up          136\n",
      "Down         75\n",
      "Name: count, dtype: int64\n",
      "-----------------------------\n",
      "acarbose\n",
      "No        71316\n",
      "Steady      192\n",
      "Up           10\n",
      "Name: count, dtype: int64\n"
     ]
    }
   ],
   "source": [
    "print(df_clean['tolbutamide'].value_counts())\n",
    "print(\"-----------------------------\")\n",
    "print(df_clean['pioglitazone'].value_counts())\n",
    "print(\"-----------------------------\")\n",
    "print(df_clean['rosiglitazone'].value_counts())\n",
    "print(\"-----------------------------\")\n",
    "print(df_clean['acarbose'].value_counts())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "685bd26e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "miglitol\n",
      "No        71498\n",
      "Steady       18\n",
      "Down          1\n",
      "Up            1\n",
      "Name: count, dtype: int64\n",
      "-----------------------------\n",
      "troglitazone\n",
      "No        71515\n",
      "Steady        3\n",
      "Name: count, dtype: int64\n",
      "-----------------------------\n",
      "tolazamide\n",
      "No        71488\n",
      "Steady       30\n",
      "Name: count, dtype: int64\n",
      "-----------------------------\n",
      "examide\n",
      "No    71518\n",
      "Name: count, dtype: int64\n"
     ]
    }
   ],
   "source": [
    "print(df_clean['miglitol'].value_counts())\n",
    "print(\"-----------------------------\")\n",
    "print(df_clean['troglitazone'].value_counts())\n",
    "print(\"-----------------------------\")\n",
    "print(df_clean['tolazamide'].value_counts())\n",
    "print(\"-----------------------------\")\n",
    "print(df_clean['examide'].value_counts())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "94e8826b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "citoglipton\n",
      "No    71518\n",
      "Name: count, dtype: int64\n",
      "-----------------------------\n",
      "insulin\n",
      "No        34921\n",
      "Steady    22129\n",
      "Down       7505\n",
      "Up         6963\n",
      "Name: count, dtype: int64\n",
      "-----------------------------\n",
      "glyburide-metformin\n",
      "No        71016\n",
      "Steady      491\n",
      "Up            7\n",
      "Down          4\n",
      "Name: count, dtype: int64\n",
      "-----------------------------\n",
      "glipizide-metformin\n",
      "No        71511\n",
      "Steady        7\n",
      "Name: count, dtype: int64\n"
     ]
    }
   ],
   "source": [
    "print(df_clean['citoglipton'].value_counts())\n",
    "print(\"-----------------------------\")\n",
    "print(df_clean['insulin'].value_counts())\n",
    "print(\"-----------------------------\")\n",
    "print(df_clean['glyburide-metformin'].value_counts())\n",
    "print(\"-----------------------------\")\n",
    "print(df_clean['glipizide-metformin'].value_counts())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "e52eb279",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "glimepiride-pioglitazone\n",
      "No    71518\n",
      "Name: count, dtype: int64\n",
      "-----------------------------\n",
      "metformin-rosiglitazone\n",
      "No        71516\n",
      "Steady        2\n",
      "Name: count, dtype: int64\n",
      "-----------------------------\n",
      "metformin-pioglitazone\n",
      "No        71517\n",
      "Steady        1\n",
      "Name: count, dtype: int64\n"
     ]
    }
   ],
   "source": [
    "print(df_clean['glimepiride-pioglitazone'].value_counts())\n",
    "print(\"-----------------------------\")\n",
    "print(df_clean['metformin-rosiglitazone'].value_counts())\n",
    "print(\"-----------------------------\")\n",
    "print(df_clean['metformin-pioglitazone'].value_counts())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "a9c81d85",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "medical_specialty\n",
       "?                                   48.207444\n",
       "InternalMedicine                    15.267485\n",
       "Family/GeneralPractice               7.156240\n",
       "Emergency/Trauma                     6.243184\n",
       "Cardiology                           5.964932\n",
       "                                      ...    \n",
       "SportsMedicine                       0.001398\n",
       "Dermatology                          0.001398\n",
       "Proctology                           0.001398\n",
       "Surgery-PlasticwithinHeadandNeck     0.001398\n",
       "Resident                             0.001398\n",
       "Name: proportion, Length: 71, dtype: float64"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "(df_clean.medical_specialty.value_counts(normalize=True, dropna=False) * 100)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3cead83d",
   "metadata": {},
   "source": [
    "Removing features that is not useful for our target readmittied\n",
    "\n",
    "encounter_id  > Irrelevant \n",
    "\n",
    "Patient_nbr > Irrelevant\n",
    "\n",
    "Weight > Consist of 97% missing value\n",
    "\n",
    "Payer_code > Irrelevant\n",
    "\n",
    "Medicial_Speciality > 48% missing value\n",
    "\n",
    "Repaglinide\t> 71K samples not using the drug\n",
    "\n",
    "Nateglinide\t> 71K samples not using the drug\n",
    "\n",
    "Chlorpropamide > 71K samples not using the drug\n",
    "\n",
    "Acarbose > 71k samples not using the drug\n",
    "\n",
    "Miglitol > 71k samples not using the drug\n",
    "\n",
    "Troglitazone > Only 3 patients using the drug\n",
    "\n",
    "Tolazamide > Only 39 patients using the drug\n",
    "\n",
    "Examide\t> All patients not using the drug\n",
    "\n",
    "Citoglipton\t> All patients not using the drug\n",
    "\n",
    "Glyburide_metformin\t> 71k samples not using the drug\n",
    "\n",
    "Glipizide_metfotmin > Only 13 patients using the drug\n",
    "\n",
    "Glimepiride_pioglitazone > Only 1 patient using the drug\n",
    "\n",
    "Metformin_rosiglitazone > Only 2 patients using the drug\n",
    "\n",
    "Metformin_pioglitazone > Only 1 patient using the drug\n",
    "\n",
    "Acetohexamide > Only 1 patient using the drug\n",
    "\n",
    "tolbutamide > Only 23 patients using the drug\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "d4b2a6e2-c9e2-4380-bdf4-0b45a6047333",
   "metadata": {},
   "outputs": [],
   "source": [
    "features_drop_list = ['encounter_id', 'patient_nbr', 'weight', 'payer_code', 'medical_specialty', 'repaglinide', 'nateglinide', 'chlorpropamide', 'acarbose', 'miglitol', 'troglitazone', 'tolazamide', 'examide', 'citoglipton', 'glyburide-metformin', 'glipizide-metformin', 'glimepiride-pioglitazone', 'metformin-rosiglitazone','metformin-pioglitazone', 'acetohexamide', 'tolbutamide']\n",
    "df_clean.drop(features_drop_list, axis=1, inplace=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f4e9bc5b",
   "metadata": {},
   "source": [
    "ICD 9 codes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "b1729aef-e47e-4b74-bd68-b7bcd4f0f896",
   "metadata": {},
   "outputs": [],
   "source": [
    "#start by setting all values containing E or V into 0 (as one category)\n",
    "df_clean.loc[df_clean['diag_1'].str.contains('V',na=False,case=False), 'diag_1'] = 0\n",
    "df_clean.loc[df_clean['diag_1'].str.contains('E',na=False,case=False), 'diag_1'] = 0\n",
    "df_clean.loc[df_clean['diag_2'].str.contains('V',na=False,case=False), 'diag_2'] = 0\n",
    "df_clean.loc[df_clean['diag_2'].str.contains('E',na=False,case=False), 'diag_2'] = 0\n",
    "df_clean.loc[df_clean['diag_3'].str.contains('V',na=False,case=False), 'diag_3'] = 0\n",
    "df_clean.loc[df_clean['diag_3'].str.contains('E',na=False,case=False), 'diag_3'] = 0\n",
    "\n",
    "#setting all missing values into -1\n",
    "df_clean['diag_1'] = df_clean['diag_1'].replace('?', -1)\n",
    "df_clean['diag_2'] = df_clean['diag_2'].replace('?', -1)\n",
    "df_clean['diag_3'] = df_clean['diag_3'].replace('?', -1)\n",
    "\n",
    "#No all diag values can be converted into numeric values\n",
    "df_clean['diag_1'] = df_clean['diag_1'].astype(float)\n",
    "df_clean['diag_2'] = df_clean['diag_2'].astype(float)\n",
    "df_clean['diag_3'] = df_clean['diag_3'].astype(float)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "9b38dcdd",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "   diag_1  diag_2  diag_3\n",
      "0     3.0     0.0     0.0\n",
      "1     3.0     3.0     3.0\n",
      "2    11.0     3.0     0.0\n",
      "3     1.0     3.0     7.0\n",
      "4     2.0     2.0     3.0\n"
     ]
    }
   ],
   "source": [
    "# Ensure 'diag_1', 'diag_2', 'diag_3' are numeric\n",
    "df_clean[['diag_1', 'diag_2', 'diag_3']] = df_clean[['diag_1', 'diag_2', 'diag_3']].apply(pd.to_numeric, errors='coerce')\n",
    "\n",
    "def categorize_diag(df_clean, col):\n",
    "    df_clean.loc[(df_clean[col] >= 1) & (df_clean[col] < 140), col] = 1\n",
    "    df_clean.loc[(df_clean[col] >= 140) & (df_clean[col] < 240), col] = 2\n",
    "    df_clean.loc[(df_clean[col] >= 240) & (df_clean[col] < 280), col] = 3\n",
    "    df_clean.loc[(df_clean[col] >= 280) & (df_clean[col] < 290), col] = 4\n",
    "    df_clean.loc[(df_clean[col] >= 290) & (df_clean[col] < 320), col] = 5\n",
    "    df_clean.loc[(df_clean[col] >= 320) & (df_clean[col] < 390), col] = 6\n",
    "    df_clean.loc[(df_clean[col] >= 390) & (df_clean[col] < 460), col] = 7\n",
    "    df_clean.loc[(df_clean[col] >= 460) & (df_clean[col] < 520), col] = 8\n",
    "    df_clean.loc[(df_clean[col] >= 520) & (df_clean[col] < 580), col] = 9\n",
    "    df_clean.loc[(df_clean[col] >= 580) & (df_clean[col] < 630), col] = 10\n",
    "    df_clean.loc[(df_clean[col] >= 630) & (df_clean[col] < 680), col] = 11\n",
    "    df_clean.loc[(df_clean[col] >= 680) & (df_clean[col] < 710), col] = 12\n",
    "    df_clean.loc[(df_clean[col] >= 710) & (df_clean[col] < 740), col] = 13\n",
    "    df_clean.loc[(df_clean[col] >= 740) & (df_clean[col] < 760), col] = 14\n",
    "    df_clean.loc[(df_clean[col] >= 760) & (df_clean[col] < 780), col] = 15\n",
    "    df_clean.loc[(df_clean[col] >= 780) & (df_clean[col] < 800), col] = 16\n",
    "    df_clean.loc[(df_clean[col] >= 800) & (df_clean[col] < 1000), col] = 17\n",
    "    df_clean.loc[df_clean[col] == -1, col] = 0  # Handle missing values\n",
    "    \n",
    "# Apply function to diagnosis columns\n",
    "for col in ['diag_1', 'diag_2', 'diag_3']:\n",
    "    categorize_diag(df_clean, col)\n",
    "\n",
    "# Print the result\n",
    "print(df_clean[['diag_1', 'diag_2', 'diag_3']].head())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "683674e6",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0          0.0\n",
      "1          3.0\n",
      "2          3.0\n",
      "3          3.0\n",
      "4          2.0\n",
      "          ... \n",
      "101754     9.0\n",
      "101755    10.0\n",
      "101756    10.0\n",
      "101758     1.0\n",
      "101765     9.0\n",
      "Name: diag_2, Length: 71518, dtype: float64\n"
     ]
    }
   ],
   "source": [
    "print(df_clean['diag_2'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "a498f8de",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([ 0.,  3.,  2.,  7.,  8.,  4., 17., 13., 10.,  1.,  9., 12.,  6.,\n",
       "       16.,  5., 11., 14.])"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#check the results\n",
    "df_clean.diag_2.unique()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "63eeb9cf-5505-478c-b949-b5f71ce4f9c9",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "race\n",
       "Caucasian          53491\n",
       "AfricanAmerican    12887\n",
       "Other               3126\n",
       "Hispanic            1517\n",
       "Asian                497\n",
       "Name: count, dtype: int64"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_clean['race'] = df_clean['race'].replace('?', 'Other')\n",
    "df_clean.race.value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "7a695780-852d-4087-8cb5-5938dfca2120",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "gender\n",
       "Female    38028\n",
       "Male      33490\n",
       "Name: count, dtype: int64"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_clean['gender'] = df_clean['gender'].replace('Unknown/Invalid', 'Female')\n",
    "df_clean.gender.value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "8ea34506-7da3-4d4d-b62e-530f16e921f2",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\SnowPlay\\AppData\\Local\\Temp\\ipykernel_6420\\2177177959.py:2: FutureWarning: Downcasting behavior in `replace` is deprecated and will be removed in a future version. To retain the old behavior, explicitly call `result.infer_objects(copy=False)`. To opt-in to the future behavior, set `pd.set_option('future.no_silent_downcasting', True)`\n",
      "  df_clean['gender'] = df_clean['gender'].replace('Female', 0)\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "gender\n",
       "0    38028\n",
       "1    33490\n",
       "Name: count, dtype: int64"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_clean['gender'] = df_clean['gender'].replace('Male', 1)\n",
    "df_clean['gender'] = df_clean['gender'].replace('Female', 0)\n",
    "df_clean.gender.value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "992a430a-4e86-4fac-8dea-a43dcd878a23",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\SnowPlay\\AppData\\Local\\Temp\\ipykernel_6420\\856190937.py:7: FutureWarning: Downcasting behavior in `replace` is deprecated and will be removed in a future version. To retain the old behavior, explicitly call `result.infer_objects(copy=False)`. To opt-in to the future behavior, set `pd.set_option('future.no_silent_downcasting', True)`\n",
      "  df_clean['age'] = df_clean['age'].replace(age_replacements)\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "age\n",
       "75    18210\n",
       "65    15960\n",
       "55    12466\n",
       "85    11589\n",
       "45     6878\n",
       "35     2699\n",
       "95     1900\n",
       "25     1127\n",
       "15      535\n",
       "5       154\n",
       "Name: count, dtype: int64"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "age_replacements = {}\n",
    "for i in range(0, 10):\n",
    "    age_range = f'[{10*i}-{10*(i+1)})'\n",
    "    midpoint = i*10 + 5\n",
    "    age_replacements[age_range] = midpoint\n",
    "\n",
    "df_clean['age'] = df_clean['age'].replace(age_replacements)\n",
    "\n",
    "df_clean['age'].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "2adaab1c-287a-429a-af24-8cf3807ad94c",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "age\n",
       "75    18210\n",
       "65    15960\n",
       "55    12466\n",
       "85    11589\n",
       "45     6878\n",
       "35     2699\n",
       "95     1900\n",
       "25     1127\n",
       "15      535\n",
       "5       154\n",
       "Name: count, dtype: int64"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_clean['age'].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "bb554076",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\SnowPlay\\AppData\\Local\\Temp\\ipykernel_6420\\3891844975.py:3: FutureWarning: Downcasting behavior in `replace` is deprecated and will be removed in a future version. To retain the old behavior, explicitly call `result.infer_objects(copy=False)`. To opt-in to the future behavior, set `pd.set_option('future.no_silent_downcasting', True)`\n",
      "  df_clean['readmitted']=df_clean['readmitted'].replace('<30', 2)\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "readmitted\n",
       "0    42985\n",
       "1    22240\n",
       "2     6293\n",
       "Name: count, dtype: int64"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_clean['readmitted']=df_clean['readmitted'].replace('NO', 0)\n",
    "df_clean['readmitted']=df_clean['readmitted'].replace('>30', 1)\n",
    "df_clean['readmitted']=df_clean['readmitted'].replace('<30', 2)\n",
    "df_clean.readmitted.value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "4dccca70",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "   race_AfricanAmerican  race_Asian  race_Caucasian  race_Hispanic  race_Other\n",
      "0                     0           0               1              0           0\n",
      "1                     0           0               1              0           0\n",
      "2                     1           0               0              0           0\n",
      "3                     0           0               1              0           0\n",
      "4                     0           0               1              0           0\n"
     ]
    }
   ],
   "source": [
    "df_clean = pd.concat([df_clean,pd.get_dummies(df_clean['race'], prefix='race')], axis=1).drop(['race'],axis=1)\n",
    "\n",
    "race_columns = ['race_AfricanAmerican', 'race_Asian', 'race_Caucasian', 'race_Hispanic', 'race_Other']\n",
    "df_clean[race_columns] = df_clean[race_columns].astype(int)\n",
    "# Check the changes\n",
    "print(df_clean[race_columns].head())"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ee6053a2",
   "metadata": {},
   "source": [
    "-- Algorithm --"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "8db28a23-d17d-47c9-a9c7-a97fd9d615d5",
   "metadata": {},
   "outputs": [],
   "source": [
    "X = df_clean.drop('readmitted', axis=1)  # Features\n",
    "y = df_clean['readmitted']               # Target variable\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "b89ce05b",
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train, X_test, y_train, y_test = train_test_split(\n",
    "    X, \n",
    "    y,\n",
    "    test_size=0.2,  # 20% for testing\n",
    "    random_state=42,  # for reproducibility\n",
    "    stratify=y  # ensure balanced split of target classes\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "09dba003",
   "metadata": {},
   "outputs": [],
   "source": [
    "cat_features = X.select_dtypes(include=['object']).columns.tolist()\n",
    "X[cat_features] = X[cat_features].astype(str)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "3fc0aff4",
   "metadata": {},
   "outputs": [],
   "source": [
    "gpu_available = \"NVIDIA_VISIBLE_DEVICES\" in os.environ or \"CUDA_VISIBLE_DEVICES\" in os.environ\n",
    "task_type = 'GPU' if gpu_available else 'CPU'\n",
    "\n",
    "class CatBoostMulticlassOptimizer:\n",
    "    def __init__(self, X_train, y_train, cat_features, eval_metric, n_splits=3, random_state=42, gpu_id=0):\n",
    "        \"\"\"\n",
    "        Initialize the CatBoost Multiclass Optimizer with memory-efficient settings.\n",
    "        \"\"\"\n",
    "        self.X_train = X_train\n",
    "        self.y_train = y_train\n",
    "        self.cat_features = cat_features\n",
    "        self.eval_metric = eval_metric\n",
    "        self.n_splits = n_splits  # Reduced from 5 to 3\n",
    "        self.random_state = random_state\n",
    "        self.gpu_id = gpu_id\n",
    "        self.n_classes = len(np.unique(y_train))\n",
    "        \n",
    "        # Validate input data\n",
    "        self._validate_inputs()\n",
    "        \n",
    "    def _validate_inputs(self):\n",
    "        if not isinstance(self.X_train, pd.DataFrame):\n",
    "            raise TypeError(\"X_train must be a pandas DataFrame\")\n",
    "            \n",
    "        if not all(col in self.X_train.columns for col in self.cat_features):\n",
    "            raise ValueError(\"Some categorical features not found in X_train\")\n",
    "            \n",
    "        if self.eval_metric not in ['f1', 'auc', 'accuracy']:\n",
    "            raise ValueError(\"eval_metric must be one of: 'f1', 'auc', 'accuracy'\")\n",
    "            \n",
    "        if self.n_classes < 2:\n",
    "            raise ValueError(\"Number of classes must be at least 2\")\n",
    "    \n",
    "    def _get_metric_score(self, y_true, y_pred, y_prob=None):\n",
    "        if self.eval_metric == 'f1':\n",
    "            return f1_score(y_true, y_pred, average='weighted')\n",
    "        elif self.eval_metric == 'auc':\n",
    "            if self.n_classes == 2:\n",
    "                return roc_auc_score(y_true, y_prob[:, 1])\n",
    "            else:\n",
    "                return roc_auc_score(y_true, y_prob, multi_class='ovr')\n",
    "        else:  # accuracy\n",
    "            return accuracy_score(y_true, y_pred)\n",
    "    \n",
    "    def _get_catboost_params(self, iterations, learning_rate, depth, l2_leaf_reg):\n",
    "        \"\"\"Simplified parameters without border_count\"\"\"\n",
    "        params = {\n",
    "            'iterations': int(iterations),\n",
    "            'learning_rate': float(learning_rate),\n",
    "            'depth': int(depth),\n",
    "            'l2_leaf_reg': float(l2_leaf_reg),\n",
    "            'random_state': self.random_state,\n",
    "            'verbose': False,\n",
    "            'task_type': task_type,\n",
    "            'devices': f'{self.gpu_id}' if task_type == 'GPU' else None,\n",
    "            'loss_function': 'MultiClass' if self.n_classes > 2 else 'Logloss',\n",
    "            'eval_metric': 'MultiClass' if self.n_classes > 2 else 'Logloss',\n",
    "            'classes_count': self.n_classes if self.n_classes > 2 else None,\n",
    "            'bootstrap_type': 'Bernoulli',\n",
    "            'subsample': 0.8,  # Use 80% of data for each tree\n",
    "            'max_bin': 32  # Reduced from default 254\n",
    "        }\n",
    "        return params\n",
    "        \n",
    "    def _objective(self, iterations, learning_rate, depth, l2_leaf_reg):\n",
    "        \"\"\"Simplified objective function\"\"\"\n",
    "        try:\n",
    "            params = self._get_catboost_params(iterations, learning_rate, depth, l2_leaf_reg)\n",
    "            \n",
    "            skf = StratifiedKFold(n_splits=self.n_splits, shuffle=True, random_state=self.random_state)\n",
    "            scores = []\n",
    "            \n",
    "            for train_idx, val_idx in skf.split(self.X_train, self.y_train):\n",
    "                X_fold_train = self.X_train.iloc[train_idx]\n",
    "                y_fold_train = self.y_train[train_idx]\n",
    "                X_fold_val = self.X_train.iloc[val_idx]\n",
    "                y_fold_val = self.y_train[val_idx]\n",
    "                \n",
    "                train_pool = Pool(\n",
    "                    data=X_fold_train,\n",
    "                    label=y_fold_train,\n",
    "                    cat_features=self.cat_features\n",
    "                )\n",
    "                val_pool = Pool(\n",
    "                    data=X_fold_val,\n",
    "                    label=y_fold_val,\n",
    "                    cat_features=self.cat_features\n",
    "                )\n",
    "                \n",
    "                model = CatBoostClassifier(**params)\n",
    "                model.fit(train_pool, eval_set=val_pool, early_stopping_rounds=20, verbose=False)\n",
    "                \n",
    "                y_prob = model.predict_proba(X_fold_val)\n",
    "                y_pred = np.argmax(y_prob, axis=1)\n",
    "                \n",
    "                score = self._get_metric_score(y_fold_val, y_pred, y_prob)\n",
    "                scores.append(score)\n",
    "\n",
    "            return np.mean(scores)\n",
    "            \n",
    "        except Exception as e:\n",
    "            print(f\"Error in optimization: {str(e)}\")\n",
    "            return 0.0\n",
    "    \n",
    "    def optimize(self, n_iter=20, n_init_points=5):\n",
    "        \"\"\"Reduced number of iterations and initial points\"\"\"\n",
    "        if n_iter <= n_init_points:\n",
    "            raise ValueError(\"n_iter must be greater than n_init_points\")\n",
    "        \n",
    "        # Simplified parameter bounds\n",
    "        pbounds = {\n",
    "            'iterations': (100, 500),  # Reduced range\n",
    "            'learning_rate': (0.01, 0.3),\n",
    "            'depth': (4, 8),  # Reduced range\n",
    "            'l2_leaf_reg': (1.0, 5.0)  # Reduced range\n",
    "        }\n",
    "        \n",
    "        try:\n",
    "            optimizer = BayesianOptimization(\n",
    "                f=self._objective,\n",
    "                pbounds=pbounds,\n",
    "                random_state=self.random_state\n",
    "            )\n",
    "            \n",
    "            optimizer.maximize(\n",
    "                init_points=n_init_points,\n",
    "                n_iter=n_iter,\n",
    "                acq='ei',  # Expected Improvement\n",
    "                xi=0.01    # Reduced exploration\n",
    "            )\n",
    "            \n",
    "            print(\"\\nBest parameters found:\")\n",
    "            best_params = optimizer.max['params']\n",
    "            for param, value in best_params.items():\n",
    "                if param in ['depth', 'iterations']:\n",
    "                    print(f\"{param}: {int(value)}\")\n",
    "                else:\n",
    "                    print(f\"{param}: {value:.4f}\")\n",
    "            print(f\"\\nBest CV {self.eval_metric} score: {optimizer.max['target']:.4f}\")\n",
    "        \n",
    "            return best_params\n",
    "            \n",
    "        except Exception as e:\n",
    "            print(f\"Optimization failed: {str(e)}\")\n",
    "            # Return default parameters if optimization fails\n",
    "            return {\n",
    "                'iterations': 300,\n",
    "                'learning_rate': 0.1,\n",
    "                'depth': 6,\n",
    "                'l2_leaf_reg': 3.0\n",
    "            }\n",
    "    \n",
    "    def train_final_model(self, best_params, test_size=0.2):\n",
    "        \"\"\"Train final model with memory-efficient settings\"\"\"\n",
    "        X_train_final, X_val_final, y_train_final, y_val_final = train_test_split(\n",
    "            self.X_train, self.y_train, test_size=test_size, \n",
    "            random_state=self.random_state, stratify=self.y_train\n",
    "        )\n",
    "        \n",
    "        train_pool = Pool(\n",
    "            data=X_train_final,\n",
    "            label=y_train_final,\n",
    "            cat_features=self.cat_features\n",
    "        )\n",
    "        val_pool = Pool(\n",
    "            data=X_val_final,\n",
    "            label=y_val_final,\n",
    "            cat_features=self.cat_features\n",
    "        )\n",
    "\n",
    "        final_params = self._get_catboost_params(\n",
    "            best_params['iterations'],\n",
    "            best_params['learning_rate'],\n",
    "            best_params['depth'],\n",
    "            best_params['l2_leaf_reg']\n",
    "        )\n",
    "        \n",
    "        final_params.update({\n",
    "            'verbose': 100,\n",
    "            'use_best_model': True\n",
    "        })\n",
    "\n",
    "        final_model = CatBoostClassifier(**final_params)\n",
    "        final_model.fit(\n",
    "            train_pool,\n",
    "            eval_set=val_pool,\n",
    "            early_stopping_rounds=20,\n",
    "            verbose=50\n",
    "        )\n",
    "        \n",
    "        y_val_pred = final_model.predict(X_val_final)\n",
    "        y_val_prob = final_model.predict_proba(X_val_final)\n",
    "        final_score = self._get_metric_score(y_val_final, y_val_pred, y_val_prob)\n",
    "        print(f\"\\nFinal validation {self.eval_metric} score: {final_score:.4f}\")\n",
    "        \n",
    "        return final_model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3a7adea1",
   "metadata": {},
   "outputs": [],
   "source": [
    "class ModelEvaluator:\n",
    "    def __init__(self, model, X_train, y_train, X_test, y_test, cat_features):\n",
    "        self.model = model\n",
    "        self.X_train = X_train\n",
    "        self.y_train = y_train\n",
    "        self.X_test = X_test\n",
    "        self.y_test = y_test\n",
    "        self.cat_features = cat_features\n",
    "        \n",
    "    def get_metrics(self):\n",
    "        \"\"\"Calculate all metrics for both training and test sets.\"\"\"\n",
    "        # Get predictions\n",
    "        y_train_pred = self.model.predict(self.X_train)\n",
    "        y_test_pred = self.model.predict(self.X_test)\n",
    "        \n",
    "        # Calculate metrics\n",
    "        metrics = {\n",
    "            'train': {\n",
    "                'accuracy': accuracy_score(self.y_train, y_train_pred),\n",
    "                'precision': precision_score(self.y_train, y_train_pred, average='weighted'),\n",
    "                'recall': recall_score(self.y_train, y_train_pred, average='weighted'),\n",
    "                'f1': f1_score(self.y_train, y_train_pred, average='weighted')\n",
    "            },\n",
    "            'test': {\n",
    "                'accuracy': accuracy_score(self.y_test, y_test_pred),\n",
    "                'precision': precision_score(self.y_test, y_test_pred, average='weighted'),\n",
    "                'recall': recall_score(self.y_test, y_test_pred, average='weighted'),\n",
    "                'f1': f1_score(self.y_test, y_test_pred, average='weighted')\n",
    "            }\n",
    "        }\n",
    "        return metrics\n",
    "    \n",
    "    def print_metrics(self):\n",
    "        \"\"\"Print all metrics in a formatted way.\"\"\"\n",
    "        metrics = self.get_metrics()\n",
    "        print(\"\\nModel Performance Metrics:\")\n",
    "        print(\"-------------------------\")\n",
    "        \n",
    "        for dataset in ['train', 'test']:\n",
    "            print(f\"\\n{dataset.capitalize()} Set Metrics:\")\n",
    "            for metric, value in metrics[dataset].items():\n",
    "                print(f\"{metric.capitalize()}: {value:.4f}\")\n",
    "        \n",
    "        # Print detailed classification report\n",
    "        print(\"\\nDetailed Classification Report (Test Set):\")\n",
    "        print(classification_report(\n",
    "            self.y_test,\n",
    "            self.model.predict(self.X_test),\n",
    "            target_names=['NO', '>30', '<30']  # your class names\n",
    "        ))\n",
    "        \n",
    "        # Print confusion matrix\n",
    "        print(\"\\nConfusion Matrix (Test Set):\")\n",
    "        cm = confusion_matrix(self.y_test, self.model.predict(self.X_test))\n",
    "        print(cm)\n",
    "    \n",
    "    def plot_learning_curves(self):\n",
    "        \"\"\"Plot learning curves from the model training.\"\"\"\n",
    "        if hasattr(self.model, 'evals_result_'):\n",
    "            results = self.model.evals_result_\n",
    "            plt.figure(figsize=(10, 6))\n",
    "            for metric in results['validation'].keys():\n",
    "                plt.plot(results['validation'][metric], label=f'validation {metric}')\n",
    "                if 'learn' in results:\n",
    "                    plt.plot(results['learn'][metric], label=f'train {metric}')\n",
    "            plt.xlabel('Iterations')\n",
    "            plt.ylabel('Score')\n",
    "            plt.title('Learning Curves')\n",
    "            plt.legend()\n",
    "            plt.grid(True)\n",
    "            plt.show()\n",
    "    \n",
    "    def plot_feature_importance(self):\n",
    "        \"\"\"Plot feature importance.\"\"\"\n",
    "        importance = self.model.feature_importances_\n",
    "        feature_names = self.X_train.columns\n",
    "        \n",
    "        # Sort feature importances in descending order\n",
    "        indices = np.argsort(importance)[::-1]\n",
    "        \n",
    "        # Plot\n",
    "        plt.figure(figsize=(12, 6))\n",
    "        plt.title('Feature Importances')\n",
    "        plt.bar(range(len(importance)), importance[indices])\n",
    "        plt.xticks(range(len(importance)), [feature_names[i] for i in indices], rotation=45, ha='right')\n",
    "        plt.tight_layout()\n",
    "        plt.show()\n",
    "    \n",
    "    def evaluate_all(self):\n",
    "        \"\"\"Run all evaluations and plots.\"\"\"\n",
    "        self.print_metrics()\n",
    "        self.plot_learning_curves()\n",
    "        self.plot_feature_importance()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "27e85083",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Optimization failed: BayesianOptimization.maximize() got an unexpected keyword argument 'acq'\n",
      "0:\tlearn: 1.0573708\ttest: 1.0574434\tbest: 1.0574434 (0)\ttotal: 93.1ms\tremaining: 27.8s\n",
      "50:\tlearn: 0.8359687\ttest: 0.8408840\tbest: 0.8408840 (50)\ttotal: 4.22s\tremaining: 20.6s\n",
      "100:\tlearn: 0.8267118\ttest: 0.8362656\tbest: 0.8362656 (100)\ttotal: 8.18s\tremaining: 16.1s\n",
      "150:\tlearn: 0.8144530\ttest: 0.8312603\tbest: 0.8312603 (150)\ttotal: 12.7s\tremaining: 12.5s\n",
      "200:\tlearn: 0.8056419\ttest: 0.8289846\tbest: 0.8289846 (200)\ttotal: 16.9s\tremaining: 8.34s\n",
      "250:\tlearn: 0.7995207\ttest: 0.8279642\tbest: 0.8279432 (247)\ttotal: 21.1s\tremaining: 4.12s\n",
      "299:\tlearn: 0.7947706\ttest: 0.8273734\tbest: 0.8273093 (291)\ttotal: 25.2s\tremaining: 0us\n",
      "\n",
      "bestTest = 0.8273093415\n",
      "bestIteration = 291\n",
      "\n",
      "Shrink model to first 292 iterations.\n",
      "\n",
      "Final validation f1 score: 0.5440\n"
     ]
    }
   ],
   "source": [
    "optimizer = CatBoostMulticlassOptimizer(\n",
    "    X_train=X_train,\n",
    "    y_train=y_train,\n",
    "    cat_features=cat_features,\n",
    "    eval_metric='f1',\n",
    "    n_splits=3  # Using fewer splits\n",
    ")\n",
    "\n",
    "# Run optimization with fewer iterations\n",
    "best_params = optimizer.optimize(n_iter=20, n_init_points=5)\n",
    "\n",
    "# Train final model\n",
    "final_model = optimizer.train_final_model(best_params)\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "874cb1a5",
   "metadata": {},
   "outputs": [
    {
     "ename": "ValueError",
     "evalue": "Target is multiclass but average='binary'. Please choose another average setting, one of [None, 'micro', 'macro', 'weighted'].",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[38], line 12\u001b[0m\n\u001b[0;32m      2\u001b[0m evaluator \u001b[38;5;241m=\u001b[39m ModelEvaluator(\n\u001b[0;32m      3\u001b[0m     model\u001b[38;5;241m=\u001b[39mfinal_model,\n\u001b[0;32m      4\u001b[0m     X_train\u001b[38;5;241m=\u001b[39mX_train,\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m      8\u001b[0m     cat_features\u001b[38;5;241m=\u001b[39mcat_features,\n\u001b[0;32m      9\u001b[0m )\n\u001b[0;32m     11\u001b[0m \u001b[38;5;66;03m# Run all evaluations\u001b[39;00m\n\u001b[1;32m---> 12\u001b[0m \u001b[43mevaluator\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mevaluate_all\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n",
      "Cell \u001b[1;32mIn[32], line 112\u001b[0m, in \u001b[0;36mModelEvaluator.evaluate_all\u001b[1;34m(self)\u001b[0m\n\u001b[0;32m    110\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21mevaluate_all\u001b[39m(\u001b[38;5;28mself\u001b[39m):\n\u001b[0;32m    111\u001b[0m \u001b[38;5;250m    \u001b[39m\u001b[38;5;124;03m\"\"\"Run all evaluations and plots.\"\"\"\u001b[39;00m\n\u001b[1;32m--> 112\u001b[0m     \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mprint_metrics\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    113\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mplot_learning_curves()\n\u001b[0;32m    114\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mplot_feature_importance()\n",
      "Cell \u001b[1;32mIn[32], line 104\u001b[0m, in \u001b[0;36mModelEvaluator.print_metrics\u001b[1;34m(self)\u001b[0m\n\u001b[0;32m    102\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21mprint_metrics\u001b[39m(\u001b[38;5;28mself\u001b[39m):\n\u001b[0;32m    103\u001b[0m \u001b[38;5;250m    \u001b[39m\u001b[38;5;124;03m\"\"\"Print all metrics in a formatted way.\"\"\"\u001b[39;00m\n\u001b[1;32m--> 104\u001b[0m     metrics \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mget_metrics\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    105\u001b[0m     \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;124mModel Performance Metrics:\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[0;32m    106\u001b[0m     \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m-------------------------\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n",
      "Cell \u001b[1;32mIn[32], line 95\u001b[0m, in \u001b[0;36mModelEvaluator.get_metrics\u001b[1;34m(self)\u001b[0m\n\u001b[0;32m     91\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21mget_metrics\u001b[39m(\u001b[38;5;28mself\u001b[39m) \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m>\u001b[39m \u001b[38;5;28mdict\u001b[39m:\n\u001b[0;32m     92\u001b[0m \u001b[38;5;250m    \u001b[39m\u001b[38;5;124;03m\"\"\"Calculate and return various performance metrics.\"\"\"\u001b[39;00m\n\u001b[0;32m     93\u001b[0m     metrics \u001b[38;5;241m=\u001b[39m {\n\u001b[0;32m     94\u001b[0m         \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mAccuracy\u001b[39m\u001b[38;5;124m'\u001b[39m: accuracy_score(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39my_test, \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39my_pred),\n\u001b[1;32m---> 95\u001b[0m         \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mPrecision\u001b[39m\u001b[38;5;124m'\u001b[39m: \u001b[43mprecision_score\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43my_test\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43my_pred\u001b[49m\u001b[43m)\u001b[49m,\n\u001b[0;32m     96\u001b[0m         \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mRecall\u001b[39m\u001b[38;5;124m'\u001b[39m: recall_score(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39my_test, \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39my_pred),\n\u001b[0;32m     97\u001b[0m         \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mF1 Score\u001b[39m\u001b[38;5;124m'\u001b[39m: f1_score(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39my_test, \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39my_pred),\n\u001b[0;32m     98\u001b[0m         \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mROC AUC\u001b[39m\u001b[38;5;124m'\u001b[39m: roc_auc_score(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39my_test, \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39my_pred_proba[:, \u001b[38;5;241m1\u001b[39m])\n\u001b[0;32m     99\u001b[0m     }\n\u001b[0;32m    100\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m metrics\n",
      "File \u001b[1;32md:\\optimizing-catboost-model-with-bayesian\\env\\Lib\\site-packages\\sklearn\\utils\\_param_validation.py:216\u001b[0m, in \u001b[0;36mvalidate_params.<locals>.decorator.<locals>.wrapper\u001b[1;34m(*args, **kwargs)\u001b[0m\n\u001b[0;32m    210\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[0;32m    211\u001b[0m     \u001b[38;5;28;01mwith\u001b[39;00m config_context(\n\u001b[0;32m    212\u001b[0m         skip_parameter_validation\u001b[38;5;241m=\u001b[39m(\n\u001b[0;32m    213\u001b[0m             prefer_skip_nested_validation \u001b[38;5;129;01mor\u001b[39;00m global_skip_validation\n\u001b[0;32m    214\u001b[0m         )\n\u001b[0;32m    215\u001b[0m     ):\n\u001b[1;32m--> 216\u001b[0m         \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mfunc\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    217\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m InvalidParameterError \u001b[38;5;28;01mas\u001b[39;00m e:\n\u001b[0;32m    218\u001b[0m     \u001b[38;5;66;03m# When the function is just a wrapper around an estimator, we allow\u001b[39;00m\n\u001b[0;32m    219\u001b[0m     \u001b[38;5;66;03m# the function to delegate validation to the estimator, but we replace\u001b[39;00m\n\u001b[0;32m    220\u001b[0m     \u001b[38;5;66;03m# the name of the estimator by the name of the function in the error\u001b[39;00m\n\u001b[0;32m    221\u001b[0m     \u001b[38;5;66;03m# message to avoid confusion.\u001b[39;00m\n\u001b[0;32m    222\u001b[0m     msg \u001b[38;5;241m=\u001b[39m re\u001b[38;5;241m.\u001b[39msub(\n\u001b[0;32m    223\u001b[0m         \u001b[38;5;124mr\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mparameter of \u001b[39m\u001b[38;5;124m\\\u001b[39m\u001b[38;5;124mw+ must be\u001b[39m\u001b[38;5;124m\"\u001b[39m,\n\u001b[0;32m    224\u001b[0m         \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mparameter of \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mfunc\u001b[38;5;241m.\u001b[39m\u001b[38;5;18m__qualname__\u001b[39m\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m must be\u001b[39m\u001b[38;5;124m\"\u001b[39m,\n\u001b[0;32m    225\u001b[0m         \u001b[38;5;28mstr\u001b[39m(e),\n\u001b[0;32m    226\u001b[0m     )\n",
      "File \u001b[1;32md:\\optimizing-catboost-model-with-bayesian\\env\\Lib\\site-packages\\sklearn\\metrics\\_classification.py:2247\u001b[0m, in \u001b[0;36mprecision_score\u001b[1;34m(y_true, y_pred, labels, pos_label, average, sample_weight, zero_division)\u001b[0m\n\u001b[0;32m   2079\u001b[0m \u001b[38;5;129m@validate_params\u001b[39m(\n\u001b[0;32m   2080\u001b[0m     {\n\u001b[0;32m   2081\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124my_true\u001b[39m\u001b[38;5;124m\"\u001b[39m: [\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124marray-like\u001b[39m\u001b[38;5;124m\"\u001b[39m, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124msparse matrix\u001b[39m\u001b[38;5;124m\"\u001b[39m],\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m   2106\u001b[0m     zero_division\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mwarn\u001b[39m\u001b[38;5;124m\"\u001b[39m,\n\u001b[0;32m   2107\u001b[0m ):\n\u001b[0;32m   2108\u001b[0m \u001b[38;5;250m    \u001b[39m\u001b[38;5;124;03m\"\"\"Compute the precision.\u001b[39;00m\n\u001b[0;32m   2109\u001b[0m \n\u001b[0;32m   2110\u001b[0m \u001b[38;5;124;03m    The precision is the ratio ``tp / (tp + fp)`` where ``tp`` is the number of\u001b[39;00m\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m   2245\u001b[0m \u001b[38;5;124;03m    array([0.5, 1. , 1. ])\u001b[39;00m\n\u001b[0;32m   2246\u001b[0m \u001b[38;5;124;03m    \"\"\"\u001b[39;00m\n\u001b[1;32m-> 2247\u001b[0m     p, _, _, _ \u001b[38;5;241m=\u001b[39m \u001b[43mprecision_recall_fscore_support\u001b[49m\u001b[43m(\u001b[49m\n\u001b[0;32m   2248\u001b[0m \u001b[43m        \u001b[49m\u001b[43my_true\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   2249\u001b[0m \u001b[43m        \u001b[49m\u001b[43my_pred\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   2250\u001b[0m \u001b[43m        \u001b[49m\u001b[43mlabels\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mlabels\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   2251\u001b[0m \u001b[43m        \u001b[49m\u001b[43mpos_label\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mpos_label\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   2252\u001b[0m \u001b[43m        \u001b[49m\u001b[43maverage\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43maverage\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   2253\u001b[0m \u001b[43m        \u001b[49m\u001b[43mwarn_for\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43m(\u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mprecision\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   2254\u001b[0m \u001b[43m        \u001b[49m\u001b[43msample_weight\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43msample_weight\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   2255\u001b[0m \u001b[43m        \u001b[49m\u001b[43mzero_division\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mzero_division\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   2256\u001b[0m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m   2257\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m p\n",
      "File \u001b[1;32md:\\optimizing-catboost-model-with-bayesian\\env\\Lib\\site-packages\\sklearn\\utils\\_param_validation.py:189\u001b[0m, in \u001b[0;36mvalidate_params.<locals>.decorator.<locals>.wrapper\u001b[1;34m(*args, **kwargs)\u001b[0m\n\u001b[0;32m    187\u001b[0m global_skip_validation \u001b[38;5;241m=\u001b[39m get_config()[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mskip_parameter_validation\u001b[39m\u001b[38;5;124m\"\u001b[39m]\n\u001b[0;32m    188\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m global_skip_validation:\n\u001b[1;32m--> 189\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mfunc\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    191\u001b[0m func_sig \u001b[38;5;241m=\u001b[39m signature(func)\n\u001b[0;32m    193\u001b[0m \u001b[38;5;66;03m# Map *args/**kwargs to the function signature\u001b[39;00m\n",
      "File \u001b[1;32md:\\optimizing-catboost-model-with-bayesian\\env\\Lib\\site-packages\\sklearn\\metrics\\_classification.py:1830\u001b[0m, in \u001b[0;36mprecision_recall_fscore_support\u001b[1;34m(y_true, y_pred, beta, labels, pos_label, average, warn_for, sample_weight, zero_division)\u001b[0m\n\u001b[0;32m   1661\u001b[0m \u001b[38;5;250m\u001b[39m\u001b[38;5;124;03m\"\"\"Compute precision, recall, F-measure and support for each class.\u001b[39;00m\n\u001b[0;32m   1662\u001b[0m \n\u001b[0;32m   1663\u001b[0m \u001b[38;5;124;03mThe precision is the ratio ``tp / (tp + fp)`` where ``tp`` is the number of\u001b[39;00m\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m   1827\u001b[0m \u001b[38;5;124;03m array([2, 2, 2]))\u001b[39;00m\n\u001b[0;32m   1828\u001b[0m \u001b[38;5;124;03m\"\"\"\u001b[39;00m\n\u001b[0;32m   1829\u001b[0m _check_zero_division(zero_division)\n\u001b[1;32m-> 1830\u001b[0m labels \u001b[38;5;241m=\u001b[39m \u001b[43m_check_set_wise_labels\u001b[49m\u001b[43m(\u001b[49m\u001b[43my_true\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43my_pred\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43maverage\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mlabels\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mpos_label\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m   1832\u001b[0m \u001b[38;5;66;03m# Calculate tp_sum, pred_sum, true_sum ###\u001b[39;00m\n\u001b[0;32m   1833\u001b[0m samplewise \u001b[38;5;241m=\u001b[39m average \u001b[38;5;241m==\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124msamples\u001b[39m\u001b[38;5;124m\"\u001b[39m\n",
      "File \u001b[1;32md:\\optimizing-catboost-model-with-bayesian\\env\\Lib\\site-packages\\sklearn\\metrics\\_classification.py:1613\u001b[0m, in \u001b[0;36m_check_set_wise_labels\u001b[1;34m(y_true, y_pred, average, labels, pos_label)\u001b[0m\n\u001b[0;32m   1611\u001b[0m         \u001b[38;5;28;01mif\u001b[39;00m y_type \u001b[38;5;241m==\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mmulticlass\u001b[39m\u001b[38;5;124m\"\u001b[39m:\n\u001b[0;32m   1612\u001b[0m             average_options\u001b[38;5;241m.\u001b[39mremove(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124msamples\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[1;32m-> 1613\u001b[0m         \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m(\n\u001b[0;32m   1614\u001b[0m             \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mTarget is \u001b[39m\u001b[38;5;132;01m%s\u001b[39;00m\u001b[38;5;124m but average=\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mbinary\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124m. Please \u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m   1615\u001b[0m             \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mchoose another average setting, one of \u001b[39m\u001b[38;5;132;01m%r\u001b[39;00m\u001b[38;5;124m.\u001b[39m\u001b[38;5;124m\"\u001b[39m \u001b[38;5;241m%\u001b[39m (y_type, average_options)\n\u001b[0;32m   1616\u001b[0m         )\n\u001b[0;32m   1617\u001b[0m \u001b[38;5;28;01melif\u001b[39;00m pos_label \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;129;01min\u001b[39;00m (\u001b[38;5;28;01mNone\u001b[39;00m, \u001b[38;5;241m1\u001b[39m):\n\u001b[0;32m   1618\u001b[0m     warnings\u001b[38;5;241m.\u001b[39mwarn(\n\u001b[0;32m   1619\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mNote that pos_label (set to \u001b[39m\u001b[38;5;132;01m%r\u001b[39;00m\u001b[38;5;124m) is ignored when \u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m   1620\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124maverage != \u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mbinary\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124m (got \u001b[39m\u001b[38;5;132;01m%r\u001b[39;00m\u001b[38;5;124m). You may use \u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m   1623\u001b[0m         \u001b[38;5;167;01mUserWarning\u001b[39;00m,\n\u001b[0;32m   1624\u001b[0m     )\n",
      "\u001b[1;31mValueError\u001b[0m: Target is multiclass but average='binary'. Please choose another average setting, one of [None, 'micro', 'macro', 'weighted']."
     ]
    }
   ],
   "source": [
    "# Initialize the evaluator\n",
    "evaluator = ModelEvaluator(\n",
    "    model=final_model,\n",
    "    X_train=X_train,\n",
    "    y_train=y_train,\n",
    "    X_test=X_test,\n",
    "    y_test=y_test,\n",
    "    cat_features=cat_features,\n",
    ")\n",
    "\n",
    "# Run all evaluations\n",
    "evaluator.evaluate_all()\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "env",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
