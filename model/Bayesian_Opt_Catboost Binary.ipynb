{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "---1---\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: pandas in d:\\optimizing-catboost-model-with-bayesian\\env\\lib\\site-packages (2.2.3)\n",
      "Requirement already satisfied: numpy>=1.23.2 in d:\\optimizing-catboost-model-with-bayesian\\env\\lib\\site-packages (from pandas) (1.26.4)\n",
      "Requirement already satisfied: python-dateutil>=2.8.2 in d:\\optimizing-catboost-model-with-bayesian\\env\\lib\\site-packages (from pandas) (2.9.0.post0)\n",
      "Requirement already satisfied: pytz>=2020.1 in d:\\optimizing-catboost-model-with-bayesian\\env\\lib\\site-packages (from pandas) (2024.2)\n",
      "Requirement already satisfied: tzdata>=2022.7 in d:\\optimizing-catboost-model-with-bayesian\\env\\lib\\site-packages (from pandas) (2024.2)\n",
      "Requirement already satisfied: six>=1.5 in d:\\optimizing-catboost-model-with-bayesian\\env\\lib\\site-packages (from python-dateutil>=2.8.2->pandas) (1.17.0)\n",
      "Note: you may need to restart the kernel to use updated packages.\n",
      "---2---\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "[notice] A new release of pip is available: 24.3.1 -> 25.0.1\n",
      "[notice] To update, run: python.exe -m pip install --upgrade pip\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: seaborn in d:\\optimizing-catboost-model-with-bayesian\\env\\lib\\site-packages (0.13.2)\n",
      "Requirement already satisfied: numpy!=1.24.0,>=1.20 in d:\\optimizing-catboost-model-with-bayesian\\env\\lib\\site-packages (from seaborn) (1.26.4)\n",
      "Requirement already satisfied: pandas>=1.2 in d:\\optimizing-catboost-model-with-bayesian\\env\\lib\\site-packages (from seaborn) (2.2.3)\n",
      "Requirement already satisfied: matplotlib!=3.6.1,>=3.4 in d:\\optimizing-catboost-model-with-bayesian\\env\\lib\\site-packages (from seaborn) (3.10.0)\n",
      "Requirement already satisfied: contourpy>=1.0.1 in d:\\optimizing-catboost-model-with-bayesian\\env\\lib\\site-packages (from matplotlib!=3.6.1,>=3.4->seaborn) (1.3.1)\n",
      "Requirement already satisfied: cycler>=0.10 in d:\\optimizing-catboost-model-with-bayesian\\env\\lib\\site-packages (from matplotlib!=3.6.1,>=3.4->seaborn) (0.12.1)\n",
      "Requirement already satisfied: fonttools>=4.22.0 in d:\\optimizing-catboost-model-with-bayesian\\env\\lib\\site-packages (from matplotlib!=3.6.1,>=3.4->seaborn) (4.55.3)\n",
      "Requirement already satisfied: kiwisolver>=1.3.1 in d:\\optimizing-catboost-model-with-bayesian\\env\\lib\\site-packages (from matplotlib!=3.6.1,>=3.4->seaborn) (1.4.7)\n",
      "Requirement already satisfied: packaging>=20.0 in d:\\optimizing-catboost-model-with-bayesian\\env\\lib\\site-packages (from matplotlib!=3.6.1,>=3.4->seaborn) (24.2)\n",
      "Requirement already satisfied: pillow>=8 in d:\\optimizing-catboost-model-with-bayesian\\env\\lib\\site-packages (from matplotlib!=3.6.1,>=3.4->seaborn) (11.0.0)\n",
      "Requirement already satisfied: pyparsing>=2.3.1 in d:\\optimizing-catboost-model-with-bayesian\\env\\lib\\site-packages (from matplotlib!=3.6.1,>=3.4->seaborn) (3.2.0)\n",
      "Requirement already satisfied: python-dateutil>=2.7 in d:\\optimizing-catboost-model-with-bayesian\\env\\lib\\site-packages (from matplotlib!=3.6.1,>=3.4->seaborn) (2.9.0.post0)\n",
      "Requirement already satisfied: pytz>=2020.1 in d:\\optimizing-catboost-model-with-bayesian\\env\\lib\\site-packages (from pandas>=1.2->seaborn) (2024.2)\n",
      "Requirement already satisfied: tzdata>=2022.7 in d:\\optimizing-catboost-model-with-bayesian\\env\\lib\\site-packages (from pandas>=1.2->seaborn) (2024.2)\n",
      "Requirement already satisfied: six>=1.5 in d:\\optimizing-catboost-model-with-bayesian\\env\\lib\\site-packages (from python-dateutil>=2.7->matplotlib!=3.6.1,>=3.4->seaborn) (1.17.0)\n",
      "Note: you may need to restart the kernel to use updated packages.\n",
      "---3---\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "[notice] A new release of pip is available: 24.3.1 -> 25.0.1\n",
      "[notice] To update, run: python.exe -m pip install --upgrade pip\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: scikit-learn in d:\\optimizing-catboost-model-with-bayesian\\env\\lib\\site-packages (1.6.1)\n",
      "Requirement already satisfied: numpy>=1.19.5 in d:\\optimizing-catboost-model-with-bayesian\\env\\lib\\site-packages (from scikit-learn) (1.26.4)\n",
      "Requirement already satisfied: scipy>=1.6.0 in d:\\optimizing-catboost-model-with-bayesian\\env\\lib\\site-packages (from scikit-learn) (1.14.1)\n",
      "Requirement already satisfied: joblib>=1.2.0 in d:\\optimizing-catboost-model-with-bayesian\\env\\lib\\site-packages (from scikit-learn) (1.4.2)\n",
      "Requirement already satisfied: threadpoolctl>=3.1.0 in d:\\optimizing-catboost-model-with-bayesian\\env\\lib\\site-packages (from scikit-learn) (3.5.0)\n",
      "Note: you may need to restart the kernel to use updated packages.\n",
      "---4---\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "[notice] A new release of pip is available: 24.3.1 -> 25.0.1\n",
      "[notice] To update, run: python.exe -m pip install --upgrade pip\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: catboost in d:\\optimizing-catboost-model-with-bayesian\\env\\lib\\site-packages (1.2.7)\n",
      "Requirement already satisfied: graphviz in d:\\optimizing-catboost-model-with-bayesian\\env\\lib\\site-packages (from catboost) (0.20.3)\n",
      "Requirement already satisfied: matplotlib in d:\\optimizing-catboost-model-with-bayesian\\env\\lib\\site-packages (from catboost) (3.10.0)\n",
      "Requirement already satisfied: numpy<2.0,>=1.16.0 in d:\\optimizing-catboost-model-with-bayesian\\env\\lib\\site-packages (from catboost) (1.26.4)\n",
      "Requirement already satisfied: pandas>=0.24 in d:\\optimizing-catboost-model-with-bayesian\\env\\lib\\site-packages (from catboost) (2.2.3)\n",
      "Requirement already satisfied: scipy in d:\\optimizing-catboost-model-with-bayesian\\env\\lib\\site-packages (from catboost) (1.14.1)\n",
      "Requirement already satisfied: plotly in d:\\optimizing-catboost-model-with-bayesian\\env\\lib\\site-packages (from catboost) (5.24.1)\n",
      "Requirement already satisfied: six in d:\\optimizing-catboost-model-with-bayesian\\env\\lib\\site-packages (from catboost) (1.17.0)\n",
      "Requirement already satisfied: python-dateutil>=2.8.2 in d:\\optimizing-catboost-model-with-bayesian\\env\\lib\\site-packages (from pandas>=0.24->catboost) (2.9.0.post0)\n",
      "Requirement already satisfied: pytz>=2020.1 in d:\\optimizing-catboost-model-with-bayesian\\env\\lib\\site-packages (from pandas>=0.24->catboost) (2024.2)\n",
      "Requirement already satisfied: tzdata>=2022.7 in d:\\optimizing-catboost-model-with-bayesian\\env\\lib\\site-packages (from pandas>=0.24->catboost) (2024.2)\n",
      "Requirement already satisfied: contourpy>=1.0.1 in d:\\optimizing-catboost-model-with-bayesian\\env\\lib\\site-packages (from matplotlib->catboost) (1.3.1)\n",
      "Requirement already satisfied: cycler>=0.10 in d:\\optimizing-catboost-model-with-bayesian\\env\\lib\\site-packages (from matplotlib->catboost) (0.12.1)\n",
      "Requirement already satisfied: fonttools>=4.22.0 in d:\\optimizing-catboost-model-with-bayesian\\env\\lib\\site-packages (from matplotlib->catboost) (4.55.3)\n",
      "Requirement already satisfied: kiwisolver>=1.3.1 in d:\\optimizing-catboost-model-with-bayesian\\env\\lib\\site-packages (from matplotlib->catboost) (1.4.7)\n",
      "Requirement already satisfied: packaging>=20.0 in d:\\optimizing-catboost-model-with-bayesian\\env\\lib\\site-packages (from matplotlib->catboost) (24.2)\n",
      "Requirement already satisfied: pillow>=8 in d:\\optimizing-catboost-model-with-bayesian\\env\\lib\\site-packages (from matplotlib->catboost) (11.0.0)\n",
      "Requirement already satisfied: pyparsing>=2.3.1 in d:\\optimizing-catboost-model-with-bayesian\\env\\lib\\site-packages (from matplotlib->catboost) (3.2.0)\n",
      "Requirement already satisfied: tenacity>=6.2.0 in d:\\optimizing-catboost-model-with-bayesian\\env\\lib\\site-packages (from plotly->catboost) (9.0.0)\n",
      "Note: you may need to restart the kernel to use updated packages.\n",
      "---5---\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "[notice] A new release of pip is available: 24.3.1 -> 25.0.1\n",
      "[notice] To update, run: python.exe -m pip install --upgrade pip\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: ipywidgets in d:\\optimizing-catboost-model-with-bayesian\\env\\lib\\site-packages (8.1.5)\n",
      "Requirement already satisfied: comm>=0.1.3 in d:\\optimizing-catboost-model-with-bayesian\\env\\lib\\site-packages (from ipywidgets) (0.2.2)\n",
      "Requirement already satisfied: ipython>=6.1.0 in d:\\optimizing-catboost-model-with-bayesian\\env\\lib\\site-packages (from ipywidgets) (8.31.0)\n",
      "Requirement already satisfied: traitlets>=4.3.1 in d:\\optimizing-catboost-model-with-bayesian\\env\\lib\\site-packages (from ipywidgets) (5.14.3)\n",
      "Requirement already satisfied: widgetsnbextension~=4.0.12 in d:\\optimizing-catboost-model-with-bayesian\\env\\lib\\site-packages (from ipywidgets) (4.0.13)\n",
      "Requirement already satisfied: jupyterlab-widgets~=3.0.12 in d:\\optimizing-catboost-model-with-bayesian\\env\\lib\\site-packages (from ipywidgets) (3.0.13)\n",
      "Requirement already satisfied: colorama in d:\\optimizing-catboost-model-with-bayesian\\env\\lib\\site-packages (from ipython>=6.1.0->ipywidgets) (0.4.6)\n",
      "Requirement already satisfied: decorator in d:\\optimizing-catboost-model-with-bayesian\\env\\lib\\site-packages (from ipython>=6.1.0->ipywidgets) (5.1.1)\n",
      "Requirement already satisfied: jedi>=0.16 in d:\\optimizing-catboost-model-with-bayesian\\env\\lib\\site-packages (from ipython>=6.1.0->ipywidgets) (0.19.2)\n",
      "Requirement already satisfied: matplotlib-inline in d:\\optimizing-catboost-model-with-bayesian\\env\\lib\\site-packages (from ipython>=6.1.0->ipywidgets) (0.1.7)\n",
      "Requirement already satisfied: prompt_toolkit<3.1.0,>=3.0.41 in d:\\optimizing-catboost-model-with-bayesian\\env\\lib\\site-packages (from ipython>=6.1.0->ipywidgets) (3.0.50)\n",
      "Requirement already satisfied: pygments>=2.4.0 in d:\\optimizing-catboost-model-with-bayesian\\env\\lib\\site-packages (from ipython>=6.1.0->ipywidgets) (2.19.1)\n",
      "Requirement already satisfied: stack_data in d:\\optimizing-catboost-model-with-bayesian\\env\\lib\\site-packages (from ipython>=6.1.0->ipywidgets) (0.6.3)\n",
      "Requirement already satisfied: typing_extensions>=4.6 in d:\\optimizing-catboost-model-with-bayesian\\env\\lib\\site-packages (from ipython>=6.1.0->ipywidgets) (4.12.2)\n",
      "Requirement already satisfied: parso<0.9.0,>=0.8.4 in d:\\optimizing-catboost-model-with-bayesian\\env\\lib\\site-packages (from jedi>=0.16->ipython>=6.1.0->ipywidgets) (0.8.4)\n",
      "Requirement already satisfied: wcwidth in d:\\optimizing-catboost-model-with-bayesian\\env\\lib\\site-packages (from prompt_toolkit<3.1.0,>=3.0.41->ipython>=6.1.0->ipywidgets) (0.2.13)\n",
      "Requirement already satisfied: executing>=1.2.0 in d:\\optimizing-catboost-model-with-bayesian\\env\\lib\\site-packages (from stack_data->ipython>=6.1.0->ipywidgets) (2.1.0)\n",
      "Requirement already satisfied: asttokens>=2.1.0 in d:\\optimizing-catboost-model-with-bayesian\\env\\lib\\site-packages (from stack_data->ipython>=6.1.0->ipywidgets) (3.0.0)\n",
      "Requirement already satisfied: pure-eval in d:\\optimizing-catboost-model-with-bayesian\\env\\lib\\site-packages (from stack_data->ipython>=6.1.0->ipywidgets) (0.2.3)\n",
      "Note: you may need to restart the kernel to use updated packages.\n",
      "---6---\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "[notice] A new release of pip is available: 24.3.1 -> 25.0.1\n",
      "[notice] To update, run: python.exe -m pip install --upgrade pip\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: pandas in d:\\optimizing-catboost-model-with-bayesian\\env\\lib\\site-packages (2.2.3)\n",
      "Requirement already satisfied: openpyxl in d:\\optimizing-catboost-model-with-bayesian\\env\\lib\\site-packages (3.1.5)\n",
      "Requirement already satisfied: numpy>=1.23.2 in d:\\optimizing-catboost-model-with-bayesian\\env\\lib\\site-packages (from pandas) (1.26.4)\n",
      "Requirement already satisfied: python-dateutil>=2.8.2 in d:\\optimizing-catboost-model-with-bayesian\\env\\lib\\site-packages (from pandas) (2.9.0.post0)\n",
      "Requirement already satisfied: pytz>=2020.1 in d:\\optimizing-catboost-model-with-bayesian\\env\\lib\\site-packages (from pandas) (2024.2)\n",
      "Requirement already satisfied: tzdata>=2022.7 in d:\\optimizing-catboost-model-with-bayesian\\env\\lib\\site-packages (from pandas) (2024.2)\n",
      "Requirement already satisfied: et-xmlfile in d:\\optimizing-catboost-model-with-bayesian\\env\\lib\\site-packages (from openpyxl) (2.0.0)\n",
      "Requirement already satisfied: six>=1.5 in d:\\optimizing-catboost-model-with-bayesian\\env\\lib\\site-packages (from python-dateutil>=2.8.2->pandas) (1.17.0)\n",
      "Note: you may need to restart the kernel to use updated packages.\n",
      "---7---\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "[notice] A new release of pip is available: 24.3.1 -> 25.0.1\n",
      "[notice] To update, run: python.exe -m pip install --upgrade pip\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: bayesian-optimization in d:\\optimizing-catboost-model-with-bayesian\\env\\lib\\site-packages (2.0.3)Note: you may need to restart the kernel to use updated packages.\n",
      "---8---\n",
      "\n",
      "Requirement already satisfied: colorama<0.5.0,>=0.4.6 in d:\\optimizing-catboost-model-with-bayesian\\env\\lib\\site-packages (from bayesian-optimization) (0.4.6)\n",
      "Requirement already satisfied: numpy>=1.25 in d:\\optimizing-catboost-model-with-bayesian\\env\\lib\\site-packages (from bayesian-optimization) (1.26.4)\n",
      "Requirement already satisfied: scikit-learn<2.0.0,>=1.0.0 in d:\\optimizing-catboost-model-with-bayesian\\env\\lib\\site-packages (from bayesian-optimization) (1.6.1)\n",
      "Requirement already satisfied: scipy<2.0.0,>=1.0.0 in d:\\optimizing-catboost-model-with-bayesian\\env\\lib\\site-packages (from bayesian-optimization) (1.14.1)\n",
      "Requirement already satisfied: joblib>=1.2.0 in d:\\optimizing-catboost-model-with-bayesian\\env\\lib\\site-packages (from scikit-learn<2.0.0,>=1.0.0->bayesian-optimization) (1.4.2)\n",
      "Requirement already satisfied: threadpoolctl>=3.1.0 in d:\\optimizing-catboost-model-with-bayesian\\env\\lib\\site-packages (from scikit-learn<2.0.0,>=1.0.0->bayesian-optimization) (3.5.0)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "[notice] A new release of pip is available: 24.3.1 -> 25.0.1\n",
      "[notice] To update, run: python.exe -m pip install --upgrade pip\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: fsspec in d:\\optimizing-catboost-model-with-bayesian\\env\\lib\\site-packages (2024.9.0)\n",
      "Note: you may need to restart the kernel to use updated packages.\n",
      "---9---\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "[notice] A new release of pip is available: 24.3.1 -> 25.0.1\n",
      "[notice] To update, run: python.exe -m pip install --upgrade pip\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: huggingface_hub in d:\\optimizing-catboost-model-with-bayesian\\env\\lib\\site-packages (0.28.1)\n",
      "Requirement already satisfied: filelock in d:\\optimizing-catboost-model-with-bayesian\\env\\lib\\site-packages (from huggingface_hub) (3.17.0)\n",
      "Requirement already satisfied: fsspec>=2023.5.0 in d:\\optimizing-catboost-model-with-bayesian\\env\\lib\\site-packages (from huggingface_hub) (2024.9.0)\n",
      "Requirement already satisfied: packaging>=20.9 in d:\\optimizing-catboost-model-with-bayesian\\env\\lib\\site-packages (from huggingface_hub) (24.2)\n",
      "Requirement already satisfied: pyyaml>=5.1 in d:\\optimizing-catboost-model-with-bayesian\\env\\lib\\site-packages (from huggingface_hub) (6.0.2)\n",
      "Requirement already satisfied: requests in d:\\optimizing-catboost-model-with-bayesian\\env\\lib\\site-packages (from huggingface_hub) (2.32.3)\n",
      "Requirement already satisfied: tqdm>=4.42.1 in d:\\optimizing-catboost-model-with-bayesian\\env\\lib\\site-packages (from huggingface_hub) (4.67.1)\n",
      "Requirement already satisfied: typing-extensions>=3.7.4.3 in d:\\optimizing-catboost-model-with-bayesian\\env\\lib\\site-packages (from huggingface_hub) (4.12.2)\n",
      "Requirement already satisfied: colorama in d:\\optimizing-catboost-model-with-bayesian\\env\\lib\\site-packages (from tqdm>=4.42.1->huggingface_hub) (0.4.6)\n",
      "Requirement already satisfied: charset-normalizer<4,>=2 in d:\\optimizing-catboost-model-with-bayesian\\env\\lib\\site-packages (from requests->huggingface_hub) (3.4.1)\n",
      "Requirement already satisfied: idna<4,>=2.5 in d:\\optimizing-catboost-model-with-bayesian\\env\\lib\\site-packages (from requests->huggingface_hub) (3.10)\n",
      "Requirement already satisfied: urllib3<3,>=1.21.1 in d:\\optimizing-catboost-model-with-bayesian\\env\\lib\\site-packages (from requests->huggingface_hub) (2.3.0)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in d:\\optimizing-catboost-model-with-bayesian\\env\\lib\\site-packages (from requests->huggingface_hub) (2025.1.31)\n",
      "Note: you may need to restart the kernel to use updated packages.\n",
      "---10---\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "[notice] A new release of pip is available: 24.3.1 -> 25.0.1\n",
      "[notice] To update, run: python.exe -m pip install --upgrade pip\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: datasets in d:\\optimizing-catboost-model-with-bayesian\\env\\lib\\site-packages (3.2.0)\n",
      "Requirement already satisfied: filelock in d:\\optimizing-catboost-model-with-bayesian\\env\\lib\\site-packages (from datasets) (3.17.0)\n",
      "Requirement already satisfied: numpy>=1.17 in d:\\optimizing-catboost-model-with-bayesian\\env\\lib\\site-packages (from datasets) (1.26.4)\n",
      "Requirement already satisfied: pyarrow>=15.0.0 in d:\\optimizing-catboost-model-with-bayesian\\env\\lib\\site-packages (from datasets) (19.0.0)\n",
      "Requirement already satisfied: dill<0.3.9,>=0.3.0 in d:\\optimizing-catboost-model-with-bayesian\\env\\lib\\site-packages (from datasets) (0.3.8)\n",
      "Requirement already satisfied: pandas in d:\\optimizing-catboost-model-with-bayesian\\env\\lib\\site-packages (from datasets) (2.2.3)\n",
      "Requirement already satisfied: requests>=2.32.2 in d:\\optimizing-catboost-model-with-bayesian\\env\\lib\\site-packages (from datasets) (2.32.3)\n",
      "Requirement already satisfied: tqdm>=4.66.3 in d:\\optimizing-catboost-model-with-bayesian\\env\\lib\\site-packages (from datasets) (4.67.1)\n",
      "Requirement already satisfied: xxhash in d:\\optimizing-catboost-model-with-bayesian\\env\\lib\\site-packages (from datasets) (3.5.0)\n",
      "Requirement already satisfied: multiprocess<0.70.17 in d:\\optimizing-catboost-model-with-bayesian\\env\\lib\\site-packages (from datasets) (0.70.16)\n",
      "Requirement already satisfied: fsspec<=2024.9.0,>=2023.1.0 in d:\\optimizing-catboost-model-with-bayesian\\env\\lib\\site-packages (from fsspec[http]<=2024.9.0,>=2023.1.0->datasets) (2024.9.0)\n",
      "Requirement already satisfied: aiohttp in d:\\optimizing-catboost-model-with-bayesian\\env\\lib\\site-packages (from datasets) (3.11.12)\n",
      "Requirement already satisfied: huggingface-hub>=0.23.0 in d:\\optimizing-catboost-model-with-bayesian\\env\\lib\\site-packages (from datasets) (0.28.1)\n",
      "Requirement already satisfied: packaging in d:\\optimizing-catboost-model-with-bayesian\\env\\lib\\site-packages (from datasets) (24.2)\n",
      "Requirement already satisfied: pyyaml>=5.1 in d:\\optimizing-catboost-model-with-bayesian\\env\\lib\\site-packages (from datasets) (6.0.2)\n",
      "Requirement already satisfied: aiohappyeyeballs>=2.3.0 in d:\\optimizing-catboost-model-with-bayesian\\env\\lib\\site-packages (from aiohttp->datasets) (2.4.6)\n",
      "Requirement already satisfied: aiosignal>=1.1.2 in d:\\optimizing-catboost-model-with-bayesian\\env\\lib\\site-packages (from aiohttp->datasets) (1.3.2)\n",
      "Requirement already satisfied: attrs>=17.3.0 in d:\\optimizing-catboost-model-with-bayesian\\env\\lib\\site-packages (from aiohttp->datasets) (25.1.0)\n",
      "Requirement already satisfied: frozenlist>=1.1.1 in d:\\optimizing-catboost-model-with-bayesian\\env\\lib\\site-packages (from aiohttp->datasets) (1.5.0)\n",
      "Requirement already satisfied: multidict<7.0,>=4.5 in d:\\optimizing-catboost-model-with-bayesian\\env\\lib\\site-packages (from aiohttp->datasets) (6.1.0)\n",
      "Requirement already satisfied: propcache>=0.2.0 in d:\\optimizing-catboost-model-with-bayesian\\env\\lib\\site-packages (from aiohttp->datasets) (0.2.1)\n",
      "Requirement already satisfied: yarl<2.0,>=1.17.0 in d:\\optimizing-catboost-model-with-bayesian\\env\\lib\\site-packages (from aiohttp->datasets) (1.18.3)\n",
      "Requirement already satisfied: typing-extensions>=3.7.4.3 in d:\\optimizing-catboost-model-with-bayesian\\env\\lib\\site-packages (from huggingface-hub>=0.23.0->datasets) (4.12.2)\n",
      "Requirement already satisfied: charset-normalizer<4,>=2 in d:\\optimizing-catboost-model-with-bayesian\\env\\lib\\site-packages (from requests>=2.32.2->datasets) (3.4.1)\n",
      "Requirement already satisfied: idna<4,>=2.5 in d:\\optimizing-catboost-model-with-bayesian\\env\\lib\\site-packages (from requests>=2.32.2->datasets) (3.10)\n",
      "Requirement already satisfied: urllib3<3,>=1.21.1 in d:\\optimizing-catboost-model-with-bayesian\\env\\lib\\site-packages (from requests>=2.32.2->datasets) (2.3.0)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in d:\\optimizing-catboost-model-with-bayesian\\env\\lib\\site-packages (from requests>=2.32.2->datasets) (2025.1.31)\n",
      "Requirement already satisfied: colorama in d:\\optimizing-catboost-model-with-bayesian\\env\\lib\\site-packages (from tqdm>=4.66.3->datasets) (0.4.6)\n",
      "Requirement already satisfied: python-dateutil>=2.8.2 in d:\\optimizing-catboost-model-with-bayesian\\env\\lib\\site-packages (from pandas->datasets) (2.9.0.post0)\n",
      "Requirement already satisfied: pytz>=2020.1 in d:\\optimizing-catboost-model-with-bayesian\\env\\lib\\site-packages (from pandas->datasets) (2024.2)\n",
      "Requirement already satisfied: tzdata>=2022.7 in d:\\optimizing-catboost-model-with-bayesian\\env\\lib\\site-packages (from pandas->datasets) (2024.2)\n",
      "Requirement already satisfied: six>=1.5 in d:\\optimizing-catboost-model-with-bayesian\\env\\lib\\site-packages (from python-dateutil>=2.8.2->pandas->datasets) (1.17.0)\n",
      "Note: you may need to restart the kernel to use updated packages.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "[notice] A new release of pip is available: 24.3.1 -> 25.0.1\n",
      "[notice] To update, run: python.exe -m pip install --upgrade pip\n"
     ]
    }
   ],
   "source": [
    "#PIP INSTALLATION\n",
    "print('---1---')\n",
    "%pip install pandas\n",
    "print('---2---')\n",
    "%pip install seaborn\n",
    "print('---3---')\n",
    "%pip install scikit-learn\n",
    "print('---4---')\n",
    "%pip install catboost\n",
    "print('---5---')\n",
    "%pip install ipywidgets\n",
    "print('---6---')\n",
    "%pip install pandas openpyxl\n",
    "print('---7---')\n",
    "%pip install bayesian-optimization\n",
    "print('---8---')\n",
    "%pip install fsspec\n",
    "print('---9---')\n",
    "%pip install huggingface_hub\n",
    "print('---10---')\n",
    "%pip install datasets\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "from huggingface_hub import login\n",
    "login(token=\"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\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "from catboost import CatBoostClassifier, Pool\n",
    "\n",
    "from sklearn.metrics import (\n",
    "    accuracy_score, precision_score, recall_score, f1_score,\n",
    "    roc_curve, roc_auc_score, precision_recall_curve, average_precision_score,\n",
    "    confusion_matrix\n",
    ")\n",
    "from sklearn.model_selection import StratifiedKFold\n",
    "from bayes_opt import BayesianOptimization\n",
    "from typing import List, Optional\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "\n",
    "from datasets import load_dataset\n",
    "\n",
    "\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt\n",
    "import os"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>time_in_hospital</th>\n",
       "      <th>num_lab_procedures</th>\n",
       "      <th>num_procedures</th>\n",
       "      <th>num_medications</th>\n",
       "      <th>number_outpatient</th>\n",
       "      <th>number_emergency</th>\n",
       "      <th>number_inpatient</th>\n",
       "      <th>number_diagnoses</th>\n",
       "      <th>change</th>\n",
       "      <th>diabetesMed</th>\n",
       "      <th>...</th>\n",
       "      <th>glyburide-metformin:Up</th>\n",
       "      <th>A1Cresult:&gt;7</th>\n",
       "      <th>A1Cresult:&gt;8</th>\n",
       "      <th>A1Cresult:None</th>\n",
       "      <th>A1Cresult:Norm</th>\n",
       "      <th>max_glu_serum:&gt;200</th>\n",
       "      <th>max_glu_serum:&gt;300</th>\n",
       "      <th>max_glu_serum:None</th>\n",
       "      <th>max_glu_serum:Norm</th>\n",
       "      <th>readmitted</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>2.0</td>\n",
       "      <td>38.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>27.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>7.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>4.0</td>\n",
       "      <td>48.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>11.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>9.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2.0</td>\n",
       "      <td>28.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>15.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>9.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>4.0</td>\n",
       "      <td>44.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>10.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>7.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>3.0</td>\n",
       "      <td>54.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>8.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>8.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 151 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "   time_in_hospital  num_lab_procedures  num_procedures  num_medications  \\\n",
       "0               2.0                38.0             3.0             27.0   \n",
       "1               4.0                48.0             0.0             11.0   \n",
       "2               2.0                28.0             0.0             15.0   \n",
       "3               4.0                44.0             0.0             10.0   \n",
       "4               3.0                54.0             0.0              8.0   \n",
       "\n",
       "   number_outpatient  number_emergency  number_inpatient  number_diagnoses  \\\n",
       "0                0.0               1.0               2.0               7.0   \n",
       "1                0.0               0.0               0.0               9.0   \n",
       "2                0.0               3.0               4.0               9.0   \n",
       "3                0.0               0.0               0.0               7.0   \n",
       "4                0.0               0.0               0.0               8.0   \n",
       "\n",
       "   change  diabetesMed  ...  glyburide-metformin:Up  A1Cresult:>7  \\\n",
       "0     1.0          1.0  ...                     0.0           0.0   \n",
       "1     0.0          0.0  ...                     0.0           0.0   \n",
       "2     0.0          1.0  ...                     0.0           0.0   \n",
       "3     0.0          1.0  ...                     0.0           0.0   \n",
       "4     1.0          1.0  ...                     0.0           0.0   \n",
       "\n",
       "   A1Cresult:>8  A1Cresult:None  A1Cresult:Norm  max_glu_serum:>200  \\\n",
       "0           0.0             1.0             0.0                 0.0   \n",
       "1           0.0             0.0             1.0                 0.0   \n",
       "2           0.0             1.0             0.0                 0.0   \n",
       "3           0.0             1.0             0.0                 0.0   \n",
       "4           0.0             1.0             0.0                 0.0   \n",
       "\n",
       "   max_glu_serum:>300  max_glu_serum:None  max_glu_serum:Norm  readmitted  \n",
       "0                 0.0                 1.0                 0.0           0  \n",
       "1                 0.0                 1.0                 0.0           0  \n",
       "2                 0.0                 1.0                 0.0           1  \n",
       "3                 0.0                 1.0                 0.0           0  \n",
       "4                 0.0                 1.0                 0.0           0  \n",
       "\n",
       "[5 rows x 151 columns]"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dataset = load_dataset(\"imodels/diabetes-readmission\")\n",
    "df = pd.DataFrame(dataset['train'])\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train = df.drop(columns=['readmitted'])\n",
    "y_train = df['readmitted'].values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_test = pd.DataFrame(dataset['test'])\n",
    "X_test = df.drop(columns=['readmitted'])\n",
    "y_test = df['readmitted'].values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "cat_features = X_train.select_dtypes(include=['object']).columns.tolist()\n",
    "X_train[cat_features] = X_train[cat_features].astype(str)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Final CatboostBayesianOptimzer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "gpu_available = \"NVIDIA_VISIBLE_DEVICES\" in os.environ or \"CUDA_VISIBLE_DEVICES\" in os.environ\n",
    "task_type = 'GPU' if gpu_available else 'CPU'\n",
    "\n",
    "class CatBoostBayesianOptimizer:\n",
    "    def __init__(self, X_train, y_train, cat_features, eval_metric, n_splits, random_state=42, gpu_id=0):\n",
    "        self.X_train = X_train\n",
    "        self.y_train = y_train\n",
    "        self.cat_features = cat_features\n",
    "        self.eval_metric = eval_metric\n",
    "        self.n_splits = n_splits\n",
    "        self.random_state = random_state\n",
    "        self.gpu_id = gpu_id\n",
    "        \n",
    "        self._validate_inputs()\n",
    "        \n",
    "    def _validate_inputs(self):\n",
    "        if not isinstance(self.X_train, pd.DataFrame):\n",
    "            raise TypeError(\"X_train must be a pandas DataFrame\")\n",
    "        \n",
    "        if not all(col in self.X_train.columns for col in self.cat_features):\n",
    "            raise ValueError(\"Some categorical features not found in X_train\")\n",
    "            \n",
    "        if self.eval_metric not in ['f1', 'auc', 'accuracy']:\n",
    "            raise ValueError(\"eval_metric must be one of: 'f1', 'auc', 'accuracy'\")\n",
    "        \n",
    "    def _get_base_params(self, custom_params=None):\n",
    "        \"\"\"Get base CatBoost parameters\"\"\"\n",
    "        base_params = {\n",
    "            'random_state': self.random_state,\n",
    "            'verbose': False,\n",
    "            'task_type': task_type,\n",
    "            'devices': f'{self.gpu_id}' if task_type == 'GPU' else None,\n",
    "            'loss_function': 'Logloss',\n",
    "            'eval_metric': 'Logloss'\n",
    "        }\n",
    "        return {**base_params, **custom_params} if custom_params else base_params\n",
    "    \n",
    "    def _get_metric_score(self, y_true, y_pred, y_prob=None):\n",
    "        if self.eval_metric == 'f1':\n",
    "            return f1_score(y_true, y_pred, average='weighted')\n",
    "        elif self.eval_metric == 'auc':\n",
    "            if len(np.unique(y_true)) > 2:\n",
    "                return roc_auc_score(y_true, y_prob, multi_class='ovr')\n",
    "            return roc_auc_score(y_true, y_prob[:, 1])\n",
    "        return accuracy_score(y_true, y_pred)\n",
    "    \n",
    "    def _evaluate_model(self, model, X_val, y_val):\n",
    "        \"\"\"Evaluate model performance\"\"\"\n",
    "        if self.eval_metric == 'auc':\n",
    "            y_prob = model.predict_proba(X_val)\n",
    "            return self._get_metric_score(y_val, np.argmax(y_prob, axis=1), y_prob)\n",
    "        y_pred = model.predict(X_val)\n",
    "        return self._get_metric_score(y_val, y_pred)\n",
    "        \n",
    "    #This is the 1st step to add another Parameters... you can add in here\n",
    "    def _objective(self, iterations, learning_rate, depth, l2_leaf_reg, border_count):\n",
    "        try:\n",
    "            params = self._get_base_params({\n",
    "                'iterations': int(iterations),\n",
    "                'learning_rate': float(learning_rate),\n",
    "                'depth': int(depth),\n",
    "                'l2_leaf_reg': float(l2_leaf_reg),\n",
    "                'border_count': int(border_count),\n",
    "            })\n",
    "            \n",
    "            X_train, X_val, y_train, y_val = train_test_split(\n",
    "                self.X_train, self.y_train,\n",
    "                test_size=0.2,\n",
    "                random_state=self.random_state,\n",
    "                stratify=self.y_train\n",
    "            )\n",
    "            \n",
    "            train_pool = Pool(X_train, label=y_train, cat_features=self.cat_features)\n",
    "            val_pool = Pool(X_val, label=y_val, cat_features=self.cat_features)\n",
    "            \n",
    "            model = CatBoostClassifier(**params)\n",
    "            model.fit(train_pool, eval_set=val_pool, early_stopping_rounds=50, verbose=False)\n",
    "            \n",
    "            return self._evaluate_model(model, X_val, y_val)\n",
    "                \n",
    "        except Exception as e:\n",
    "            print(f\"Error in optimization: {str(e)}\")\n",
    "            return 0.0\n",
    "        \n",
    "    def optimize(self, n_iter=50, n_init_points=10):\n",
    "        if n_iter <= n_init_points:\n",
    "            raise ValueError(\"n_iter must be greater than n_init_points\")\n",
    "        \n",
    "        #After adding the parameters you set the value for the parameters\n",
    "        pbounds = {\n",
    "            'iterations': (200, 1500),\n",
    "            'learning_rate': (0.005, 0.1),\n",
    "            'depth': (6, 12),\n",
    "            'l2_leaf_reg': (0.1, 10.0),\n",
    "            'border_count': (1, 255),\n",
    "        }\n",
    "        \n",
    "        optimizer = BayesianOptimization(\n",
    "            f=self._objective,\n",
    "            pbounds=pbounds,\n",
    "            random_state=self.random_state\n",
    "        )\n",
    "        \n",
    "        optimizer.maximize(init_points=n_init_points, n_iter=n_iter)\n",
    "        \n",
    "        best_params = optimizer.max['params']\n",
    "        print(\"\\nBest parameters found:\")\n",
    "        for param, value in best_params.items():\n",
    "            if param in ['depth', 'border_count', 'iterations']:\n",
    "                print(f\"{param}: {int(value)}\")\n",
    "            else:\n",
    "                print(f\"{param}: {value:.4f}\")\n",
    "        print(f\"\\nBest CV {self.eval_metric} score: {optimizer.max['target']:.4f}\")\n",
    "    \n",
    "        return best_params\n",
    "    \n",
    "    def Final_model(self, best_params):\n",
    "        \"\"\"Use SKCV to evaluate and choose the best iteration count, then train a final model\"\"\"\n",
    "        # Prepare cross-validation folds\n",
    "        skf = StratifiedKFold(n_splits=self.n_splits, shuffle=True, random_state=self.random_state)\n",
    "        fold_scores = []\n",
    "        best_iterations = []\n",
    "        \n",
    "        # Create base parameters from best Bayesian optimization results\n",
    "        model_params = self._get_base_params({\n",
    "            'iterations': int(best_params['iterations']),\n",
    "            'learning_rate': best_params['learning_rate'],\n",
    "            'depth': int(best_params['depth']),\n",
    "            'l2_leaf_reg': best_params['l2_leaf_reg'],\n",
    "            'border_count': int(best_params['border_count'])\n",
    "        })\n",
    "        \n",
    "        print(f\"\\nPerforming {self.n_splits}-fold CV to determine optimal iterations...\")\n",
    "        \n",
    "        for fold, (train_idx, val_idx) in enumerate(skf.split(self.X_train, self.y_train), 1):\n",
    "            X_fold_train = self.X_train.iloc[train_idx]\n",
    "            y_fold_train = self.y_train[train_idx]\n",
    "            X_fold_val = self.X_train.iloc[val_idx]\n",
    "            y_fold_val = self.y_train[val_idx]\n",
    "            \n",
    "            train_pool = Pool(X_fold_train, label=y_fold_train, cat_features=self.cat_features)\n",
    "            val_pool = Pool(X_fold_val, label=y_fold_val, cat_features=self.cat_features)\n",
    "            \n",
    "            # Train model with early stopping\n",
    "            model = CatBoostClassifier(**model_params)\n",
    "\n",
    "            #You can change the final model here\n",
    "            model.fit(train_pool, eval_set=val_pool, early_stopping_rounds=50, verbose=100)\n",
    "            \n",
    "            # Store the best iteration number\n",
    "            best_iterations.append(model.get_best_iteration())\n",
    "            \n",
    "            # Evaluate on validation set\n",
    "            score = self._evaluate_model(model, X_fold_val, y_fold_val)\n",
    "            print(f\"Fold {fold} {self.eval_metric} score: {score:.4f}, Best iteration: {model.get_best_iteration()}\")\n",
    "            \n",
    "            fold_scores.append(score)\n",
    "        \n",
    "        mean_score = np.mean(fold_scores)\n",
    "        std_score = np.std(fold_scores)\n",
    "        \n",
    "        # Calculate the median best iteration across folds\n",
    "        optimal_iterations = int(np.median(best_iterations)) if np.std(best_iterations) > 5 else int(np.mean(best_iterations))\n",
    "        \n",
    "        print(f\"\\nCV Results:\")\n",
    "        print(f\"Average {self.eval_metric} score: {mean_score:.4f} ± {std_score:.4f}\")\n",
    "        print(f\"Optimal iterations (median across folds): {optimal_iterations}\")\n",
    "        \n",
    "        # Train final model on full dataset with optimal iterations\n",
    "        final_model_params = model_params.copy()\n",
    "        final_model_params['iterations'] = optimal_iterations\n",
    "        \n",
    "        print(f\"\\nTraining final model on full dataset with {optimal_iterations} iterations...\")\n",
    "        full_train_pool = Pool(self.X_train, label=self.y_train, cat_features=self.cat_features)\n",
    "        \n",
    "        final_model = CatBoostClassifier(**final_model_params)\n",
    "        final_model.fit(full_train_pool, verbose=100)\n",
    "        \n",
    "        print(f\"Final model training complete.\")\n",
    "        \n",
    "        return final_model, mean_score, std_score\n",
    "\n",
    "    def save_model(self, model, filepath):\n",
    "        \"\"\"Save the trained CatBoost model to disk\"\"\"\n",
    "        try:\n",
    "            model.save_model(filepath)\n",
    "            print(f\"Model successfully saved to {filepath}\")\n",
    "            return True\n",
    "        except Exception as e:\n",
    "            print(f\"Error saving model: {str(e)}\")\n",
    "            return False\n",
    "\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "class FinalModelEvaluator:\n",
    "    def __init__(\n",
    "        self,\n",
    "        model,\n",
    "        X_train: pd.DataFrame,\n",
    "        y_train: np.ndarray,\n",
    "        X_test: pd.DataFrame,\n",
    "        y_test: np.ndarray,\n",
    "        cat_features: list\n",
    "    ):\n",
    "        self.model = model\n",
    "        self.X_train = X_train\n",
    "        self.y_train = y_train\n",
    "        self.X_test = X_test\n",
    "        self.y_test = y_test\n",
    "        self.cat_features = cat_features\n",
    "        \n",
    "        # Calculate predictions for the final model\n",
    "        self.y_pred = model.predict(X_test)\n",
    "        self.y_pred_proba = model.predict_proba(X_test)\n",
    "\n",
    "    def plot_learning_curve(self, figsize: tuple = (12, 5)):\n",
    "        \"\"\"Plot learning curve for the final model.\"\"\"\n",
    "        plt.figure(figsize=figsize)\n",
    "        \n",
    "        train_loss = self.model.get_evals_result()['learn']['Logloss']\n",
    "        if 'validation' in self.model.get_evals_result():\n",
    "            val_loss = self.model.get_evals_result()['validation']['Logloss']\n",
    "            \n",
    "        plt.plot(train_loss, label='Training Loss')\n",
    "        if 'validation' in self.model.get_evals_result():\n",
    "            plt.plot(val_loss, label='Validation Loss')\n",
    "            \n",
    "        plt.title('Learning Curve (Final Model)')\n",
    "        plt.xlabel('Iterations')\n",
    "        plt.ylabel('Loss')\n",
    "        plt.legend()\n",
    "        plt.grid(True)\n",
    "        plt.show()\n",
    "\n",
    "    def plot_feature_importance(self, top_n: int = 20, figsize: tuple = (10, 6)):\n",
    "        \"\"\"Plot feature importance of the final model.\"\"\"\n",
    "        importance = pd.DataFrame({\n",
    "            'Feature': self.X_train.columns,\n",
    "            'Importance': self.model.get_feature_importance()\n",
    "        }).sort_values('Importance', ascending=False)\n",
    "        \n",
    "        if top_n:\n",
    "            importance = importance.head(top_n)\n",
    "            \n",
    "        plt.figure(figsize=figsize)\n",
    "        plt.barh(importance['Feature'], importance['Importance'])\n",
    "        plt.title(f'Top {top_n} Feature Importance (Final Model)' if top_n else 'Feature Importance')\n",
    "        plt.xlabel('Importance Score')\n",
    "        plt.tight_layout()\n",
    "        plt.show()\n",
    "\n",
    "    def plot_roc_curve(self, figsize: tuple = (8, 6)):\n",
    "        \"\"\"Plot ROC curve for the final model.\"\"\"\n",
    "        plt.figure(figsize=figsize)\n",
    "        \n",
    "        fpr, tpr, _ = roc_curve(self.y_test, self.y_pred_proba[:, 1])\n",
    "        auc = roc_auc_score(self.y_test, self.y_pred_proba[:, 1])\n",
    "        \n",
    "        plt.plot(fpr, tpr, label=f'ROC Curve (AUC = {auc:.3f})')\n",
    "        plt.plot([0, 1], [0, 1], 'k--')\n",
    "        plt.xlim([0.0, 1.0])\n",
    "        plt.ylim([0.0, 1.05])\n",
    "        plt.xlabel('False Positive Rate')\n",
    "        plt.ylabel('True Positive Rate')\n",
    "        plt.title('ROC Curve (Final Model)')\n",
    "        plt.legend(loc=\"lower right\")\n",
    "        plt.grid(True)\n",
    "        plt.show()\n",
    "\n",
    "    def plot_confusion_matrix(self, figsize: tuple = (8, 6)):\n",
    "        \"\"\"Plot confusion matrix for the final model.\"\"\"\n",
    "        plt.figure(figsize=figsize)\n",
    "        \n",
    "        cm = confusion_matrix(self.y_test, self.y_pred)\n",
    "        sns.heatmap(cm, annot=True, fmt='d', cmap='Blues')\n",
    "        plt.title('Confusion Matrix (Final Model)')\n",
    "        plt.ylabel('True Label')\n",
    "        plt.xlabel('Predicted Label')\n",
    "        plt.tight_layout()\n",
    "        plt.show()\n",
    "\n",
    "    def get_metrics(self) -> dict:\n",
    "        \"\"\"Calculate and return metrics for the final model.\"\"\"\n",
    "        metrics = {\n",
    "            'Accuracy': accuracy_score(self.y_test, self.y_pred),\n",
    "            'Precision': precision_score(self.y_test, self.y_pred),\n",
    "            'Recall': recall_score(self.y_test, self.y_pred),\n",
    "            'F1 Score': f1_score(self.y_test, self.y_pred),\n",
    "            'ROC AUC': roc_auc_score(self.y_test, self.y_pred_proba[:, 1])\n",
    "        }\n",
    "        \n",
    "        return metrics\n",
    "\n",
    "    def print_metrics(self):\n",
    "        \"\"\"Print all metrics in a formatted way.\"\"\"\n",
    "        metrics = self.get_metrics()\n",
    "        \n",
    "        print(\"\\nFinal Model Performance Metrics:\")\n",
    "        print(\"-------------------------------\")\n",
    "        for metric, value in metrics.items():\n",
    "            print(f\"{metric}: {value:.4f}\")\n",
    "\n",
    "    def compare_with_cv_metrics(self, cv_mean_metrics, cv_std_metrics):\n",
    "        \"\"\"Compare final model metrics with cross-validation metrics.\"\"\"\n",
    "        final_metrics = self.get_metrics()\n",
    "        \n",
    "        print(\"\\nMetrics Comparison (Final Model vs. Cross-Validation):\")\n",
    "        print(\"-------------------------------------------------\")\n",
    "        for metric in final_metrics.keys():\n",
    "            final_value = final_metrics[metric]\n",
    "            if metric in cv_mean_metrics:\n",
    "                cv_mean = cv_mean_metrics[metric]\n",
    "                cv_std = cv_std_metrics[metric]\n",
    "                diff = final_value - cv_mean\n",
    "                print(f\"{metric}:\")\n",
    "                print(f\"  - Final Model: {final_value:.4f}\")\n",
    "                print(f\"  - CV Mean:     {cv_mean:.4f} ± {cv_std:.4f}\")\n",
    "                print(f\"  - Difference:  {diff:.4f} ({diff/cv_mean*100:.2f}%)\")\n",
    "            else:\n",
    "                print(f\"{metric}: {final_value:.4f} (CV metric not available)\")\n",
    "\n",
    "    def evaluate_all(self):\n",
    "        \"\"\"Run all evaluations and plots.\"\"\"\n",
    "        self.print_metrics()\n",
    "        self.plot_learning_curve()\n",
    "        self.plot_feature_importance()\n",
    "        self.plot_roc_curve()\n",
    "        self.plot_confusion_matrix()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "|   iter    |  target   | border... |   depth   | iterat... | l2_lea... | learni... |\n",
      "-------------------------------------------------------------------------------------\n",
      "| \u001b[39m1        \u001b[39m | \u001b[39m0.6934   \u001b[39m | \u001b[39m96.13    \u001b[39m | \u001b[39m11.7     \u001b[39m | \u001b[39m1.232e+03\u001b[39m | \u001b[39m6.027    \u001b[39m | \u001b[39m0.01982  \u001b[39m |\n",
      "| \u001b[39m2        \u001b[39m | \u001b[39m0.6931   \u001b[39m | \u001b[39m40.62    \u001b[39m | \u001b[39m6.349    \u001b[39m | \u001b[39m1.366e+03\u001b[39m | \u001b[39m6.051    \u001b[39m | \u001b[39m0.07227  \u001b[39m |\n",
      "| \u001b[39m3        \u001b[39m | \u001b[39m0.6906   \u001b[39m | \u001b[39m6.228    \u001b[39m | \u001b[39m11.82    \u001b[39m | \u001b[39m1.332e+03\u001b[39m | \u001b[39m2.202    \u001b[39m | \u001b[39m0.02227  \u001b[39m |\n",
      "| \u001b[39m4        \u001b[39m | \u001b[39m0.691    \u001b[39m | \u001b[39m43.83    \u001b[39m | \u001b[39m8.879    \u001b[39m | \u001b[39m1.365e+03\u001b[39m | \u001b[39m3.623    \u001b[39m | \u001b[39m0.07802  \u001b[39m |\n",
      "| \u001b[39m5        \u001b[39m | \u001b[39m0.6918   \u001b[39m | \u001b[39m231.2    \u001b[39m | \u001b[39m6.632    \u001b[39m | \u001b[39m647.3    \u001b[39m | \u001b[39m9.26     \u001b[39m | \u001b[39m0.07822  \u001b[39m |\n",
      "| \u001b[39m6        \u001b[39m | \u001b[39m0.6894   \u001b[39m | \u001b[39m149.3    \u001b[39m | \u001b[39m6.287    \u001b[39m | \u001b[39m535.8    \u001b[39m | \u001b[39m1.135    \u001b[39m | \u001b[39m0.02715  \u001b[39m |\n",
      "| \u001b[39m7        \u001b[39m | \u001b[39m0.6906   \u001b[39m | \u001b[39m120.0    \u001b[39m | \u001b[39m11.96    \u001b[39m | \u001b[39m1.422e+03\u001b[39m | \u001b[39m4.375    \u001b[39m | \u001b[39m0.03497  \u001b[39m |\n",
      "| \u001b[39m8        \u001b[39m | \u001b[39m0.6932   \u001b[39m | \u001b[39m206.1    \u001b[39m | \u001b[39m7.055    \u001b[39m | \u001b[39m816.7    \u001b[39m | \u001b[39m2.762    \u001b[39m | \u001b[39m0.07396  \u001b[39m |\n",
      "| \u001b[39m9        \u001b[39m | \u001b[39m0.6929   \u001b[39m | \u001b[39m125.8    \u001b[39m | \u001b[39m7.534    \u001b[39m | \u001b[39m1.235e+03\u001b[39m | \u001b[39m5.998    \u001b[39m | \u001b[39m0.08082  \u001b[39m |\n",
      "| \u001b[39m10       \u001b[39m | \u001b[39m0.6919   \u001b[39m | \u001b[39m20.17    \u001b[39m | \u001b[39m10.87    \u001b[39m | \u001b[39m966.7    \u001b[39m | \u001b[39m3.127    \u001b[39m | \u001b[39m0.03338  \u001b[39m |\n",
      "| \u001b[39m11       \u001b[39m | \u001b[39m0.6885   \u001b[39m | \u001b[39m21.96    \u001b[39m | \u001b[39m11.42    \u001b[39m | \u001b[39m1.094e+03\u001b[39m | \u001b[39m7.523    \u001b[39m | \u001b[39m0.07607  \u001b[39m |\n",
      "| \u001b[39m12       \u001b[39m | \u001b[39m0.6903   \u001b[39m | \u001b[39m185.9    \u001b[39m | \u001b[39m10.0     \u001b[39m | \u001b[39m1.495e+03\u001b[39m | \u001b[39m4.125    \u001b[39m | \u001b[39m0.05618  \u001b[39m |\n",
      "| \u001b[39m13       \u001b[39m | \u001b[39m0.6911   \u001b[39m | \u001b[39m34.93    \u001b[39m | \u001b[39m10.42    \u001b[39m | \u001b[39m801.3    \u001b[39m | \u001b[39m1.976    \u001b[39m | \u001b[39m0.02655  \u001b[39m |\n",
      "=====================================================================================\n",
      "\n",
      "Best parameters found:\n",
      "border_count: 96\n",
      "depth: 11\n",
      "iterations: 1231\n",
      "l2_leaf_reg: 6.0267\n",
      "learning_rate: 0.0198\n",
      "\n",
      "Best CV auc score: 0.6934\n"
     ]
    }
   ],
   "source": [
    "optimizer = CatBoostBayesianOptimizer(\n",
    "    X_train=X_train,\n",
    "    y_train=y_train,\n",
    "    cat_features=cat_features,\n",
    "    eval_metric=\"auc\", \n",
    "    n_splits=5,\n",
    "    random_state=42,\n",
    "    gpu_id=0\n",
    ")\n",
    "\n",
    "#We can also change the iterations of the bayesion and the best points\n",
    "best_params = optimizer.optimize(n_iter=10, n_init_points=3)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Performing 5-fold CV to determine optimal iterations...\n",
      "0:\tlearn: 0.6912039\ttest: 0.6914296\tbest: 0.6914296 (0)\ttotal: 107ms\tremaining: 2m 11s\n",
      "100:\tlearn: 0.6241047\ttest: 0.6435566\tbest: 0.6435566 (100)\ttotal: 10.6s\tremaining: 1m 58s\n",
      "200:\tlearn: 0.6040752\ttest: 0.6379715\tbest: 0.6379715 (200)\ttotal: 21.3s\tremaining: 1m 49s\n",
      "300:\tlearn: 0.5905117\ttest: 0.6359017\tbest: 0.6358983 (297)\ttotal: 32.3s\tremaining: 1m 39s\n",
      "400:\tlearn: 0.5795582\ttest: 0.6347393\tbest: 0.6347393 (400)\ttotal: 43.1s\tremaining: 1m 29s\n",
      "500:\tlearn: 0.5683938\ttest: 0.6339519\tbest: 0.6339519 (500)\ttotal: 54.6s\tremaining: 1m 19s\n",
      "600:\tlearn: 0.5562904\ttest: 0.6334165\tbest: 0.6334141 (595)\ttotal: 1m 6s\tremaining: 1m 10s\n",
      "700:\tlearn: 0.5428554\ttest: 0.6331617\tbest: 0.6331440 (685)\ttotal: 1m 17s\tremaining: 58.8s\n",
      "800:\tlearn: 0.5314471\ttest: 0.6329416\tbest: 0.6329226 (797)\ttotal: 1m 28s\tremaining: 47.5s\n",
      "Stopped by overfitting detector  (50 iterations wait)\n",
      "\n",
      "bestTest = 0.6328952211\n",
      "bestIteration = 820\n",
      "\n",
      "Shrink model to first 821 iterations.\n",
      "Fold 1 auc score: 0.6869, Best iteration: 820\n",
      "0:\tlearn: 0.6912344\ttest: 0.6914258\tbest: 0.6914258 (0)\ttotal: 107ms\tremaining: 2m 11s\n",
      "100:\tlearn: 0.6242416\ttest: 0.6430061\tbest: 0.6430061 (100)\ttotal: 10.8s\tremaining: 2m\n",
      "200:\tlearn: 0.6050792\ttest: 0.6376792\tbest: 0.6376792 (200)\ttotal: 21.4s\tremaining: 1m 49s\n",
      "300:\tlearn: 0.5919017\ttest: 0.6354204\tbest: 0.6354204 (300)\ttotal: 32s\tremaining: 1m 38s\n",
      "400:\tlearn: 0.5809757\ttest: 0.6341101\tbest: 0.6341101 (400)\ttotal: 42.6s\tremaining: 1m 28s\n",
      "500:\tlearn: 0.5699843\ttest: 0.6333329\tbest: 0.6333329 (500)\ttotal: 53.3s\tremaining: 1m 17s\n",
      "600:\tlearn: 0.5583765\ttest: 0.6327691\tbest: 0.6327691 (600)\ttotal: 1m 4s\tremaining: 1m 7s\n",
      "700:\tlearn: 0.5439489\ttest: 0.6323293\tbest: 0.6323222 (699)\ttotal: 1m 15s\tremaining: 57.4s\n",
      "800:\tlearn: 0.5305262\ttest: 0.6321627\tbest: 0.6321300 (790)\ttotal: 1m 26s\tremaining: 46.6s\n",
      "Stopped by overfitting detector  (50 iterations wait)\n",
      "\n",
      "bestTest = 0.6321064083\n",
      "bestIteration = 807\n",
      "\n",
      "Shrink model to first 808 iterations.\n",
      "Fold 2 auc score: 0.6886, Best iteration: 807\n",
      "0:\tlearn: 0.6911553\ttest: 0.6913746\tbest: 0.6913746 (0)\ttotal: 110ms\tremaining: 2m 15s\n",
      "100:\tlearn: 0.6241022\ttest: 0.6431294\tbest: 0.6431294 (100)\ttotal: 10.8s\tremaining: 2m\n",
      "200:\tlearn: 0.6047073\ttest: 0.6376687\tbest: 0.6376687 (200)\ttotal: 21.8s\tremaining: 1m 51s\n",
      "300:\tlearn: 0.5900456\ttest: 0.6354118\tbest: 0.6354118 (300)\ttotal: 32.5s\tremaining: 1m 40s\n",
      "400:\tlearn: 0.5789427\ttest: 0.6341868\tbest: 0.6341837 (399)\ttotal: 43.4s\tremaining: 1m 29s\n",
      "500:\tlearn: 0.5685233\ttest: 0.6332389\tbest: 0.6332389 (500)\ttotal: 53.9s\tremaining: 1m 18s\n",
      "600:\tlearn: 0.5565754\ttest: 0.6324113\tbest: 0.6324113 (600)\ttotal: 1m 4s\tremaining: 1m 7s\n",
      "700:\tlearn: 0.5420039\ttest: 0.6318749\tbest: 0.6318749 (700)\ttotal: 1m 15s\tremaining: 57.1s\n",
      "800:\tlearn: 0.5285570\ttest: 0.6315381\tbest: 0.6315163 (796)\ttotal: 1m 26s\tremaining: 46.4s\n",
      "900:\tlearn: 0.5168025\ttest: 0.6313217\tbest: 0.6312886 (897)\ttotal: 1m 37s\tremaining: 35.6s\n",
      "Stopped by overfitting detector  (50 iterations wait)\n",
      "\n",
      "bestTest = 0.6312885717\n",
      "bestIteration = 897\n",
      "\n",
      "Shrink model to first 898 iterations.\n",
      "Fold 3 auc score: 0.6911, Best iteration: 897\n",
      "0:\tlearn: 0.6912989\ttest: 0.6913485\tbest: 0.6913485 (0)\ttotal: 109ms\tremaining: 2m 14s\n",
      "100:\tlearn: 0.6253055\ttest: 0.6402534\tbest: 0.6402534 (100)\ttotal: 10.7s\tremaining: 1m 59s\n",
      "200:\tlearn: 0.6054870\ttest: 0.6341003\tbest: 0.6341003 (200)\ttotal: 21s\tremaining: 1m 47s\n",
      "300:\tlearn: 0.5912229\ttest: 0.6318058\tbest: 0.6318058 (300)\ttotal: 31.6s\tremaining: 1m 37s\n",
      "400:\tlearn: 0.5804898\ttest: 0.6304987\tbest: 0.6304987 (400)\ttotal: 42.1s\tremaining: 1m 27s\n",
      "500:\tlearn: 0.5692840\ttest: 0.6296338\tbest: 0.6296338 (500)\ttotal: 52.5s\tremaining: 1m 16s\n",
      "600:\tlearn: 0.5559904\ttest: 0.6290411\tbest: 0.6290374 (598)\ttotal: 1m 3s\tremaining: 1m 6s\n",
      "700:\tlearn: 0.5422325\ttest: 0.6284734\tbest: 0.6284734 (700)\ttotal: 1m 13s\tremaining: 55.5s\n",
      "800:\tlearn: 0.5297744\ttest: 0.6283101\tbest: 0.6282586 (788)\ttotal: 1m 24s\tremaining: 45.1s\n",
      "Stopped by overfitting detector  (50 iterations wait)\n",
      "\n",
      "bestTest = 0.6282586261\n",
      "bestIteration = 788\n",
      "\n",
      "Shrink model to first 789 iterations.\n",
      "Fold 4 auc score: 0.6938, Best iteration: 788\n",
      "0:\tlearn: 0.6911743\ttest: 0.6913388\tbest: 0.6913388 (0)\ttotal: 124ms\tremaining: 2m 32s\n",
      "100:\tlearn: 0.6244292\ttest: 0.6420726\tbest: 0.6420726 (100)\ttotal: 10.4s\tremaining: 1m 55s\n",
      "200:\tlearn: 0.6045310\ttest: 0.6362230\tbest: 0.6362230 (200)\ttotal: 21s\tremaining: 1m 47s\n",
      "300:\tlearn: 0.5919355\ttest: 0.6340150\tbest: 0.6340150 (300)\ttotal: 31.6s\tremaining: 1m 37s\n",
      "400:\tlearn: 0.5803105\ttest: 0.6326892\tbest: 0.6326878 (399)\ttotal: 42.4s\tremaining: 1m 27s\n",
      "500:\tlearn: 0.5696355\ttest: 0.6316979\tbest: 0.6316979 (500)\ttotal: 53.2s\tremaining: 1m 17s\n",
      "600:\tlearn: 0.5568044\ttest: 0.6308297\tbest: 0.6308204 (599)\ttotal: 1m 3s\tremaining: 1m 7s\n",
      "700:\tlearn: 0.5412693\ttest: 0.6305135\tbest: 0.6305007 (680)\ttotal: 1m 14s\tremaining: 56.4s\n",
      "800:\tlearn: 0.5283444\ttest: 0.6302663\tbest: 0.6302341 (792)\ttotal: 1m 25s\tremaining: 45.9s\n",
      "900:\tlearn: 0.5165059\ttest: 0.6301288\tbest: 0.6300935 (895)\ttotal: 1m 36s\tremaining: 35.4s\n",
      "Stopped by overfitting detector  (50 iterations wait)\n",
      "\n",
      "bestTest = 0.6300197284\n",
      "bestIteration = 925\n",
      "\n",
      "Shrink model to first 926 iterations.\n",
      "Fold 5 auc score: 0.6906, Best iteration: 925\n",
      "\n",
      "CV Results:\n",
      "Average auc score: 0.6902 ± 0.0023\n",
      "Optimal iterations (median across folds): 820\n",
      "\n",
      "Training final model on full dataset with 820 iterations...\n",
      "0:\tlearn: 0.6912696\ttotal: 108ms\tremaining: 1m 28s\n",
      "100:\tlearn: 0.6267257\ttotal: 11.4s\tremaining: 1m 20s\n",
      "200:\tlearn: 0.6090714\ttotal: 22.4s\tremaining: 1m 8s\n",
      "300:\tlearn: 0.5973183\ttotal: 33.2s\tremaining: 57.3s\n",
      "400:\tlearn: 0.5869943\ttotal: 44.2s\tremaining: 46.2s\n",
      "500:\tlearn: 0.5778525\ttotal: 55.3s\tremaining: 35.2s\n",
      "600:\tlearn: 0.5667977\ttotal: 1m 6s\tremaining: 24.3s\n"
     ]
    }
   ],
   "source": [
    "# Select best model using SKCV and train final model\n",
    "final_model = optimizer.Final_model(best_params)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "ename": "AttributeError",
     "evalue": "'tuple' object has no attribute 'predict'",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mAttributeError\u001b[0m                            Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[13], line 2\u001b[0m\n\u001b[0;32m      1\u001b[0m \u001b[38;5;66;03m# Now evaluate the final model\u001b[39;00m\n\u001b[1;32m----> 2\u001b[0m evaluator \u001b[38;5;241m=\u001b[39m \u001b[43mFinalModelEvaluator\u001b[49m\u001b[43m(\u001b[49m\n\u001b[0;32m      3\u001b[0m \u001b[43m    \u001b[49m\u001b[43mmodel\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mfinal_model\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m      4\u001b[0m \u001b[43m    \u001b[49m\u001b[43mX_train\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mX_train\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m      5\u001b[0m \u001b[43m    \u001b[49m\u001b[43my_train\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43my_train\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m      6\u001b[0m \u001b[43m    \u001b[49m\u001b[43mX_test\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mX_test\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m      7\u001b[0m \u001b[43m    \u001b[49m\u001b[43my_test\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43my_test\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m      8\u001b[0m \u001b[43m    \u001b[49m\u001b[43mcat_features\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mcat_features\u001b[49m\n\u001b[0;32m      9\u001b[0m \u001b[43m)\u001b[49m\n\u001b[0;32m     11\u001b[0m \u001b[38;5;66;03m# Run all evaluations\u001b[39;00m\n\u001b[0;32m     12\u001b[0m evaluator\u001b[38;5;241m.\u001b[39mevaluate_all()\n",
      "Cell \u001b[1;32mIn[10], line 19\u001b[0m, in \u001b[0;36mFinalModelEvaluator.__init__\u001b[1;34m(self, model, X_train, y_train, X_test, y_test, cat_features)\u001b[0m\n\u001b[0;32m     16\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mcat_features \u001b[38;5;241m=\u001b[39m cat_features\n\u001b[0;32m     18\u001b[0m \u001b[38;5;66;03m# Calculate predictions for the final model\u001b[39;00m\n\u001b[1;32m---> 19\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39my_pred \u001b[38;5;241m=\u001b[39m \u001b[43mmodel\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mpredict\u001b[49m(X_test)\n\u001b[0;32m     20\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39my_pred_proba \u001b[38;5;241m=\u001b[39m model\u001b[38;5;241m.\u001b[39mpredict_proba(X_test)\n",
      "\u001b[1;31mAttributeError\u001b[0m: 'tuple' object has no attribute 'predict'"
     ]
    }
   ],
   "source": [
    "# Now evaluate the final model\n",
    "evaluator = FinalModelEvaluator(\n",
    "    model=final_model,\n",
    "    X_train=X_train,\n",
    "    y_train=y_train,\n",
    "    X_test=X_test,\n",
    "    y_test=y_test,\n",
    "    cat_features=cat_features\n",
    ")\n",
    "\n",
    "# Run all evaluations\n",
    "evaluator.evaluate_all()\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "env",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
