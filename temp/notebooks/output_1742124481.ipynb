{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "9c99efff",
   "metadata": {
    "tags": [
     "papermill-error-cell-tag"
    ]
   },
   "source": [
    "<span style=\"color:red; font-family:Helvetica Neue, Helvetica, Arial, sans-serif; font-size:2em;\">An Exception was encountered at '<a href=\"#papermill-error-cell\">In [11]</a>'.</span>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "10028052",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-03-16T11:28:02.449668Z",
     "iopub.status.busy": "2025-03-16T11:28:02.449668Z",
     "iopub.status.idle": "2025-03-16T11:28:10.892977Z",
     "shell.execute_reply": "2025-03-16T11:28:10.892977Z"
    },
    "papermill": {
     "duration": 8.447065,
     "end_time": "2025-03-16T11:28:10.894218",
     "exception": false,
     "start_time": "2025-03-16T11:28:02.447153",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "---1---\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: pandas in d:\\optimizing-catboost-model-with-bayesian\\env\\lib\\site-packages (2.2.1)\n",
      "Requirement already satisfied: numpy<2,>=1.23.2 in d:\\optimizing-catboost-model-with-bayesian\\env\\lib\\site-packages (from pandas) (1.26.4)\n",
      "Requirement already satisfied: python-dateutil>=2.8.2 in d:\\optimizing-catboost-model-with-bayesian\\env\\lib\\site-packages (from pandas) (2.9.0.post0)\n",
      "Requirement already satisfied: pytz>=2020.1 in d:\\optimizing-catboost-model-with-bayesian\\env\\lib\\site-packages (from pandas) (2024.2)\n",
      "Requirement already satisfied: tzdata>=2022.7 in d:\\optimizing-catboost-model-with-bayesian\\env\\lib\\site-packages (from pandas) (2024.2)\n",
      "Requirement already satisfied: six>=1.5 in d:\\optimizing-catboost-model-with-bayesian\\env\\lib\\site-packages (from python-dateutil>=2.8.2->pandas) (1.17.0)\n",
      "Note: you may need to restart the kernel to use updated packages.\n",
      "---2---\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "[notice] A new release of pip is available: 24.3.1 -> 25.0.1\n",
      "[notice] To update, run: python.exe -m pip install --upgrade pip\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: seaborn in d:\\optimizing-catboost-model-with-bayesian\\env\\lib\\site-packages (0.13.2)\n",
      "Requirement already satisfied: numpy!=1.24.0,>=1.20 in d:\\optimizing-catboost-model-with-bayesian\\env\\lib\\site-packages (from seaborn) (1.26.4)\n",
      "Requirement already satisfied: pandas>=1.2 in d:\\optimizing-catboost-model-with-bayesian\\env\\lib\\site-packages (from seaborn) (2.2.1)\n",
      "Requirement already satisfied: matplotlib!=3.6.1,>=3.4 in d:\\optimizing-catboost-model-with-bayesian\\env\\lib\\site-packages (from seaborn) (3.10.0)\n",
      "Requirement already satisfied: contourpy>=1.0.1 in d:\\optimizing-catboost-model-with-bayesian\\env\\lib\\site-packages (from matplotlib!=3.6.1,>=3.4->seaborn) (1.3.1)\n",
      "Requirement already satisfied: cycler>=0.10 in d:\\optimizing-catboost-model-with-bayesian\\env\\lib\\site-packages (from matplotlib!=3.6.1,>=3.4->seaborn) (0.12.1)\n",
      "Requirement already satisfied: fonttools>=4.22.0 in d:\\optimizing-catboost-model-with-bayesian\\env\\lib\\site-packages (from matplotlib!=3.6.1,>=3.4->seaborn) (4.55.3)\n",
      "Requirement already satisfied: kiwisolver>=1.3.1 in d:\\optimizing-catboost-model-with-bayesian\\env\\lib\\site-packages (from matplotlib!=3.6.1,>=3.4->seaborn) (1.4.7)\n",
      "Requirement already satisfied: packaging>=20.0 in d:\\optimizing-catboost-model-with-bayesian\\env\\lib\\site-packages (from matplotlib!=3.6.1,>=3.4->seaborn) (24.2)\n",
      "Requirement already satisfied: pillow>=8 in d:\\optimizing-catboost-model-with-bayesian\\env\\lib\\site-packages (from matplotlib!=3.6.1,>=3.4->seaborn) (11.0.0)\n",
      "Requirement already satisfied: pyparsing>=2.3.1 in d:\\optimizing-catboost-model-with-bayesian\\env\\lib\\site-packages (from matplotlib!=3.6.1,>=3.4->seaborn) (3.2.0)\n",
      "Requirement already satisfied: python-dateutil>=2.7 in d:\\optimizing-catboost-model-with-bayesian\\env\\lib\\site-packages (from matplotlib!=3.6.1,>=3.4->seaborn) (2.9.0.post0)\n",
      "Requirement already satisfied: pytz>=2020.1 in d:\\optimizing-catboost-model-with-bayesian\\env\\lib\\site-packages (from pandas>=1.2->seaborn) (2024.2)\n",
      "Requirement already satisfied: tzdata>=2022.7 in d:\\optimizing-catboost-model-with-bayesian\\env\\lib\\site-packages (from pandas>=1.2->seaborn) (2024.2)\n",
      "Requirement already satisfied: six>=1.5 in d:\\optimizing-catboost-model-with-bayesian\\env\\lib\\site-packages (from python-dateutil>=2.7->matplotlib!=3.6.1,>=3.4->seaborn) (1.17.0)\n",
      "Note: you may need to restart the kernel to use updated packages.\n",
      "---3---\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "[notice] A new release of pip is available: 24.3.1 -> 25.0.1\n",
      "[notice] To update, run: python.exe -m pip install --upgrade pip\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: scikit-learn in d:\\optimizing-catboost-model-with-bayesian\\env\\lib\\site-packages (1.6.1)\n",
      "Requirement already satisfied: numpy>=1.19.5 in d:\\optimizing-catboost-model-with-bayesian\\env\\lib\\site-packages (from scikit-learn) (1.26.4)\n",
      "Requirement already satisfied: scipy>=1.6.0 in d:\\optimizing-catboost-model-with-bayesian\\env\\lib\\site-packages (from scikit-learn) (1.14.1)\n",
      "Requirement already satisfied: joblib>=1.2.0 in d:\\optimizing-catboost-model-with-bayesian\\env\\lib\\site-packages (from scikit-learn) (1.4.2)\n",
      "Requirement already satisfied: threadpoolctl>=3.1.0 in d:\\optimizing-catboost-model-with-bayesian\\env\\lib\\site-packages (from scikit-learn) (3.5.0)\n",
      "Note: you may need to restart the kernel to use updated packages.\n",
      "---4---\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "[notice] A new release of pip is available: 24.3.1 -> 25.0.1\n",
      "[notice] To update, run: python.exe -m pip install --upgrade pip\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: catboost in d:\\optimizing-catboost-model-with-bayesian\\env\\lib\\site-packages (1.2.7)\n",
      "Requirement already satisfied: graphviz in d:\\optimizing-catboost-model-with-bayesian\\env\\lib\\site-packages (from catboost) (0.20.3)\n",
      "Requirement already satisfied: matplotlib in d:\\optimizing-catboost-model-with-bayesian\\env\\lib\\site-packages (from catboost) (3.10.0)\n",
      "Requirement already satisfied: numpy<2.0,>=1.16.0 in d:\\optimizing-catboost-model-with-bayesian\\env\\lib\\site-packages (from catboost) (1.26.4)\n",
      "Requirement already satisfied: pandas>=0.24 in d:\\optimizing-catboost-model-with-bayesian\\env\\lib\\site-packages (from catboost) (2.2.1)\n",
      "Requirement already satisfied: scipy in d:\\optimizing-catboost-model-with-bayesian\\env\\lib\\site-packages (from catboost) (1.14.1)\n",
      "Requirement already satisfied: plotly in d:\\optimizing-catboost-model-with-bayesian\\env\\lib\\site-packages (from catboost) (5.24.1)\n",
      "Requirement already satisfied: six in d:\\optimizing-catboost-model-with-bayesian\\env\\lib\\site-packages (from catboost) (1.17.0)\n",
      "Requirement already satisfied: python-dateutil>=2.8.2 in d:\\optimizing-catboost-model-with-bayesian\\env\\lib\\site-packages (from pandas>=0.24->catboost) (2.9.0.post0)\n",
      "Requirement already satisfied: pytz>=2020.1 in d:\\optimizing-catboost-model-with-bayesian\\env\\lib\\site-packages (from pandas>=0.24->catboost) (2024.2)\n",
      "Requirement already satisfied: tzdata>=2022.7 in d:\\optimizing-catboost-model-with-bayesian\\env\\lib\\site-packages (from pandas>=0.24->catboost) (2024.2)\n",
      "Requirement already satisfied: contourpy>=1.0.1 in d:\\optimizing-catboost-model-with-bayesian\\env\\lib\\site-packages (from matplotlib->catboost) (1.3.1)\n",
      "Requirement already satisfied: cycler>=0.10 in d:\\optimizing-catboost-model-with-bayesian\\env\\lib\\site-packages (from matplotlib->catboost) (0.12.1)\n",
      "Requirement already satisfied: fonttools>=4.22.0 in d:\\optimizing-catboost-model-with-bayesian\\env\\lib\\site-packages (from matplotlib->catboost) (4.55.3)\n",
      "Requirement already satisfied: kiwisolver>=1.3.1 in d:\\optimizing-catboost-model-with-bayesian\\env\\lib\\site-packages (from matplotlib->catboost) (1.4.7)\n",
      "Requirement already satisfied: packaging>=20.0 in d:\\optimizing-catboost-model-with-bayesian\\env\\lib\\site-packages (from matplotlib->catboost) (24.2)\n",
      "Requirement already satisfied: pillow>=8 in d:\\optimizing-catboost-model-with-bayesian\\env\\lib\\site-packages (from matplotlib->catboost) (11.0.0)\n",
      "Requirement already satisfied: pyparsing>=2.3.1 in d:\\optimizing-catboost-model-with-bayesian\\env\\lib\\site-packages (from matplotlib->catboost) (3.2.0)\n",
      "Requirement already satisfied: tenacity>=6.2.0 in d:\\optimizing-catboost-model-with-bayesian\\env\\lib\\site-packages (from plotly->catboost) (9.0.0)\n",
      "Note: you may need to restart the kernel to use updated packages.\n",
      "---5---\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "[notice] A new release of pip is available: 24.3.1 -> 25.0.1\n",
      "[notice] To update, run: python.exe -m pip install --upgrade pip\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: ipywidgets in d:\\optimizing-catboost-model-with-bayesian\\env\\lib\\site-packages (8.1.5)\n",
      "Requirement already satisfied: comm>=0.1.3 in d:\\optimizing-catboost-model-with-bayesian\\env\\lib\\site-packages (from ipywidgets) (0.2.2)\n",
      "Requirement already satisfied: ipython>=6.1.0 in d:\\optimizing-catboost-model-with-bayesian\\env\\lib\\site-packages (from ipywidgets) (8.31.0)\n",
      "Requirement already satisfied: traitlets>=4.3.1 in d:\\optimizing-catboost-model-with-bayesian\\env\\lib\\site-packages (from ipywidgets) (5.14.3)\n",
      "Requirement already satisfied: widgetsnbextension~=4.0.12 in d:\\optimizing-catboost-model-with-bayesian\\env\\lib\\site-packages (from ipywidgets) (4.0.13)\n",
      "Requirement already satisfied: jupyterlab-widgets~=3.0.12 in d:\\optimizing-catboost-model-with-bayesian\\env\\lib\\site-packages (from ipywidgets) (3.0.13)\n",
      "Requirement already satisfied: colorama in d:\\optimizing-catboost-model-with-bayesian\\env\\lib\\site-packages (from ipython>=6.1.0->ipywidgets) (0.4.6)\n",
      "Requirement already satisfied: decorator in d:\\optimizing-catboost-model-with-bayesian\\env\\lib\\site-packages (from ipython>=6.1.0->ipywidgets) (5.1.1)\n",
      "Requirement already satisfied: jedi>=0.16 in d:\\optimizing-catboost-model-with-bayesian\\env\\lib\\site-packages (from ipython>=6.1.0->ipywidgets) (0.19.2)\n",
      "Requirement already satisfied: matplotlib-inline in d:\\optimizing-catboost-model-with-bayesian\\env\\lib\\site-packages (from ipython>=6.1.0->ipywidgets) (0.1.7)\n",
      "Requirement already satisfied: prompt_toolkit<3.1.0,>=3.0.41 in d:\\optimizing-catboost-model-with-bayesian\\env\\lib\\site-packages (from ipython>=6.1.0->ipywidgets) (3.0.50)\n",
      "Requirement already satisfied: pygments>=2.4.0 in d:\\optimizing-catboost-model-with-bayesian\\env\\lib\\site-packages (from ipython>=6.1.0->ipywidgets) (2.19.1)\n",
      "Requirement already satisfied: stack_data in d:\\optimizing-catboost-model-with-bayesian\\env\\lib\\site-packages (from ipython>=6.1.0->ipywidgets) (0.6.3)\n",
      "Requirement already satisfied: typing_extensions>=4.6 in d:\\optimizing-catboost-model-with-bayesian\\env\\lib\\site-packages (from ipython>=6.1.0->ipywidgets) (4.12.2)\n",
      "Requirement already satisfied: parso<0.9.0,>=0.8.4 in d:\\optimizing-catboost-model-with-bayesian\\env\\lib\\site-packages (from jedi>=0.16->ipython>=6.1.0->ipywidgets) (0.8.4)\n",
      "Requirement already satisfied: wcwidth in d:\\optimizing-catboost-model-with-bayesian\\env\\lib\\site-packages (from prompt_toolkit<3.1.0,>=3.0.41->ipython>=6.1.0->ipywidgets) (0.2.13)\n",
      "Requirement already satisfied: executing>=1.2.0 in d:\\optimizing-catboost-model-with-bayesian\\env\\lib\\site-packages (from stack_data->ipython>=6.1.0->ipywidgets) (2.1.0)\n",
      "Requirement already satisfied: asttokens>=2.1.0 in d:\\optimizing-catboost-model-with-bayesian\\env\\lib\\site-packages (from stack_data->ipython>=6.1.0->ipywidgets) (3.0.0)\n",
      "Requirement already satisfied: pure-eval in d:\\optimizing-catboost-model-with-bayesian\\env\\lib\\site-packages (from stack_data->ipython>=6.1.0->ipywidgets) (0.2.3)\n",
      "Note: you may need to restart the kernel to use updated packages.\n",
      "---6---\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "[notice] A new release of pip is available: 24.3.1 -> 25.0.1\n",
      "[notice] To update, run: python.exe -m pip install --upgrade pip\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: pandas in d:\\optimizing-catboost-model-with-bayesian\\env\\lib\\site-packages (2.2.1)\n",
      "Requirement already satisfied: openpyxl in d:\\optimizing-catboost-model-with-bayesian\\env\\lib\\site-packages (3.1.2)\n",
      "Requirement already satisfied: numpy<2,>=1.23.2 in d:\\optimizing-catboost-model-with-bayesian\\env\\lib\\site-packages (from pandas) (1.26.4)\n",
      "Requirement already satisfied: python-dateutil>=2.8.2 in d:\\optimizing-catboost-model-with-bayesian\\env\\lib\\site-packages (from pandas) (2.9.0.post0)\n",
      "Requirement already satisfied: pytz>=2020.1 in d:\\optimizing-catboost-model-with-bayesian\\env\\lib\\site-packages (from pandas) (2024.2)\n",
      "Requirement already satisfied: tzdata>=2022.7 in d:\\optimizing-catboost-model-with-bayesian\\env\\lib\\site-packages (from pandas) (2024.2)\n",
      "Requirement already satisfied: et-xmlfile in d:\\optimizing-catboost-model-with-bayesian\\env\\lib\\site-packages (from openpyxl) (2.0.0)\n",
      "Requirement already satisfied: six>=1.5 in d:\\optimizing-catboost-model-with-bayesian\\env\\lib\\site-packages (from python-dateutil>=2.8.2->pandas) (1.17.0)\n",
      "Note: you may need to restart the kernel to use updated packages.\n",
      "---7---\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "[notice] A new release of pip is available: 24.3.1 -> 25.0.1\n",
      "[notice] To update, run: python.exe -m pip install --upgrade pip\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: bayesian-optimization in d:\\optimizing-catboost-model-with-bayesian\\env\\lib\\site-packages (2.0.3)\n",
      "Requirement already satisfied: colorama<0.5.0,>=0.4.6 in d:\\optimizing-catboost-model-with-bayesian\\env\\lib\\site-packages (from bayesian-optimization) (0.4.6)\n",
      "Requirement already satisfied: numpy>=1.25 in d:\\optimizing-catboost-model-with-bayesian\\env\\lib\\site-packages (from bayesian-optimization) (1.26.4)\n",
      "Requirement already satisfied: scikit-learn<2.0.0,>=1.0.0 in d:\\optimizing-catboost-model-with-bayesian\\env\\lib\\site-packages (from bayesian-optimization) (1.6.1)\n",
      "Requirement already satisfied: scipy<2.0.0,>=1.0.0 in d:\\optimizing-catboost-model-with-bayesian\\env\\lib\\site-packages (from bayesian-optimization) (1.14.1)\n",
      "Requirement already satisfied: joblib>=1.2.0 in d:\\optimizing-catboost-model-with-bayesian\\env\\lib\\site-packages (from scikit-learn<2.0.0,>=1.0.0->bayesian-optimization) (1.4.2)\n",
      "Requirement already satisfied: threadpoolctl>=3.1.0 in d:\\optimizing-catboost-model-with-bayesian\\env\\lib\\site-packages (from scikit-learn<2.0.0,>=1.0.0->bayesian-optimization) (3.5.0)\n",
      "Note: you may need to restart the kernel to use updated packages.\n",
      "---8---\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "[notice] A new release of pip is available: 24.3.1 -> 25.0.1\n",
      "[notice] To update, run: python.exe -m pip install --upgrade pip\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: fsspec in d:\\optimizing-catboost-model-with-bayesian\\env\\lib\\site-packages (2024.9.0)\n",
      "Note: you may need to restart the kernel to use updated packages.\n",
      "---9---\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "[notice] A new release of pip is available: 24.3.1 -> 25.0.1\n",
      "[notice] To update, run: python.exe -m pip install --upgrade pip\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: huggingface_hub in d:\\optimizing-catboost-model-with-bayesian\\env\\lib\\site-packages (0.28.1)\n",
      "Requirement already satisfied: filelock in d:\\optimizing-catboost-model-with-bayesian\\env\\lib\\site-packages (from huggingface_hub) (3.17.0)\n",
      "Requirement already satisfied: fsspec>=2023.5.0 in d:\\optimizing-catboost-model-with-bayesian\\env\\lib\\site-packages (from huggingface_hub) (2024.9.0)\n",
      "Requirement already satisfied: packaging>=20.9 in d:\\optimizing-catboost-model-with-bayesian\\env\\lib\\site-packages (from huggingface_hub) (24.2)\n",
      "Requirement already satisfied: pyyaml>=5.1 in d:\\optimizing-catboost-model-with-bayesian\\env\\lib\\site-packages (from huggingface_hub) (6.0.2)\n",
      "Requirement already satisfied: requests in d:\\optimizing-catboost-model-with-bayesian\\env\\lib\\site-packages (from huggingface_hub) (2.32.3)\n",
      "Requirement already satisfied: tqdm>=4.42.1 in d:\\optimizing-catboost-model-with-bayesian\\env\\lib\\site-packages (from huggingface_hub) (4.67.1)\n",
      "Requirement already satisfied: typing-extensions>=3.7.4.3 in d:\\optimizing-catboost-model-with-bayesian\\env\\lib\\site-packages (from huggingface_hub) (4.12.2)\n",
      "Requirement already satisfied: colorama in d:\\optimizing-catboost-model-with-bayesian\\env\\lib\\site-packages (from tqdm>=4.42.1->huggingface_hub) (0.4.6)\n",
      "Requirement already satisfied: charset-normalizer<4,>=2 in d:\\optimizing-catboost-model-with-bayesian\\env\\lib\\site-packages (from requests->huggingface_hub) (3.4.1)\n",
      "Requirement already satisfied: idna<4,>=2.5 in d:\\optimizing-catboost-model-with-bayesian\\env\\lib\\site-packages (from requests->huggingface_hub) (3.10)\n",
      "Requirement already satisfied: urllib3<3,>=1.21.1 in d:\\optimizing-catboost-model-with-bayesian\\env\\lib\\site-packages (from requests->huggingface_hub) (2.3.0)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in d:\\optimizing-catboost-model-with-bayesian\\env\\lib\\site-packages (from requests->huggingface_hub) (2025.1.31)\n",
      "Note: you may need to restart the kernel to use updated packages.\n",
      "---10---\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "[notice] A new release of pip is available: 24.3.1 -> 25.0.1\n",
      "[notice] To update, run: python.exe -m pip install --upgrade pip\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: datasets in d:\\optimizing-catboost-model-with-bayesian\\env\\lib\\site-packages (3.2.0)\n",
      "Requirement already satisfied: filelock in d:\\optimizing-catboost-model-with-bayesian\\env\\lib\\site-packages (from datasets) (3.17.0)\n",
      "Requirement already satisfied: numpy>=1.17 in d:\\optimizing-catboost-model-with-bayesian\\env\\lib\\site-packages (from datasets) (1.26.4)\n",
      "Requirement already satisfied: pyarrow>=15.0.0 in d:\\optimizing-catboost-model-with-bayesian\\env\\lib\\site-packages (from datasets) (15.0.0)\n",
      "Requirement already satisfied: dill<0.3.9,>=0.3.0 in d:\\optimizing-catboost-model-with-bayesian\\env\\lib\\site-packages (from datasets) (0.3.8)\n",
      "Requirement already satisfied: pandas in d:\\optimizing-catboost-model-with-bayesian\\env\\lib\\site-packages (from datasets) (2.2.1)\n",
      "Requirement already satisfied: requests>=2.32.2 in d:\\optimizing-catboost-model-with-bayesian\\env\\lib\\site-packages (from datasets) (2.32.3)\n",
      "Requirement already satisfied: tqdm>=4.66.3 in d:\\optimizing-catboost-model-with-bayesian\\env\\lib\\site-packages (from datasets) (4.67.1)\n",
      "Requirement already satisfied: xxhash in d:\\optimizing-catboost-model-with-bayesian\\env\\lib\\site-packages (from datasets) (3.5.0)\n",
      "Requirement already satisfied: multiprocess<0.70.17 in d:\\optimizing-catboost-model-with-bayesian\\env\\lib\\site-packages (from datasets) (0.70.16)\n",
      "Requirement already satisfied: fsspec<=2024.9.0,>=2023.1.0 in d:\\optimizing-catboost-model-with-bayesian\\env\\lib\\site-packages (from fsspec[http]<=2024.9.0,>=2023.1.0->datasets) (2024.9.0)\n",
      "Requirement already satisfied: aiohttp in d:\\optimizing-catboost-model-with-bayesian\\env\\lib\\site-packages (from datasets) (3.11.12)\n",
      "Requirement already satisfied: huggingface-hub>=0.23.0 in d:\\optimizing-catboost-model-with-bayesian\\env\\lib\\site-packages (from datasets) (0.28.1)\n",
      "Requirement already satisfied: packaging in d:\\optimizing-catboost-model-with-bayesian\\env\\lib\\site-packages (from datasets) (24.2)\n",
      "Requirement already satisfied: pyyaml>=5.1 in d:\\optimizing-catboost-model-with-bayesian\\env\\lib\\site-packages (from datasets) (6.0.2)\n",
      "Requirement already satisfied: aiohappyeyeballs>=2.3.0 in d:\\optimizing-catboost-model-with-bayesian\\env\\lib\\site-packages (from aiohttp->datasets) (2.4.6)\n",
      "Requirement already satisfied: aiosignal>=1.1.2 in d:\\optimizing-catboost-model-with-bayesian\\env\\lib\\site-packages (from aiohttp->datasets) (1.3.2)\n",
      "Requirement already satisfied: attrs>=17.3.0 in d:\\optimizing-catboost-model-with-bayesian\\env\\lib\\site-packages (from aiohttp->datasets) (25.1.0)\n",
      "Requirement already satisfied: frozenlist>=1.1.1 in d:\\optimizing-catboost-model-with-bayesian\\env\\lib\\site-packages (from aiohttp->datasets) (1.5.0)\n",
      "Requirement already satisfied: multidict<7.0,>=4.5 in d:\\optimizing-catboost-model-with-bayesian\\env\\lib\\site-packages (from aiohttp->datasets) (6.1.0)\n",
      "Requirement already satisfied: propcache>=0.2.0 in d:\\optimizing-catboost-model-with-bayesian\\env\\lib\\site-packages (from aiohttp->datasets) (0.2.1)\n",
      "Requirement already satisfied: yarl<2.0,>=1.17.0 in d:\\optimizing-catboost-model-with-bayesian\\env\\lib\\site-packages (from aiohttp->datasets) (1.18.3)\n",
      "Requirement already satisfied: typing-extensions>=3.7.4.3 in d:\\optimizing-catboost-model-with-bayesian\\env\\lib\\site-packages (from huggingface-hub>=0.23.0->datasets) (4.12.2)\n",
      "Requirement already satisfied: charset-normalizer<4,>=2 in d:\\optimizing-catboost-model-with-bayesian\\env\\lib\\site-packages (from requests>=2.32.2->datasets) (3.4.1)\n",
      "Requirement already satisfied: idna<4,>=2.5 in d:\\optimizing-catboost-model-with-bayesian\\env\\lib\\site-packages (from requests>=2.32.2->datasets) (3.10)\n",
      "Requirement already satisfied: urllib3<3,>=1.21.1 in d:\\optimizing-catboost-model-with-bayesian\\env\\lib\\site-packages (from requests>=2.32.2->datasets) (2.3.0)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in d:\\optimizing-catboost-model-with-bayesian\\env\\lib\\site-packages (from requests>=2.32.2->datasets) (2025.1.31)\n",
      "Requirement already satisfied: colorama in d:\\optimizing-catboost-model-with-bayesian\\env\\lib\\site-packages (from tqdm>=4.66.3->datasets) (0.4.6)\n",
      "Requirement already satisfied: python-dateutil>=2.8.2 in d:\\optimizing-catboost-model-with-bayesian\\env\\lib\\site-packages (from pandas->datasets) (2.9.0.post0)\n",
      "Requirement already satisfied: pytz>=2020.1 in d:\\optimizing-catboost-model-with-bayesian\\env\\lib\\site-packages (from pandas->datasets) (2024.2)\n",
      "Requirement already satisfied: tzdata>=2022.7 in d:\\optimizing-catboost-model-with-bayesian\\env\\lib\\site-packages (from pandas->datasets) (2024.2)\n",
      "Requirement already satisfied: six>=1.5 in d:\\optimizing-catboost-model-with-bayesian\\env\\lib\\site-packages (from python-dateutil>=2.8.2->pandas->datasets) (1.17.0)\n",
      "Note: you may need to restart the kernel to use updated packages.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "[notice] A new release of pip is available: 24.3.1 -> 25.0.1\n",
      "[notice] To update, run: python.exe -m pip install --upgrade pip\n"
     ]
    }
   ],
   "source": [
    "#PIP INSTALLATION\n",
    "print('---1---')\n",
    "%pip install pandas\n",
    "print('---2---')\n",
    "%pip install seaborn\n",
    "print('---3---')\n",
    "%pip install scikit-learn\n",
    "print('---4---')\n",
    "%pip install catboost\n",
    "print('---5---')\n",
    "%pip install ipywidgets\n",
    "print('---6---')\n",
    "%pip install pandas openpyxl\n",
    "print('---7---')\n",
    "%pip install bayesian-optimization\n",
    "print('---8---')\n",
    "%pip install fsspec\n",
    "print('---9---')\n",
    "%pip install huggingface_hub\n",
    "print('---10---')\n",
    "%pip install datasets\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "e633549b",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-03-16T11:28:10.900733Z",
     "iopub.status.busy": "2025-03-16T11:28:10.900733Z",
     "iopub.status.idle": "2025-03-16T11:28:12.951546Z",
     "shell.execute_reply": "2025-03-16T11:28:12.951546Z"
    },
    "papermill": {
     "duration": 2.056339,
     "end_time": "2025-03-16T11:28:12.952554",
     "exception": false,
     "start_time": "2025-03-16T11:28:10.896215",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "from catboost import CatBoostClassifier, Pool\n",
    "\n",
    "from sklearn.metrics import (\n",
    "    accuracy_score, precision_score, recall_score, f1_score,\n",
    "    roc_curve, roc_auc_score, precision_recall_curve, average_precision_score,\n",
    "    confusion_matrix\n",
    ")\n",
    "from sklearn.model_selection import StratifiedKFold\n",
    "from bayes_opt import BayesianOptimization\n",
    "from typing import List, Optional\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "\n",
    "from datasets import load_dataset\n",
    "\n",
    "\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt\n",
    "import os"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "c3c70b67",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-03-16T11:28:12.960067Z",
     "iopub.status.busy": "2025-03-16T11:28:12.959070Z",
     "iopub.status.idle": "2025-03-16T11:28:12.962421Z",
     "shell.execute_reply": "2025-03-16T11:28:12.962421Z"
    },
    "papermill": {
     "duration": 0.007875,
     "end_time": "2025-03-16T11:28:12.963427",
     "exception": false,
     "start_time": "2025-03-16T11:28:12.955552",
     "status": "completed"
    },
    "tags": [
     "parameters"
    ]
   },
   "outputs": [],
   "source": [
    "dataset_path = None\n",
    "algorithm = 'catboost'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "136f5db0",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-03-16T11:28:12.969935Z",
     "iopub.status.busy": "2025-03-16T11:28:12.968934Z",
     "iopub.status.idle": "2025-03-16T11:28:12.971925Z",
     "shell.execute_reply": "2025-03-16T11:28:12.971925Z"
    },
    "papermill": {
     "duration": 0.006506,
     "end_time": "2025-03-16T11:28:12.972931",
     "exception": false,
     "start_time": "2025-03-16T11:28:12.966425",
     "status": "completed"
    },
    "tags": [
     "injected-parameters"
    ]
   },
   "outputs": [],
   "source": [
    "# Parameters\n",
    "dataset_path = \"temp\\\\1b9c6bc6-5a5b-4a23-9dfc-1a6d44661717.csv\"\n",
    "algorithm = \"bayesian\"\n",
    "model_output_path = \"saved_models/Bayesian_Opt_Catboost_1742124481.cbm\"\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "72ec46bc",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-03-16T11:28:12.980154Z",
     "iopub.status.busy": "2025-03-16T11:28:12.979150Z",
     "iopub.status.idle": "2025-03-16T11:28:13.119723Z",
     "shell.execute_reply": "2025-03-16T11:28:13.119217Z"
    },
    "papermill": {
     "duration": 0.144793,
     "end_time": "2025-03-16T11:28:13.120725",
     "exception": false,
     "start_time": "2025-03-16T11:28:12.975932",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "df = pd.read_csv(dataset_path)\n",
    "X = df.drop(columns=['readmitted'])\n",
    "y = df['readmitted'].values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "b3f8338c",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-03-16T11:28:13.128230Z",
     "iopub.status.busy": "2025-03-16T11:28:13.127724Z",
     "iopub.status.idle": "2025-03-16T11:28:13.160682Z",
     "shell.execute_reply": "2025-03-16T11:28:13.160682Z"
    },
    "papermill": {
     "duration": 0.037968,
     "end_time": "2025-03-16T11:28:13.161692",
     "exception": false,
     "start_time": "2025-03-16T11:28:13.123724",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "cat_features = X.select_dtypes(include=['object']).columns.tolist()\n",
    "X[cat_features] = X[cat_features].astype(str)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "490518bd",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-03-16T11:28:13.169195Z",
     "iopub.status.busy": "2025-03-16T11:28:13.169195Z",
     "iopub.status.idle": "2025-03-16T11:28:13.208259Z",
     "shell.execute_reply": "2025-03-16T11:28:13.207754Z"
    },
    "papermill": {
     "duration": 0.043575,
     "end_time": "2025-03-16T11:28:13.209262",
     "exception": false,
     "start_time": "2025-03-16T11:28:13.165687",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d6c6c3b5",
   "metadata": {
    "papermill": {
     "duration": 0.002999,
     "end_time": "2025-03-16T11:28:13.215769",
     "exception": false,
     "start_time": "2025-03-16T11:28:13.212770",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "Final CatboostBayesianOptimzer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "fae5545d",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-03-16T11:28:13.221781Z",
     "iopub.status.busy": "2025-03-16T11:28:13.221781Z",
     "iopub.status.idle": "2025-03-16T11:28:13.237903Z",
     "shell.execute_reply": "2025-03-16T11:28:13.237392Z"
    },
    "papermill": {
     "duration": 0.019628,
     "end_time": "2025-03-16T11:28:13.237903",
     "exception": false,
     "start_time": "2025-03-16T11:28:13.218275",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "gpu_available = \"NVIDIA_VISIBLE_DEVICES\" in os.environ or \"CUDA_VISIBLE_DEVICES\" in os.environ\n",
    "task_type = 'GPU' if gpu_available else 'CPU'\n",
    "\n",
    "class CatBoostBayesianOptimizer:\n",
    "    def __init__(self, X_train, y_train, cat_features, eval_metric, n_splits, random_state=42, gpu_id=0):\n",
    "        self.X_train = X_train\n",
    "        self.y_train = y_train\n",
    "        self.cat_features = cat_features\n",
    "        self.eval_metric = eval_metric\n",
    "        self.n_splits = n_splits\n",
    "        self.random_state = random_state\n",
    "        self.gpu_id = gpu_id\n",
    "        \n",
    "        self._validate_inputs()\n",
    "        \n",
    "    def _validate_inputs(self):\n",
    "        if not isinstance(self.X_train, pd.DataFrame):\n",
    "            raise TypeError(\"X_train must be a pandas DataFrame\")\n",
    "        \n",
    "        if not all(col in self.X_train.columns for col in self.cat_features):\n",
    "            raise ValueError(\"Some categorical features not found in X_train\")\n",
    "            \n",
    "        if self.eval_metric not in ['f1', 'auc', 'accuracy']:\n",
    "            raise ValueError(\"eval_metric must be one of: 'f1', 'auc', 'accuracy'\")\n",
    "    \n",
    "    #This is also hyperparameters for catboost but it cant be applied with bayesian optimization\n",
    "    def _get_base_params(self, custom_params=None):\n",
    "        \"\"\"Get base CatBoost parameters\"\"\"\n",
    "        base_params = {\n",
    "            'random_state': self.random_state,\n",
    "            'verbose': False,\n",
    "            'task_type': task_type,\n",
    "            'devices': f'{self.gpu_id}' if task_type == 'GPU' else None,\n",
    "            'loss_function': 'Logloss',\n",
    "            'eval_metric': 'Logloss'\n",
    "        }\n",
    "        return {**base_params, **custom_params} if custom_params else base_params\n",
    "    \n",
    "    def _get_metric_score(self, y_true, y_pred, y_prob=None):\n",
    "        if self.eval_metric == 'f1':\n",
    "            return f1_score(y_true, y_pred, average='weighted')\n",
    "        elif self.eval_metric == 'auc':\n",
    "            if len(np.unique(y_true)) > 2:\n",
    "                return roc_auc_score(y_true, y_prob, multi_class='ovr')\n",
    "            return roc_auc_score(y_true, y_prob[:, 1])\n",
    "        return accuracy_score(y_true, y_pred)\n",
    "    \n",
    "    def _evaluate_model(self, model, X_val, y_val):\n",
    "        \"\"\"Evaluate model performance\"\"\"\n",
    "        if self.eval_metric == 'auc':\n",
    "            y_prob = model.predict_proba(X_val)\n",
    "            return self._get_metric_score(y_val, np.argmax(y_prob, axis=1), y_prob)\n",
    "        y_pred = model.predict(X_val)\n",
    "        return self._get_metric_score(y_val, y_pred)\n",
    "        \n",
    "    #This is the 1st step to add another Parameters... you can add in here\n",
    "    def _objective(self, iterations, learning_rate, depth, l2_leaf_reg, border_count):\n",
    "        try:\n",
    "            params = self._get_base_params({\n",
    "                'iterations': int(iterations),\n",
    "                'learning_rate': float(learning_rate),\n",
    "                'depth': int(depth),\n",
    "                'l2_leaf_reg': float(l2_leaf_reg),\n",
    "                'border_count': int(border_count),\n",
    "            })\n",
    "            \n",
    "            X_train, X_val, y_train, y_val = train_test_split(\n",
    "                self.X_train, self.y_train,\n",
    "                test_size=0.2,\n",
    "                random_state=self.random_state,\n",
    "                stratify=self.y_train\n",
    "            )\n",
    "            \n",
    "            train_pool = Pool(X_train, label=y_train, cat_features=self.cat_features)\n",
    "            val_pool = Pool(X_val, label=y_val, cat_features=self.cat_features)\n",
    "            \n",
    "            model = CatBoostClassifier(**params)\n",
    "            model.fit(train_pool, eval_set=val_pool, early_stopping_rounds=50, verbose=False)\n",
    "            \n",
    "            return self._evaluate_model(model, X_val, y_val)\n",
    "                \n",
    "        except Exception as e:\n",
    "            print(f\"Error in optimization: {str(e)}\")\n",
    "            return 0.0\n",
    "        \n",
    "    def optimize(self, n_iter=50, n_init_points=10):\n",
    "        if n_iter <= n_init_points:\n",
    "            raise ValueError(\"n_iter must be greater than n_init_points\")\n",
    "        \n",
    "        #After adding the parameters you set the value for the parameters\n",
    "        pbounds = {\n",
    "            'iterations': (800, 1000),\n",
    "            'learning_rate': (0.025, 0.035),\n",
    "            'depth': (7, 9),\n",
    "            'l2_leaf_reg': (3.0, 5.0),\n",
    "            'border_count': (60, 85),\n",
    "        }\n",
    "        \n",
    "        optimizer = BayesianOptimization(\n",
    "            f=self._objective,\n",
    "            pbounds=pbounds,\n",
    "            random_state=self.random_state\n",
    "        )\n",
    "        \n",
    "        optimizer.maximize(init_points=n_init_points, n_iter=n_iter)\n",
    "        \n",
    "        best_params = optimizer.max['params']\n",
    "        print(\"\\nBest parameters found:\")\n",
    "        for param, value in best_params.items():\n",
    "            if param in ['depth', 'border_count', 'iterations']:\n",
    "                print(f\"{param}: {int(value)}\")\n",
    "            else:\n",
    "                print(f\"{param}: {value:.4f}\")\n",
    "        print(f\"\\nBest CV {self.eval_metric} score: {optimizer.max['target']:.4f}\")\n",
    "    \n",
    "        return best_params\n",
    "    \n",
    "    def Final_model(self, best_params):\n",
    "        \"\"\"Use SKCV to evaluate and choose the best iteration count, then train a final model\"\"\"\n",
    "        # Prepare cross-validation folds\n",
    "        skf = StratifiedKFold(n_splits=self.n_splits, shuffle=True, random_state=self.random_state)\n",
    "        fold_scores = []\n",
    "        best_iterations = []\n",
    "        \n",
    "        # Create base parameters from best Bayesian optimization results\n",
    "        model_params = self._get_base_params({\n",
    "            'iterations': int(best_params['iterations']),\n",
    "            'learning_rate': best_params['learning_rate'],\n",
    "            'depth': int(best_params['depth']),\n",
    "            'l2_leaf_reg': best_params['l2_leaf_reg'],\n",
    "            'border_count': int(best_params['border_count'])\n",
    "        })\n",
    "        \n",
    "        print(f\"\\nPerforming {self.n_splits}-fold CV to determine optimal iterations...\")\n",
    "        \n",
    "        for fold, (cv_train_idx, cv_val_idx) in enumerate(skf.split(self.X_train, self.y_train), 1):\n",
    "            # Split training data into CV train and validation sets\n",
    "            X_cv_train = self.X_train.iloc[cv_train_idx]\n",
    "            y_cv_train = self.y_train[cv_train_idx]\n",
    "            X_cv_val = self.X_train.iloc[cv_val_idx]\n",
    "            y_cv_val = self.y_train[cv_val_idx]\n",
    "            \n",
    "            train_pool = Pool(X_cv_train, label=y_cv_train, cat_features=self.cat_features)\n",
    "            val_pool = Pool(X_cv_val, label=y_cv_val, cat_features=self.cat_features)\n",
    "    \n",
    "            # Train model with early stopping\n",
    "            model = CatBoostClassifier(**model_params)\n",
    "            #You can change the final model here\n",
    "            model.fit(train_pool, eval_set=val_pool, early_stopping_rounds=50, verbose=100)\n",
    "            \n",
    "            # Store the best iteration number\n",
    "            best_iterations.append(model.get_best_iteration())\n",
    "            \n",
    "            # Evaluate on validation set\n",
    "            score = self._evaluate_model(model, X_cv_val, y_cv_val)\n",
    "            print(f\"Fold {fold} {self.eval_metric} score: {score:.4f}, Best iteration: {model.get_best_iteration()}\")\n",
    "            \n",
    "            fold_scores.append(score)\n",
    "        \n",
    "        mean_score = np.mean(fold_scores)\n",
    "        std_score = np.std(fold_scores)\n",
    "        \n",
    "        # Calculate the median best iteration across folds\n",
    "        optimal_iterations = int(np.median(best_iterations)) if np.std(best_iterations) > 5 else int(np.mean(best_iterations))\n",
    "        \n",
    "        print(f\"\\nCV Results:\")\n",
    "        print(f\"Average {self.eval_metric} score: {mean_score:.4f} ± {std_score:.4f}\")\n",
    "        print(f\"Optimal iterations (median across folds): {optimal_iterations}\")\n",
    "        \n",
    "        # Train final model on split dataset with validation set\n",
    "        X_train_final, X_val_final, y_train_final, y_val_final = train_test_split(\n",
    "            self.X_train, self.y_train,\n",
    "            test_size=0.1,  # 20% validation set\n",
    "            random_state=self.random_state,\n",
    "            stratify=self.y_train\n",
    "        )\n",
    "        \n",
    "        train_pool = Pool(X_train_final, label=y_train_final, cat_features=self.cat_features)\n",
    "        val_pool = Pool(X_val_final, label=y_val_final, cat_features=self.cat_features)\n",
    "        \n",
    "        final_model_params = model_params.copy()\n",
    "        final_model_params['iterations'] = optimal_iterations\n",
    "        \n",
    "        print(f\"\\nTraining final model on training dataset with {optimal_iterations} iterations...\")\n",
    "        \n",
    "        final_model = CatBoostClassifier(**final_model_params)\n",
    "        final_model.fit(train_pool, eval_set=val_pool, verbose=100)\n",
    "        \n",
    "        return final_model, mean_score, std_score\n",
    "\n",
    "    def save_model(self, model, filepath):\n",
    "        \"\"\"Save the trained CatBoost model to disk\"\"\"\n",
    "        try:\n",
    "            model.save_model(filepath)\n",
    "            print(f\"Model successfully saved to {filepath}\")\n",
    "            return True\n",
    "        except Exception as e:\n",
    "            print(f\"Error saving model: {str(e)}\")\n",
    "            return False\n",
    "\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "92ae5444",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-03-16T11:28:13.247867Z",
     "iopub.status.busy": "2025-03-16T11:28:13.247867Z",
     "iopub.status.idle": "2025-03-16T11:28:13.262649Z",
     "shell.execute_reply": "2025-03-16T11:28:13.262649Z"
    },
    "papermill": {
     "duration": 0.020787,
     "end_time": "2025-03-16T11:28:13.263655",
     "exception": false,
     "start_time": "2025-03-16T11:28:13.242868",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "class FinalModelEvaluator:\n",
    "    def __init__(\n",
    "        self,\n",
    "        model,\n",
    "        X_train: pd.DataFrame,\n",
    "        y_train: np.ndarray,\n",
    "        X_test: pd.DataFrame,\n",
    "        y_test: np.ndarray,\n",
    "        cat_features: list\n",
    "    ):\n",
    "        self.model = model\n",
    "        self.X_train = X_train\n",
    "        self.y_train = y_train\n",
    "        self.X_test = X_test\n",
    "        self.y_test = y_test\n",
    "        self.cat_features = cat_features\n",
    "        \n",
    "        # Calculate predictions for the final model\n",
    "        self.y_pred = model.predict(X_test)\n",
    "        self.y_pred_proba = model.predict_proba(X_test)\n",
    "\n",
    "    def plot_learning_curve(self, figsize: tuple = (12, 5)):\n",
    "        \"\"\"Plot learning curve for the final model.\"\"\"\n",
    "        plt.figure(figsize=figsize)\n",
    "        \n",
    "        evals_result = self.model.get_evals_result()\n",
    "        train_loss = evals_result['learn']['Logloss']\n",
    "        \n",
    "        plt.plot(train_loss, label='Training Loss')\n",
    "        \n",
    "        # Check for validation data under either 'validation' or 'test' keys\n",
    "        if 'validation' in evals_result:\n",
    "            val_loss = evals_result['validation']['Logloss']\n",
    "            plt.plot(val_loss, label='Validation Loss')\n",
    "        elif 'test' in evals_result:\n",
    "            val_loss = evals_result['test']['Logloss']\n",
    "            plt.plot(val_loss, label='Validation Loss')\n",
    "            \n",
    "        plt.title('Learning Curve (Final Model)')\n",
    "        plt.xlabel('Iterations')\n",
    "        plt.ylabel('Loss')\n",
    "        plt.legend()\n",
    "        plt.grid(True)\n",
    "        plt.show()\n",
    "\n",
    "    def plot_feature_importance(self, top_n: int = 20, figsize: tuple = (10, 6)):\n",
    "        \"\"\"Plot feature importance of the final model.\"\"\"\n",
    "        importance = pd.DataFrame({\n",
    "            'Feature': self.X_train.columns,\n",
    "            'Importance': self.model.get_feature_importance()\n",
    "        }).sort_values('Importance', ascending=False)\n",
    "        \n",
    "        if top_n:\n",
    "            importance = importance.head(top_n)\n",
    "            \n",
    "        plt.figure(figsize=figsize)\n",
    "        plt.barh(importance['Feature'], importance['Importance'])\n",
    "        plt.title(f'Top {top_n} Feature Importance (Final Model)' if top_n else 'Feature Importance')\n",
    "        plt.xlabel('Importance Score')\n",
    "        plt.tight_layout()\n",
    "        plt.show()\n",
    "\n",
    "    def plot_roc_curve(self, figsize: tuple = (8, 6)):\n",
    "        \"\"\"Plot ROC curve for the final model.\"\"\"\n",
    "        plt.figure(figsize=figsize)\n",
    "        \n",
    "        fpr, tpr, _ = roc_curve(self.y_test, self.y_pred_proba[:, 1])\n",
    "        auc = roc_auc_score(self.y_test, self.y_pred_proba[:, 1])\n",
    "        \n",
    "        plt.plot(fpr, tpr, label=f'ROC Curve (AUC = {auc:.3f})')\n",
    "        plt.plot([0, 1], [0, 1], 'k--')\n",
    "        plt.xlim([0.0, 1.0])\n",
    "        plt.ylim([0.0, 1.05])\n",
    "        plt.xlabel('False Positive Rate')\n",
    "        plt.ylabel('True Positive Rate')\n",
    "        plt.title('ROC Curve (Final Model)')\n",
    "        plt.legend(loc=\"lower right\")\n",
    "        plt.grid(True)\n",
    "        plt.show()\n",
    "\n",
    "    def plot_confusion_matrix(self, figsize: tuple = (8, 6)):\n",
    "        \"\"\"Plot confusion matrix for the final model.\"\"\"\n",
    "        plt.figure(figsize=figsize)\n",
    "        \n",
    "        cm = confusion_matrix(self.y_test, self.y_pred)\n",
    "        sns.heatmap(cm, annot=True, fmt='d', cmap='Blues')\n",
    "        plt.title('Confusion Matrix (Final Model)')\n",
    "        plt.ylabel('True Label')\n",
    "        plt.xlabel('Predicted Label')\n",
    "        plt.tight_layout()\n",
    "        plt.show()\n",
    "\n",
    "    def get_metrics(self) -> dict:\n",
    "        \"\"\"Calculate and return metrics for the final model.\"\"\"\n",
    "        metrics = {\n",
    "            'Accuracy': accuracy_score(self.y_test, self.y_pred),\n",
    "            'Precision': precision_score(self.y_test, self.y_pred),\n",
    "            'Recall': recall_score(self.y_test, self.y_pred),\n",
    "            'F1 Score': f1_score(self.y_test, self.y_pred),\n",
    "            'ROC AUC': roc_auc_score(self.y_test, self.y_pred_proba[:, 1])\n",
    "        }\n",
    "        \n",
    "        return metrics\n",
    "\n",
    "    def print_metrics(self):\n",
    "        \"\"\"Print all metrics in a formatted way.\"\"\"\n",
    "        metrics = self.get_metrics()\n",
    "        \n",
    "        print(\"\\nFinal Model Performance Metrics:\")\n",
    "        print(\"-------------------------------\")\n",
    "        for metric, value in metrics.items():\n",
    "            print(f\"{metric}: {value:.4f}\")\n",
    "\n",
    "    def compare_with_cv_metrics(self, cv_mean_metrics, cv_std_metrics):\n",
    "        \"\"\"Compare final model metrics with cross-validation metrics.\"\"\"\n",
    "        final_metrics = self.get_metrics()\n",
    "        \n",
    "        print(\"\\nMetrics Comparison (Final Model vs. Cross-Validation):\")\n",
    "        print(\"-------------------------------------------------\")\n",
    "        for metric in final_metrics.keys():\n",
    "            final_value = final_metrics[metric]\n",
    "            if metric in cv_mean_metrics:\n",
    "                cv_mean = cv_mean_metrics[metric]\n",
    "                cv_std = cv_std_metrics[metric]\n",
    "                diff = final_value - cv_mean\n",
    "                print(f\"{metric}:\")\n",
    "                print(f\"  - Final Model: {final_value:.4f}\")\n",
    "                print(f\"  - CV Mean:     {cv_mean:.4f} ± {cv_std:.4f}\")\n",
    "                print(f\"  - Difference:  {diff:.4f} ({diff/cv_mean*100:.2f}%)\")\n",
    "            else:\n",
    "                print(f\"{metric}: {final_value:.4f} (CV metric not available)\")\n",
    "\n",
    "    def evaluate_all(self):\n",
    "        \"\"\"Run all evaluations and plots.\"\"\"\n",
    "        self.print_metrics()\n",
    "        self.plot_learning_curve()\n",
    "        self.plot_feature_importance()\n",
    "        self.plot_roc_curve()\n",
    "        self.plot_confusion_matrix()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "26c8bf3c",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-03-16T11:28:13.271668Z",
     "iopub.status.busy": "2025-03-16T11:28:13.271668Z",
     "iopub.status.idle": "2025-03-16T11:28:18.011735Z",
     "shell.execute_reply": "2025-03-16T11:28:18.011735Z"
    },
    "papermill": {
     "duration": 4.745089,
     "end_time": "2025-03-16T11:28:18.012742",
     "exception": false,
     "start_time": "2025-03-16T11:28:13.267653",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "|   iter    |  target   | border... |   depth   | iterat... | l2_lea... | learni... |\n",
      "-------------------------------------------------------------------------------------\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Error in optimization: catboost/private/libs/target/target_converter.cpp:410: Target with classes must contain only 2 unique values for binary classification\n",
      "| \u001b[39m1        \u001b[39m | \u001b[39m0.0      \u001b[39m | \u001b[39m69.36    \u001b[39m | \u001b[39m8.901    \u001b[39m | \u001b[39m946.4    \u001b[39m | \u001b[39m4.197    \u001b[39m | \u001b[39m0.02656  \u001b[39m |\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Error in optimization: catboost/private/libs/target/target_converter.cpp:410: Target with classes must contain only 2 unique values for binary classification\n",
      "| \u001b[39m2        \u001b[39m | \u001b[39m0.0      \u001b[39m | \u001b[39m63.9     \u001b[39m | \u001b[39m7.116    \u001b[39m | \u001b[39m973.2    \u001b[39m | \u001b[39m4.202    \u001b[39m | \u001b[39m0.03208  \u001b[39m |\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Error in optimization: catboost/private/libs/target/target_converter.cpp:410: Target with classes must contain only 2 unique values for binary classification\n",
      "| \u001b[39m3        \u001b[39m | \u001b[39m0.0      \u001b[39m | \u001b[39m84.72    \u001b[39m | \u001b[39m7.342    \u001b[39m | \u001b[39m800.3    \u001b[39m | \u001b[39m4.19     \u001b[39m | \u001b[39m0.03453  \u001b[39m |\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Error in optimization: catboost/private/libs/target/target_converter.cpp:410: Target with classes must contain only 2 unique values for binary classification\n",
      "| \u001b[39m4        \u001b[39m | \u001b[39m0.0      \u001b[39m | \u001b[39m60.3     \u001b[39m | \u001b[39m7.732    \u001b[39m | \u001b[39m800.4    \u001b[39m | \u001b[39m3.331    \u001b[39m | \u001b[39m0.02948  \u001b[39m |\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Error in optimization: catboost/private/libs/target/target_converter.cpp:410: Target with classes must contain only 2 unique values for binary classification\n",
      "| \u001b[39m5        \u001b[39m | \u001b[39m0.0      \u001b[39m | \u001b[39m84.54    \u001b[39m | \u001b[39m7.522    \u001b[39m | \u001b[39m999.1    \u001b[39m | \u001b[39m3.108    \u001b[39m | \u001b[39m0.03108  \u001b[39m |\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Error in optimization: catboost/private/libs/target/target_converter.cpp:410: Target with classes must contain only 2 unique values for binary classification\n",
      "| \u001b[39m6        \u001b[39m | \u001b[39m0.0      \u001b[39m | \u001b[39m84.77    \u001b[39m | \u001b[39m7.131    \u001b[39m | \u001b[39m800.7    \u001b[39m | \u001b[39m4.46     \u001b[39m | \u001b[39m0.03475  \u001b[39m |\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Error in optimization: catboost/private/libs/target/target_converter.cpp:410: Target with classes must contain only 2 unique values for binary classification\n",
      "| \u001b[39m7        \u001b[39m | \u001b[39m0.0      \u001b[39m | \u001b[39m60.3     \u001b[39m | \u001b[39m8.437    \u001b[39m | \u001b[39m999.3    \u001b[39m | \u001b[39m4.482    \u001b[39m | \u001b[39m0.02763  \u001b[39m |\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Error in optimization: catboost/private/libs/target/target_converter.cpp:410: Target with classes must contain only 2 unique values for binary classification\n",
      "| \u001b[39m8        \u001b[39m | \u001b[39m0.0      \u001b[39m | \u001b[39m60.04    \u001b[39m | \u001b[39m8.385    \u001b[39m | \u001b[39m800.7    \u001b[39m | \u001b[39m3.981    \u001b[39m | \u001b[39m0.02643  \u001b[39m |\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Error in optimization: catboost/private/libs/target/target_converter.cpp:410: Target with classes must contain only 2 unique values for binary classification\n",
      "| \u001b[39m9        \u001b[39m | \u001b[39m0.0      \u001b[39m | \u001b[39m84.56    \u001b[39m | \u001b[39m8.32     \u001b[39m | \u001b[39m999.7    \u001b[39m | \u001b[39m3.88     \u001b[39m | \u001b[39m0.03449  \u001b[39m |\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Error in optimization: catboost/private/libs/target/target_converter.cpp:410: Target with classes must contain only 2 unique values for binary classification\n",
      "| \u001b[39m10       \u001b[39m | \u001b[39m0.0      \u001b[39m | \u001b[39m84.77    \u001b[39m | \u001b[39m7.976    \u001b[39m | \u001b[39m800.6    \u001b[39m | \u001b[39m3.896    \u001b[39m | \u001b[39m0.03415  \u001b[39m |\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Error in optimization: catboost/private/libs/target/target_converter.cpp:410: Target with classes must contain only 2 unique values for binary classification\n",
      "| \u001b[39m11       \u001b[39m | \u001b[39m0.0      \u001b[39m | \u001b[39m60.03    \u001b[39m | \u001b[39m8.494    \u001b[39m | \u001b[39m999.2    \u001b[39m | \u001b[39m4.06     \u001b[39m | \u001b[39m0.02914  \u001b[39m |\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Error in optimization: catboost/private/libs/target/target_converter.cpp:410: Target with classes must contain only 2 unique values for binary classification\n",
      "| \u001b[39m12       \u001b[39m | \u001b[39m0.0      \u001b[39m | \u001b[39m60.01    \u001b[39m | \u001b[39m8.869    \u001b[39m | \u001b[39m800.7    \u001b[39m | \u001b[39m4.095    \u001b[39m | \u001b[39m0.03186  \u001b[39m |\n",
      "=====================================================================================\n",
      "\n",
      "Best parameters found:\n",
      "border_count: 69\n",
      "depth: 8\n",
      "iterations: 946\n",
      "l2_leaf_reg: 4.1973\n",
      "learning_rate: 0.0266\n",
      "\n",
      "Best CV auc score: 0.0000\n"
     ]
    }
   ],
   "source": [
    "optimizer = CatBoostBayesianOptimizer(\n",
    "    X_train=X_train,\n",
    "    y_train=y_train,\n",
    "    cat_features=cat_features,\n",
    "    eval_metric=\"auc\", \n",
    "    n_splits=5,\n",
    "    random_state=42,\n",
    "    gpu_id=0\n",
    ")\n",
    "\n",
    "#We can also change the iterations of the bayesion and the best points\n",
    "best_params = optimizer.optimize(n_iter=10, n_init_points=2)\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3d95aa47",
   "metadata": {
    "tags": [
     "papermill-error-cell-tag"
    ]
   },
   "source": [
    "<span id=\"papermill-error-cell\" style=\"color:red; font-family:Helvetica Neue, Helvetica, Arial, sans-serif; font-size:2em;\">Execution using papermill encountered an exception here and stopped:</span>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "c02c8fef",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-03-16T11:28:18.020257Z",
     "iopub.status.busy": "2025-03-16T11:28:18.020257Z",
     "iopub.status.idle": "2025-03-16T11:28:19.080118Z",
     "shell.execute_reply": "2025-03-16T11:28:19.080118Z"
    },
    "papermill": {
     "duration": 1.063375,
     "end_time": "2025-03-16T11:28:19.080118",
     "exception": true,
     "start_time": "2025-03-16T11:28:18.016743",
     "status": "failed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Performing 5-fold CV to determine optimal iterations...\n"
     ]
    },
    {
     "ename": "CatBoostError",
     "evalue": "catboost/private/libs/target/target_converter.cpp:410: Target with classes must contain only 2 unique values for binary classification",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mCatBoostError\u001b[0m                             Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[11], line 2\u001b[0m\n\u001b[0;32m      1\u001b[0m \u001b[38;5;66;03m# Select best model using SKCV and train final model\u001b[39;00m\n\u001b[1;32m----> 2\u001b[0m final_model, cv_score, cv_std \u001b[38;5;241m=\u001b[39m \u001b[43moptimizer\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mFinal_model\u001b[49m\u001b[43m(\u001b[49m\u001b[43mbest_params\u001b[49m\u001b[43m)\u001b[49m\n",
      "Cell \u001b[1;32mIn[8], line 149\u001b[0m, in \u001b[0;36mCatBoostBayesianOptimizer.Final_model\u001b[1;34m(self, best_params)\u001b[0m\n\u001b[0;32m    147\u001b[0m model \u001b[38;5;241m=\u001b[39m CatBoostClassifier(\u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mmodel_params)\n\u001b[0;32m    148\u001b[0m \u001b[38;5;66;03m#You can change the final model here\u001b[39;00m\n\u001b[1;32m--> 149\u001b[0m \u001b[43mmodel\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mfit\u001b[49m\u001b[43m(\u001b[49m\u001b[43mtrain_pool\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43meval_set\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mval_pool\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mearly_stopping_rounds\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;241;43m50\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mverbose\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;241;43m100\u001b[39;49m\u001b[43m)\u001b[49m\n\u001b[0;32m    151\u001b[0m \u001b[38;5;66;03m# Store the best iteration number\u001b[39;00m\n\u001b[0;32m    152\u001b[0m best_iterations\u001b[38;5;241m.\u001b[39mappend(model\u001b[38;5;241m.\u001b[39mget_best_iteration())\n",
      "File \u001b[1;32mD:\\optimizing-catboost-model-with-bayesian\\env\\Lib\\site-packages\\catboost\\core.py:5245\u001b[0m, in \u001b[0;36mCatBoostClassifier.fit\u001b[1;34m(self, X, y, cat_features, text_features, embedding_features, graph, sample_weight, baseline, use_best_model, eval_set, verbose, logging_level, plot, plot_file, column_description, verbose_eval, metric_period, silent, early_stopping_rounds, save_snapshot, snapshot_file, snapshot_interval, init_model, callbacks, log_cout, log_cerr)\u001b[0m\n\u001b[0;32m   5242\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mloss_function\u001b[39m\u001b[38;5;124m'\u001b[39m \u001b[38;5;129;01min\u001b[39;00m params:\n\u001b[0;32m   5243\u001b[0m     CatBoostClassifier\u001b[38;5;241m.\u001b[39m_check_is_compatible_loss(params[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mloss_function\u001b[39m\u001b[38;5;124m'\u001b[39m])\n\u001b[1;32m-> 5245\u001b[0m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_fit\u001b[49m\u001b[43m(\u001b[49m\u001b[43mX\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43my\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mcat_features\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mtext_features\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43membedding_features\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43;01mNone\u001b[39;49;00m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mgraph\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43msample_weight\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43;01mNone\u001b[39;49;00m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43;01mNone\u001b[39;49;00m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43;01mNone\u001b[39;49;00m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43;01mNone\u001b[39;49;00m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mbaseline\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43muse_best_model\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   5246\u001b[0m \u001b[43m          \u001b[49m\u001b[43meval_set\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mverbose\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mlogging_level\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mplot\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mplot_file\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mcolumn_description\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mverbose_eval\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mmetric_period\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   5247\u001b[0m \u001b[43m          \u001b[49m\u001b[43msilent\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mearly_stopping_rounds\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43msave_snapshot\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43msnapshot_file\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43msnapshot_interval\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43minit_model\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mcallbacks\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mlog_cout\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mlog_cerr\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m   5248\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\n",
      "File \u001b[1;32mD:\\optimizing-catboost-model-with-bayesian\\env\\Lib\\site-packages\\catboost\\core.py:2410\u001b[0m, in \u001b[0;36mCatBoost._fit\u001b[1;34m(self, X, y, cat_features, text_features, embedding_features, pairs, graph, sample_weight, group_id, group_weight, subgroup_id, pairs_weight, baseline, use_best_model, eval_set, verbose, logging_level, plot, plot_file, column_description, verbose_eval, metric_period, silent, early_stopping_rounds, save_snapshot, snapshot_file, snapshot_interval, init_model, callbacks, log_cout, log_cerr)\u001b[0m\n\u001b[0;32m   2407\u001b[0m allow_clear_pool \u001b[38;5;241m=\u001b[39m train_params[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mallow_clear_pool\u001b[39m\u001b[38;5;124m\"\u001b[39m]\n\u001b[0;32m   2409\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m plot_wrapper(plot, plot_file, \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mTraining plots\u001b[39m\u001b[38;5;124m'\u001b[39m, [_get_train_dir(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mget_params())]):\n\u001b[1;32m-> 2410\u001b[0m     \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_train\u001b[49m\u001b[43m(\u001b[49m\n\u001b[0;32m   2411\u001b[0m \u001b[43m        \u001b[49m\u001b[43mtrain_pool\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   2412\u001b[0m \u001b[43m        \u001b[49m\u001b[43mtrain_params\u001b[49m\u001b[43m[\u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43meval_sets\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m]\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   2413\u001b[0m \u001b[43m        \u001b[49m\u001b[43mparams\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   2414\u001b[0m \u001b[43m        \u001b[49m\u001b[43mallow_clear_pool\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   2415\u001b[0m \u001b[43m        \u001b[49m\u001b[43mtrain_params\u001b[49m\u001b[43m[\u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43minit_model\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m]\u001b[49m\n\u001b[0;32m   2416\u001b[0m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m   2418\u001b[0m \u001b[38;5;66;03m# Have property feature_importance possibly set\u001b[39;00m\n\u001b[0;32m   2419\u001b[0m loss \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_object\u001b[38;5;241m.\u001b[39m_get_loss_function_name()\n",
      "File \u001b[1;32mD:\\optimizing-catboost-model-with-bayesian\\env\\Lib\\site-packages\\catboost\\core.py:1790\u001b[0m, in \u001b[0;36m_CatBoostBase._train\u001b[1;34m(self, train_pool, test_pool, params, allow_clear_pool, init_model)\u001b[0m\n\u001b[0;32m   1789\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21m_train\u001b[39m(\u001b[38;5;28mself\u001b[39m, train_pool, test_pool, params, allow_clear_pool, init_model):\n\u001b[1;32m-> 1790\u001b[0m     \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_object\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_train\u001b[49m\u001b[43m(\u001b[49m\u001b[43mtrain_pool\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mtest_pool\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mparams\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mallow_clear_pool\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43minit_model\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_object\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43;01mif\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43minit_model\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43;01melse\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[38;5;28;43;01mNone\u001b[39;49;00m\u001b[43m)\u001b[49m\n\u001b[0;32m   1791\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_set_trained_model_attributes()\n",
      "File \u001b[1;32m_catboost.pyx:5017\u001b[0m, in \u001b[0;36m_catboost._CatBoost._train\u001b[1;34m()\u001b[0m\n",
      "File \u001b[1;32m_catboost.pyx:5066\u001b[0m, in \u001b[0;36m_catboost._CatBoost._train\u001b[1;34m()\u001b[0m\n",
      "\u001b[1;31mCatBoostError\u001b[0m: catboost/private/libs/target/target_converter.cpp:410: Target with classes must contain only 2 unique values for binary classification"
     ]
    }
   ],
   "source": [
    "# Select best model using SKCV and train final model\n",
    "final_model, cv_score, cv_std = optimizer.Final_model(best_params)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "758c6a68",
   "metadata": {
    "papermill": {
     "duration": null,
     "end_time": null,
     "exception": null,
     "start_time": null,
     "status": "pending"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Now evaluate the final model\n",
    "evaluator = FinalModelEvaluator(\n",
    "    model=final_model,\n",
    "    X_train=X_train,\n",
    "    y_train=y_train,\n",
    "    X_test=X_test,\n",
    "    y_test=y_test,\n",
    "    cat_features=cat_features\n",
    ")\n",
    "\n",
    "# Run all evaluations\n",
    "evaluator.evaluate_all()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f78154c6",
   "metadata": {
    "papermill": {
     "duration": null,
     "end_time": null,
     "exception": null,
     "start_time": null,
     "status": "pending"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "os.makedirs('saved_models', exist_ok=True)\n",
    "final_model.save_model('saved_models/Bayesian_Opt_Catboost.cbm')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "env",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.0"
  },
  "papermill": {
   "default_parameters": {},
   "duration": 18.609388,
   "end_time": "2025-03-16T11:28:19.764616",
   "environment_variables": {},
   "exception": true,
   "input_path": "model/Bayesian_Opt_Catboost Binary.ipynb",
   "output_path": "temp\\notebooks\\output_1742124481.ipynb",
   "parameters": {
    "algorithm": "bayesian",
    "dataset_path": "temp\\1b9c6bc6-5a5b-4a23-9dfc-1a6d44661717.csv",
    "model_output_path": "saved_models/Bayesian_Opt_Catboost_1742124481.cbm"
   },
   "start_time": "2025-03-16T11:28:01.155228",
   "version": "2.6.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}